{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pathlib as path\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "from random import sample\n",
    "from cmath import nan\n",
    "import json\n",
    "\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch folder found at:\n",
      " c:\\Users\\User\\Desktop\\visual_memory_project\\visual-memory-project\\projects\\birds\\experiment 1\\collected data\\pilot_24_hours\\batch 1\n"
     ]
    }
   ],
   "source": [
    "#define the relevant path to the current batch you wish to parse\n",
    "gap_name='pilot_24_hours' #dont change this as this parsing sciprt only handles the same day batches.  \n",
    "\n",
    "project_name='birds'\n",
    "experiment_name='experiment 1'\n",
    "batch_name='batch 1'\n",
    "qualification_method='loose' #or 'loose'  - defines different disqualification criterions (add this suffix to the saved file)\n",
    "\n",
    "PATH_TO_BATCH=path.Path.cwd().parent.parent.parent / 'projects' / project_name / experiment_name / 'collected data' / gap_name / batch_name\n",
    "PATH_TO_BATCH_DATA = PATH_TO_BATCH / 'data'\n",
    "\n",
    "if PATH_TO_BATCH.exists():\n",
    "    print('batch folder found at:\\n' ,PATH_TO_BATCH)\n",
    "else: \n",
    "    print('path to batch is non existent:\\n',PATH_TO_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# it is important to copy the column names from the csv files so the right columns get updated\n",
    "qualification_name_for_testin='UPDATE-completed encoding successfully '  #note that the -space- after the title is improtant as for some reason this is how the qualification name is defined\n",
    "qualification_name_for_entire_experiment='UPDATE-completed birds memory rep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_criterions(type='strict'):\n",
    "    #the function sets the criterions and returns them as a pd.series\n",
    "    criterions_df=pd.Series(dtype=float)\n",
    "\n",
    "    #update the non changing ciretrions: \n",
    "    criterions_df['demo_arrow_correctness']=1\n",
    "    criterions_df['encoding_arrow_accuracy']=0.6\n",
    "    criterions_df['longest_allowed_consequtive_strike']=15\n",
    "    criterions_df['fast_threshold']=0.3\n",
    "\n",
    "    if type=='strict':\n",
    "        criterions_df['demo_accuracy_treshold']=0.5 \n",
    "        \n",
    "        criterions_df['fast_allowed_count']=3 \n",
    "        criterions_df['slow_threshold']=10\n",
    "        criterions_df['slow_allowed_count']=2\n",
    "        criterions_df['binom_single_layer']=0.75\n",
    "        criterions_df['binom_averages']=0.61\n",
    "    elif type=='loose': #here we change things to be easier to pass\n",
    "        criterions_df['demo_accuracy_treshold']=0\n",
    "        criterions_df['fast_threshold']=0.3\n",
    "        criterions_df['fast_allowed_count']=5 \n",
    "        criterions_df['slow_threshold']=15\n",
    "        criterions_df['slow_allowed_count']=5\n",
    "        criterions_df['binom_single_layer']=0.55\n",
    "        criterions_df['binom_averages']=0.55\n",
    "    else: \n",
    "        raise Exception('requested method is not defined')\n",
    "    \n",
    "    return criterions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "demo_arrow_correctness                 1.00\n",
       "encoding_arrow_accuracy                0.60\n",
       "longest_allowed_consequtive_strike    15.00\n",
       "fast_threshold                         0.30\n",
       "demo_accuracy_treshold                 0.00\n",
       "fast_allowed_count                     5.00\n",
       "slow_threshold                        15.00\n",
       "slow_allowed_count                     5.00\n",
       "binom_single_layer                     0.55\n",
       "binom_averages                         0.55\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "criterions_df=set_criterions(qualification_method)\n",
    "criterions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_criterions(type='strict'):\n",
    "    #the function sets the criterions and returns them as a pd.series\n",
    "    criterions_df=pd.Series(dtype=float)\n",
    "\n",
    "    #update the non changing ciretrions: \n",
    "    criterions_df['demo_arrow_correctness']=1\n",
    "    criterions_df['encoding_arrow_accuracy']=0.6\n",
    "    criterions_df['longest_allowed_consequtive_strike']=15\n",
    "    criterions_df['fast_threshold']=0.3\n",
    "\n",
    "    if type=='strict':\n",
    "        criterions_df['demo_accuracy_treshold']=0.5 \n",
    "        \n",
    "        criterions_df['fast_allowed_count']=3 \n",
    "        criterions_df['slow_threshold']=10\n",
    "        criterions_df['slow_allowed_count']=2\n",
    "        criterions_df['binom_single_layer']=0.75\n",
    "        criterions_df['binom_averages']=0.61\n",
    "    elif type=='loose': #here we change things to be easier to pass\n",
    "        criterions_df['demo_accuracy_treshold']=0\n",
    "        criterions_df['fast_threshold']=0.3\n",
    "        criterions_df['fast_allowed_count']=5 \n",
    "        criterions_df['slow_threshold']=15\n",
    "        criterions_df['slow_allowed_count']=5\n",
    "        criterions_df['binom_single_layer']=0.55\n",
    "        criterions_df['binom_averages']=0.55\n",
    "    else: \n",
    "        raise Exception('requested method is not defined')\n",
    "    \n",
    "    return criterions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "demo_arrow_correctness                 1.00\n",
       "encoding_arrow_accuracy                0.60\n",
       "longest_allowed_consequtive_strike    15.00\n",
       "fast_threshold                         0.30\n",
       "demo_accuracy_treshold                 0.00\n",
       "fast_allowed_count                     5.00\n",
       "slow_threshold                        15.00\n",
       "slow_allowed_count                     5.00\n",
       "binom_single_layer                     0.55\n",
       "binom_averages                         0.55\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "criterions_df=set_criterions(qualification_method)\n",
    "criterions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A3BU8UL4W258UU': [0, 1672259949355, 1672330353312, 1672338011502],\n",
       " 'A2YC6PEMIRSOAA': [999, 1672259992394, 1672260336538],\n",
       " 'A2IQ0QCTQ3KWLT': [2, 1672259962573],\n",
       " 'APVZGZM1RA3AZ': [999, 1672259965919, 1672451513039],\n",
       " 'A27PVIL93ZMY46': [999, 1672259976932, 1672431903284],\n",
       " 'A11F3MA5FWH6SJ': [5, 1672259987509, 1672330050392, 1672335745754],\n",
       " 'A2PPTQXFVA9H38': [999, 1672259987861],\n",
       " 'A1FJGB5JLZ81XB': [7, 1672260025367, 1672334776164, 1672337091803],\n",
       " 'AYWHJVYLOA2B5': [999, 1672260029473],\n",
       " 'A9YPM325MKYLO': [9,\n",
       "  1672260039075,\n",
       "  1672330447238,\n",
       "  1672330627138,\n",
       "  1672333360670,\n",
       "  1672343237383],\n",
       " 'AGZ3QJFK1BR8V': [10,\n",
       "  1672260111857,\n",
       "  1672330308647,\n",
       "  1672330477505,\n",
       "  1672331290953,\n",
       "  1672336504122],\n",
       " 'AW9T591E49DCX': [11, 1672260117172, 1672331320568],\n",
       " 'A6M7YIG6KKHPA': [12, 1672260301475, 1672329813672, 1672329849584],\n",
       " 'A1TKZIBGTP7FE8': [13, 1672260321296, 1672346014127],\n",
       " 'A3HZFB2JLF3JMY': [14, 1672260345507],\n",
       " 'ARR9GKAG3JFE5': [15, 1672260410283, 1672344293514],\n",
       " 'A1PHDT66U6IK4Q': [16,\n",
       "  1672260558724,\n",
       "  1672330013374,\n",
       "  1672330273345,\n",
       "  1672331907909,\n",
       "  1672333999861,\n",
       "  1672335867212,\n",
       "  1672337055604],\n",
       " 'A3SKE5B27HLVO6': [17, 1672260574773, 1672331588331, 1672336764278],\n",
       " 'A1QT3YA7G8MO63': [18, 1672260449206, 1672342649908],\n",
       " 'A2VLTSW6CXIUMR': [19, 1672260855599, 1672350028452],\n",
       " 'A1FMVUYV72MUO3': [999, 1672260889474, 1672366520395],\n",
       " 'A2376IXNKHYB22': [999, 999, 999],\n",
       " 'A2XDWB9NVYI3LQ': [999, 1672260987435, 1672368570043],\n",
       " 'AWX3PLN2FS0SW': [999, 999, 999],\n",
       " 'A2IP3ZAFYGV8M9': [23, 1672261263996, 1672348660773],\n",
       " 'A1QUQ0TV9KVD4C': [21, 1672261682060],\n",
       " 'A1YV7SCB1OHMUT': [24, 1672261683329, 1672329977079],\n",
       " 'A3CH1Z6J9R38G9': [26,\n",
       "  1672261908133,\n",
       "  1672331114658,\n",
       "  1672331943263,\n",
       "  1672334404561,\n",
       "  1672336907779,\n",
       "  1672337767267],\n",
       " 'A3KP8KFGG6734Q': [25,\n",
       "  1672262067284,\n",
       "  1672262637385,\n",
       "  1672330879530,\n",
       "  1672356371483],\n",
       " 'hjfhhyhy46478': [999, 999, 999],\n",
       " 'ksgsuhf644': [999, 999, 999],\n",
       " 'A1OM5NWYYYJKQW': [27, 1672262466157, 1672329743884, 1672340507840],\n",
       " 'A7VA2Y4H6U31O': [28, 1672262935938, 1672330641939, 1672338822690],\n",
       " 'A2B153AHPWHLH1': [29, 1672263102293],\n",
       " 'A39M9PZLH3J1NF': [999, 1672263106065],\n",
       " 'AXPZAP62ZYWP8': [31, 1672263205796, 1672337433968, 1672343630318],\n",
       " 'A41APS6V2Z1FJ': [32, 1672263770329, 1672339809777],\n",
       " 'A1Y2W25NF6T431': [999, 1672264261852],\n",
       " 'A2M183CETUMR96': [34, 1672264350184, 1672358532686],\n",
       " 'A1SNC8UL8YFRH5': [35, 1672264395481, 1672347780832],\n",
       " 'A31T2PF4RV3GTF': [36, 1672272089756, 1672331302872, 1672336100994],\n",
       " 'A1DZMZTXWOM9MR': [37, 1672273012190, 1672365046651],\n",
       " 'A11J9UQ036KJA1': [38, 1672274476434],\n",
       " 'A25PFSORDO3SWQ': [39, 1672274742971, 1672352498510],\n",
       " 'A3ATB5GC4BQIH0': [40, 1672274902382, 1672330349861, 1672362175130],\n",
       " 'ACGGIBC0P38HU': [41, 1672277137233, 1672360652315],\n",
       " 'A2YVQKJX3FO6P': [42, 1672278953409, 1672340145634, 1672366806134],\n",
       " 'AAF1SJ9FCBF75': [43, 1672281438975, 1672370976812],\n",
       " 'A39VAFCIGP83ER': [44,\n",
       "  1672282360982,\n",
       "  1672337934811,\n",
       "  1672346205293,\n",
       "  1672346443137,\n",
       "  1672352366678,\n",
       "  1672353595279,\n",
       "  1672355418377,\n",
       "  1672366834322],\n",
       " 'A16JG2M1SEGWPW': [999,\n",
       "  1672316383870,\n",
       "  1672317139595,\n",
       "  1672317516600,\n",
       "  1672319128198,\n",
       "  1672320185583],\n",
       " 'AHXQCR64E5GUE': [999, 999, 999],\n",
       " 'AMPR904VJJFZY': [46,\n",
       "  1672323849721,\n",
       "  1672329782081,\n",
       "  1672329848269,\n",
       "  1672330877873,\n",
       "  1672347114435],\n",
       " 'A22HIX1M4QXZBB': [1, 1672330046121],\n",
       " 'A248QG4DPULP46': [6, 1672330756613],\n",
       " 'A2ASR7XQA7KERU': [3, 1672497020995]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this section loads the shelf dict in the state it is after finishing the testing session for this batch. \n",
    "shelf_dict_after_test_name=PATH_TO_BATCH / 'shelf after test session closed.txt' #define the name of the relevant shelf for this stage\n",
    "with open(shelf_dict_after_test_name) as f:\n",
    "    data = f.read()\n",
    "shelf_dict = json.loads(data)\n",
    "shelf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section reads all the relevant files: \n",
    "if (PATH_TO_BATCH / 'Batch_encoding_batch_results.csv').exists():\n",
    "    encoding_df=pd.read_csv(PATH_TO_BATCH / 'Batch_encoding_batch_results.csv')\n",
    "else: \n",
    "    print(f'no \"Batch_encoding_batch_results.csv\" was found in data')\n",
    "\n",
    "if (PATH_TO_BATCH / 'Batch_testing_batch_results.csv').exists():\n",
    "    testing_df=pd.read_csv(PATH_TO_BATCH / 'Batch_testing_batch_results.csv')\n",
    "else: \n",
    "    print(f'no \"Batch_testing_batch_results.csv\" was found in data (probably because only the encoding session finished)')\n",
    "if (PATH_TO_BATCH / 'Batch_workers_after_test.csv').exists():\n",
    "    workers_df=pd.read_csv(PATH_TO_BATCH / 'Batch_workers_after_test.csv')\n",
    "else:\n",
    "    print('No AMAZON worker list was found: please make sure to upload one and name it correctly')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_consequtive_repetition(responses_array):\n",
    "#add a stop value so the loop will use the logic also if the end of the responses is all repeating: \n",
    "    responses_array=np.append(responses_array,[99])\n",
    "    longest_rep_dict=dict()\n",
    "    last_input=responses_array[0]\n",
    "    consequtive_rep_counter=0\n",
    "    for response in responses_array[1:]: \n",
    "        if response==last_input: #if consequtive rep: \n",
    "            consequtive_rep_counter=consequtive_rep_counter+1 #add to counter\n",
    "        else: #once a new entry is in the vector - store the counter rep information \n",
    "            if last_input in longest_rep_dict.keys(): #if it was allready stored in our dictionary\n",
    "                if longest_rep_dict[last_input]<consequtive_rep_counter: #replace the counter only if it is higher than what stored in dict\n",
    "                    longest_rep_dict[last_input]=consequtive_rep_counter\n",
    "            else: #this entry is not yet in the dictionary: add it \n",
    "                longest_rep_dict[last_input]=consequtive_rep_counter\n",
    "            \n",
    "            consequtive_rep_counter=0\n",
    "            last_input=response\n",
    "    return max(longest_rep_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_worker_results(PATH_TO_BATCH_DATA,subject_name,parse_type='encoding'):\n",
    "    cur_sub=pd.read_csv(PATH_TO_BATCH_DATA / subject_name)\n",
    "    sub_demographics=cur_sub[['workID','Age','Gender']].iloc[0]\n",
    "\n",
    "    #extract demo related information: \n",
    "\n",
    "    #if participant did not click on the arrow during the demo a 'demo_encoding_response.rt' colmumn wont exists: \n",
    "    #thus we will create one and fill it with nans (so everything will be consistent with other participants)\n",
    "    demo_columns=['demo_encoding_loop.thisTrialN','DemoImage','DemoCorrect','demo_encoding_response.rt','demo_encoding_response.keys']\n",
    "    demo_test_columns=['demo_test_response.keys','demo_test_response.corr','demo_test_response.rt','demo_test_loop.thisTrialN','DemoImage1','DemoImage2','DemoCorrectTest']\n",
    "    encoding_related_columns=['test_encoding_response.keys','test_encoding_response.corr','trials.thisTrialN','target_image','pair','layer','correct','test_encoding_response.rt','key_resp_end.keys']\n",
    "    test_related_columns=['layer','correct','test_test_response.keys','test_test_response.corr','test_test_response.rt','trials_2.thisRepN','trials_2.thisTrialN','trials_2.thisN','trials_2.thisIndex','trials_2.ran','image1','image2']\n",
    "\n",
    "    if not('demo_encoding_response.rt' in cur_sub.columns):\n",
    "        cur_sub['demo_encoding_response.rt']=np.nan  \n",
    "\n",
    "    if (parse_type=='encoding'):\n",
    "        sub_demo_information=cur_sub[demo_columns]\n",
    "        empty_inds=sub_demo_information.loc[sub_demo_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "        #drop irrelevant columns: \n",
    "        sub_demo_information=sub_demo_information.drop(index=empty_inds)\n",
    "\n",
    "\n",
    "        #extract the demo test columns: \n",
    "        sub_demo_test_information=cur_sub[demo_test_columns]\n",
    "        empty_inds=sub_demo_test_information.loc[sub_demo_test_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "        #drop irrelevant columns: \n",
    "        sub_demo_test_information=sub_demo_test_information.drop(index=empty_inds)\n",
    "\n",
    "        demo_df=pd.concat([sub_demo_information.reset_index(),sub_demo_test_information.reset_index()],axis=1)\n",
    "\n",
    "    #extract real experiment related information: \n",
    "\n",
    "    #if participant did not click on the arrow during the encoding a 'test_encoding_response.rt' column wont exists: \n",
    "    #thus we will create one and fill it with nans (so everything will be consistent with other participants)\n",
    "    if not('test_encoding_response.rt' in cur_sub.columns):\n",
    "        cur_sub['test_encoding_response.rt']=np.nan\n",
    "        \n",
    "\n",
    "    if (parse_type=='encoding') | (parse_type=='all'):\n",
    "        sub_encoding_information=cur_sub[encoding_related_columns]\n",
    "        #encoding section ends with a key press of the space key: so seperate this phase by finding this space key row\n",
    "        end_of_section_ind=np.where(sub_encoding_information['key_resp_end.keys']=='space')[0][0]\n",
    "        sub_encoding_information=sub_encoding_information.iloc[0:end_of_section_ind]\n",
    "        #remove all the rows that precede the real encoding phase: \n",
    "        empty_inds=sub_encoding_information.loc[sub_encoding_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "        sub_encoding_information=sub_encoding_information.drop(index=empty_inds).reset_index()\n",
    "\n",
    "    if (parse_type=='test') | (parse_type=='all'):\n",
    "    #extract real experiment TEST related information: \n",
    "        sub_test_information=cur_sub[test_related_columns].dropna()\n",
    "\n",
    "\n",
    "    subject_dictionary=dict()\n",
    "    subject_dictionary['demographics']=sub_demographics\n",
    "    if (parse_type=='encoding') | (parse_type=='all'):\n",
    "        subject_dictionary['demo_df']=demo_df\n",
    "    if (parse_type=='encoding') | (parse_type=='all'):\n",
    "        subject_dictionary['encoding_df']=sub_encoding_information\n",
    "    if (parse_type=='test') | (parse_type=='all'):\n",
    "        subject_dictionary['test_df']=sub_test_information\n",
    "\n",
    "    return subject_dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODING_A11F3MA5FWH6SJ_2022-12-28_15h39.47.509.csv\n",
      "ENCODING_A11J9UQ036KJA1_2022-12-28_19h41.16.434.csv\n",
      "ENCODING_A16JG2M1SEGWPW_2022-12-29_07h19.43.870.csv\n",
      "ENCODING_A1DZMZTXWOM9MR_2022-12-28_18h16.52.190.csv\n",
      "ENCODING_A1FJGB5JLZ81XB_2022-12-28_15h40.25.367.csv\n",
      "ENCODING_A1FMVUYV72MUO3_2022-12-28_15h54.49.474.csv\n",
      "ENCODING_A1OM5NWYYYJKQW_2022-12-28_16h21.06.157.csv\n",
      "ENCODING_A1PHDT66U6IK4Q_2022-12-28_15h49.18.724.csv\n",
      "ENCODING_A1QT3YA7G8MO63_2022-12-28_14h47.29.206.csv\n",
      "ENCODING_A1SNC8UL8YFRH5_2022-12-28_16h53.15.481.csv\n",
      "ENCODING_A1TKZIBGTP7FE8_2022-12-28_15h45.21.296.csv\n",
      "ENCODING_A1YV7SCB1OHMUT_2022-12-28_13h08.03.329.csv\n",
      "ENCODING_A22HIX1M4QXZBB_2022-12-29_11h07.26.121.csv\n",
      "ENCODING_A248QG4DPULP46_2022-12-29_11h19.16.613.csv\n",
      "ENCODING_A25PFSORDO3SWQ_2022-12-28_19h45.42.971.csv\n",
      "ENCODING_A27PVIL93ZMY46_2022-12-28_15h39.36.932.csv\n",
      "ENCODING_A2ASR7XQA7KERU_2022-12-31_09h30.20.995.csv\n",
      "ENCODING_A2IP3ZAFYGV8M9_2022-12-28_15h01.03.996.csv\n",
      "ENCODING_A2M183CETUMR96_2022-12-28_15h52.30.184.csv\n",
      "ENCODING_A2VLTSW6CXIUMR_2022-12-28_15h54.15.599.csv\n",
      "ENCODING_A2XDWB9NVYI3LQ_2022-12-28_17h56.27.435.csv\n",
      "ENCODING_A2YC6PEMIRSOAA_2022-12-28_14h39.52.394.csv\n",
      "ENCODING_A2YVQKJX3FO6P_2022-12-28_22h55.53.409.csv\n",
      "ENCODING_A31T2PF4RV3GTF_2022-12-28_16h01.29.756.csv\n",
      "ENCODING_A39M9PZLH3J1NF_2022-12-28_15h31.46.065.csv\n",
      "ENCODING_A39VAFCIGP83ER_2022-12-28_21h52.40.982.csv\n",
      "ENCODING_A3ATB5GC4BQIH0_2022-12-28_21h48.22.382.csv\n",
      "ENCODING_A3BU8UL4W258UU_2022-12-28_15h39.09.355.csv\n",
      "ENCODING_A3CH1Z6J9R38G9_2022-12-28_14h11.48.133.csv\n",
      "ENCODING_A3KP8KFGG6734Q_2022-12-28_14h14.27.284.csv\n",
      "ENCODING_A3SKE5B27HLVO6_2022-12-28_12h49.34.773.csv\n",
      "ENCODING_A41APS6V2Z1FJ_2022-12-28_16h42.50.329.csv\n",
      "ENCODING_A6M7YIG6KKHPA_2022-12-28_12h45.01.475.csv\n",
      "ENCODING_A7VA2Y4H6U31O_2022-12-28_16h28.55.938.csv\n",
      "ENCODING_A9YPM325MKYLO_2022-12-28_13h40.39.075.csv\n",
      "ENCODING_AAF1SJ9FCBF75_2022-12-28_21h37.18.975.csv\n",
      "ENCODING_ACGGIBC0P38HU_2022-12-28_17h25.37.233.csv\n",
      "ENCODING_AGZ3QJFK1BR8V_2022-12-28_15h41.51.857.csv\n",
      "ENCODING_AMPR904VJJFZY_2022-12-29_09h24.09.721.csv\n",
      "ENCODING_APVZGZM1RA3AZ_2022-12-28_14h39.25.919.csv\n",
      "ENCODING_ARR9GKAG3JFE5_2022-12-28_15h46.50.283.csv\n",
      "ENCODING_AW9T591E49DCX_2022-12-28_15h41.57.172.csv\n",
      "ENCODING_AXPZAP62ZYWP8_2022-12-28_16h33.25.796.csv\n",
      "ENCODING_AYWHJVYLOA2B5_2022-12-28_14h40.29.473.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get all results with Encoding information - extract the arrow attention check accuracy and RT (RT is currently not usd as a criterion)\n",
    "\n",
    "#this section extract the list of participants from the downloaded results files (and not via the workers or session list csvs) \n",
    "# - it will create the qualification_df (a table with information on the worker ids and encoding behavior of all participants that we have files for)\n",
    "all_filenames=[file for file in PATH_TO_BATCH_DATA.iterdir() if 'csv' in file.name and 'ENCODING' in file.name]\n",
    "#print(f'current csv files:\\n{all_filenames}')\n",
    "\n",
    "qualification_for_test_df=pd.DataFrame(columns=['workerID','arrow_acc','mean_arrow_RT'])\n",
    "for subject_csv in all_filenames:\n",
    "    print(subject_csv.name)\n",
    "    subject_dict=process_worker_results(PATH_TO_BATCH_DATA,path.Path(subject_csv))\n",
    "    cur_sub_encoding=subject_dict['encoding_df']\n",
    "\n",
    "    sname=subject_csv.name.split('_')[1] #change according to actuall format. \n",
    "\n",
    "    #get only attention check related info: \n",
    "    cur_sub_encoding=cur_sub_encoding[['test_encoding_response.keys','correct','test_encoding_response.rt']].copy().dropna(how = 'all')\n",
    "    if len(cur_sub_encoding)==0: #empty - the participant didnt respond on the arrow at all\n",
    "        arrow_acc=0\n",
    "        RT=nan\n",
    "    else: \n",
    "        RT=cur_sub_encoding['test_encoding_response.rt'].mean()\n",
    "        arrow_acc=(cur_sub_encoding['correct']==cur_sub_encoding['test_encoding_response.keys']).mean()\n",
    "    sub_df=pd.DataFrame({'workerID':sname,'arrow_acc':arrow_acc,'mean_arrow_RT':RT},index=[sname])\n",
    "    qualification_for_test_df=pd.concat([qualification_for_test_df,sub_df],axis=0)\n",
    "\n",
    "#the following part update the qualification_df with information on wether the participant id exists in the amazon workers list: \n",
    "\n",
    "#change participants qualifications if they exists in the workers list based on thier encoding arrow accuracy\n",
    "qualification_for_test_df['in_encoding_workers_list']=nan\n",
    "\n",
    "for curr_worker_ID in qualification_for_test_df.index:\n",
    "    if curr_worker_ID in encoding_df['WorkerId'].values:\n",
    "        qualification_for_test_df.loc[curr_worker_ID,'in_encoding_workers_list']=int(1)\n",
    "    else:\n",
    "        qualification_for_test_df.loc[curr_worker_ID,'in_encoding_workers_list']=int(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects_demo_df=pd.DataFrame()\n",
    "all_subjects_encoding_df=pd.DataFrame()\n",
    "all_subjects_test_df=pd.DataFrame()\n",
    "all_subjects_biographics_df=pd.DataFrame()\n",
    "all_filenames=[file.name for file in PATH_TO_BATCH_DATA.iterdir() if 'csv' in file.name and 'TEST' in file.name]\n",
    "\n",
    "for subject_test_filename in all_filenames:\n",
    "    subject_name=subject_test_filename.split('_')[1]\n",
    "    subject_encoding_filename=[file.name for file in PATH_TO_BATCH_DATA.iterdir() if 'csv' in file.name and 'ENCODING' in file.name and subject_name in file.name][0]\n",
    "    curr_subject_dictionary=process_worker_results(PATH_TO_BATCH_DATA,subject_encoding_filename,parse_type='encoding')\n",
    "    curr_demo_df=curr_subject_dictionary['demo_df']\n",
    "    curr_demo_df['subject']=subject_name\n",
    "    curr_encoding_df=curr_subject_dictionary['encoding_df']\n",
    "    curr_encoding_df['subject']=subject_name\n",
    "    curr_demographics_df=curr_subject_dictionary['demographics']\n",
    "    curr_demographics_df['subject']=subject_name\n",
    "\n",
    "    curr_subject_dictionary=process_worker_results(PATH_TO_BATCH_DATA,subject_test_filename,parse_type='test')\n",
    "    curr_test_df=curr_subject_dictionary['test_df']\n",
    "    curr_test_df['subject']=subject_name\n",
    "\n",
    "\n",
    "\n",
    "    all_subjects_demo_df=pd.concat([all_subjects_demo_df,curr_demo_df],axis=0,ignore_index=True)\n",
    "    all_subjects_encoding_df=pd.concat([all_subjects_encoding_df,curr_encoding_df],axis=0,ignore_index=True)\n",
    "    all_subjects_test_df=pd.concat([all_subjects_test_df,curr_test_df],axis=0,ignore_index=True)\n",
    "    all_subjects_biographics_df=pd.concat([all_subjects_biographics_df,pd.DataFrame(curr_demographics_df).T],axis=0,ignore_index=True)\n",
    "\n",
    "\n",
    "all_subjects_demo_df.to_csv(PATH_TO_BATCH / 'all_subjects_demo_df.csv')\n",
    "all_subjects_encoding_df.to_csv(PATH_TO_BATCH / 'all_subjects_encoding_df.csv')\n",
    "all_subjects_test_df.to_csv(PATH_TO_BATCH / 'all_subjects_test_df.csv')\n",
    "all_subjects_biographics_df.to_csv(PATH_TO_BATCH / 'all_subjects_biographics_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender is still inconsistent with more than 2 unique values: ['Femae' 'female' 'ma' 'male']\n",
      "Mean age: 37.58, range: [22 - 69], 0.15% female\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import category\n",
    "\n",
    "# if there are any empty values - fill with mean of subjects age \n",
    "mean_value = all_subjects_biographics_df['Age'].mean()\n",
    "all_subjects_biographics_df['Age'].fillna(value=mean_value, inplace=True)\n",
    "all_subjects_biographics_df['Age'] = all_subjects_biographics_df['Age'].astype(np.int64)\n",
    "\n",
    "all_subjects_biographics_df['Age']=all_subjects_biographics_df['Age'].astype(int)\n",
    "all_subjects_biographics_df['Gender'].replace({'woman':'female','FEMLAE':'female','Male':'male','MALE':'male','FEMALE':'female','Female':'female','ale':'male'},inplace=True)\n",
    "if len(np.unique(all_subjects_biographics_df['Gender'].values))<=2:\n",
    "    print('transformed the gender column to be consistent having two possible values:',np.unique(all_subjects_biographics_df['Gender'].values))\n",
    "else: \n",
    "    print('gender is still inconsistent with more than 2 unique values:',np.unique(all_subjects_biographics_df['Gender'].values))\n",
    "all_subjects_biographics_df['Gender']=all_subjects_biographics_df['Gender'].astype(\"category\")\n",
    "\n",
    "mean_age,min_age,max_age=all_subjects_biographics_df['Age'].mean(),all_subjects_biographics_df['Age'].min(),all_subjects_biographics_df['Age'].max()\n",
    "female_prop=all_subjects_biographics_df.loc[all_subjects_biographics_df['Gender']=='female','Gender'].count()/all_subjects_biographics_df['Gender'].count()\n",
    "\n",
    "print(f'Mean age: {mean_age:.2f}, range: [{min_age} - {max_age}], {female_prop:.2f}% female')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this part plots the seperate dataframes: \n",
    "### demo phase (encoding and test in the same dataframe)\n",
    "### encoding experiment phase\n",
    "### test experiment phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>demo_encoding_loop.thisTrialN</th>\n",
       "      <th>DemoImage</th>\n",
       "      <th>DemoCorrect</th>\n",
       "      <th>demo_encoding_response.rt</th>\n",
       "      <th>demo_encoding_response.keys</th>\n",
       "      <th>index</th>\n",
       "      <th>demo_test_response.keys</th>\n",
       "      <th>demo_test_response.corr</th>\n",
       "      <th>demo_test_response.rt</th>\n",
       "      <th>demo_test_loop.thisTrialN</th>\n",
       "      <th>DemoImage1</th>\n",
       "      <th>DemoImage2</th>\n",
       "      <th>DemoCorrectTest</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>flower1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>flower1.jpg</td>\n",
       "      <td>flower1_pair.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>flower2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>left</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>flower2_pair.jpg</td>\n",
       "      <td>flower2.jpg</td>\n",
       "      <td>right</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>1.6953</td>\n",
       "      <td>left</td>\n",
       "      <td>14.0</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>flower3.jpg</td>\n",
       "      <td>flower3_pair.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>flower3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4288</td>\n",
       "      <td>3.0</td>\n",
       "      <td>flower4.jpg</td>\n",
       "      <td>flower4_pair.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>flower4.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8950</td>\n",
       "      <td>4.0</td>\n",
       "      <td>flower5_pair.jpg</td>\n",
       "      <td>flower5.jpg</td>\n",
       "      <td>right</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  demo_encoding_loop.thisTrialN    DemoImage DemoCorrect  \\\n",
       "0      4                            0.0  flower1.jpg         NaN   \n",
       "1      5                            1.0  flower2.jpg         NaN   \n",
       "2      6                            2.0     left.jpg        left   \n",
       "3      7                            3.0  flower3.jpg         NaN   \n",
       "4      8                            4.0  flower4.jpg         NaN   \n",
       "\n",
       "   demo_encoding_response.rt demo_encoding_response.keys  index  \\\n",
       "0                        NaN                         NaN   12.0   \n",
       "1                        NaN                         NaN   13.0   \n",
       "2                     1.6953                        left   14.0   \n",
       "3                        NaN                         NaN   15.0   \n",
       "4                        NaN                         NaN   16.0   \n",
       "\n",
       "  demo_test_response.keys  demo_test_response.corr  demo_test_response.rt  \\\n",
       "0                    left                      1.0                 2.8031   \n",
       "1                    left                      0.0                 3.7117   \n",
       "2                    left                      1.0                 2.2200   \n",
       "3                    left                      1.0                 1.4288   \n",
       "4                   right                      1.0                 1.8950   \n",
       "\n",
       "   demo_test_loop.thisTrialN        DemoImage1        DemoImage2  \\\n",
       "0                        0.0       flower1.jpg  flower1_pair.jpg   \n",
       "1                        1.0  flower2_pair.jpg       flower2.jpg   \n",
       "2                        2.0       flower3.jpg  flower3_pair.jpg   \n",
       "3                        3.0       flower4.jpg  flower4_pair.jpg   \n",
       "4                        4.0  flower5_pair.jpg       flower5.jpg   \n",
       "\n",
       "  DemoCorrectTest         subject  \n",
       "0            left  A11F3MA5FWH6SJ  \n",
       "1           right  A11F3MA5FWH6SJ  \n",
       "2            left  A11F3MA5FWH6SJ  \n",
       "3            left  A11F3MA5FWH6SJ  \n",
       "4           right  A11F3MA5FWH6SJ  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects_demo_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_encoding_response.keys</th>\n",
       "      <th>test_encoding_response.corr</th>\n",
       "      <th>trials.thisTrialN</th>\n",
       "      <th>target_image</th>\n",
       "      <th>pair</th>\n",
       "      <th>layer</th>\n",
       "      <th>correct</th>\n",
       "      <th>test_encoding_response.rt</th>\n",
       "      <th>key_resp_end.keys</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STRIPPED_SWALLOW_1.jpg</td>\n",
       "      <td>MAGPIE_GOOSE_4.jpg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BALI_STARLING_1.jpg</td>\n",
       "      <td>IBERIAN_MAGPIE_1.jpg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>RUBY_THROATED_HUMMINGBIRD_3.jpg</td>\n",
       "      <td>MYNA_5.jpg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>LARK_BUNTING_2.jpg</td>\n",
       "      <td>PEACOCK_1.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HAWAIIAN_GOOSE_4.jpg</td>\n",
       "      <td>HIMALAYAN_MONAL_2.jpg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index test_encoding_response.keys  test_encoding_response.corr  \\\n",
       "0     20                         NaN                          1.0   \n",
       "1     21                         NaN                          1.0   \n",
       "2     22                         NaN                          1.0   \n",
       "3     23                         NaN                          1.0   \n",
       "4     24                         NaN                          1.0   \n",
       "\n",
       "   trials.thisTrialN                     target_image                   pair  \\\n",
       "0                0.0           STRIPPED_SWALLOW_1.jpg     MAGPIE_GOOSE_4.jpg   \n",
       "1                1.0              BALI_STARLING_1.jpg   IBERIAN_MAGPIE_1.jpg   \n",
       "2                2.0  RUBY_THROATED_HUMMINGBIRD_3.jpg             MYNA_5.jpg   \n",
       "3                3.0               LARK_BUNTING_2.jpg          PEACOCK_1.jpg   \n",
       "4                4.0             HAWAIIAN_GOOSE_4.jpg  HIMALAYAN_MONAL_2.jpg   \n",
       "\n",
       "   layer correct  test_encoding_response.rt key_resp_end.keys         subject  \n",
       "0    2.0     NaN                        NaN               NaN  A11F3MA5FWH6SJ  \n",
       "1    3.0     NaN                        NaN               NaN  A11F3MA5FWH6SJ  \n",
       "2    2.0     NaN                        NaN               NaN  A11F3MA5FWH6SJ  \n",
       "3    1.0     NaN                        NaN               NaN  A11F3MA5FWH6SJ  \n",
       "4    2.0     NaN                        NaN               NaN  A11F3MA5FWH6SJ  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects_encoding_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>correct</th>\n",
       "      <th>test_test_response.keys</th>\n",
       "      <th>test_test_response.corr</th>\n",
       "      <th>test_test_response.rt</th>\n",
       "      <th>trials_2.thisRepN</th>\n",
       "      <th>trials_2.thisTrialN</th>\n",
       "      <th>trials_2.thisN</th>\n",
       "      <th>trials_2.thisIndex</th>\n",
       "      <th>trials_2.ran</th>\n",
       "      <th>image1</th>\n",
       "      <th>image2</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.1472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GYRFALCON_1.jpg</td>\n",
       "      <td>OSTRICH_1.jpg</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ASIAN_DOLLARD_BIRD_2.jpg</td>\n",
       "      <td>VIOLET_GREEN_SWALLOW_4.jpg</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.9381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KIWI_3.jpg</td>\n",
       "      <td>ARARIPE_MANAKIN_4.jpg</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CASSOWARY_1.jpg</td>\n",
       "      <td>SCARLET_MACAW_1.jpg</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALPINE_CHOUGH_4.jpg</td>\n",
       "      <td>BOBOLINK_3.jpg</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer correct test_test_response.keys  test_test_response.corr  \\\n",
       "0    1.0    left                    left                      1.0   \n",
       "1    3.0    left                    left                      1.0   \n",
       "2    1.0   right                   right                      1.0   \n",
       "3    2.0    left                    left                      1.0   \n",
       "4    3.0    left                   right                      0.0   \n",
       "\n",
       "   test_test_response.rt  trials_2.thisRepN  trials_2.thisTrialN  \\\n",
       "0                 6.1472                0.0                  0.0   \n",
       "1                 1.8693                0.0                  1.0   \n",
       "2                 2.9381                0.0                  2.0   \n",
       "3                 3.6978                0.0                  3.0   \n",
       "4                 1.7443                0.0                  4.0   \n",
       "\n",
       "   trials_2.thisN  trials_2.thisIndex  trials_2.ran                    image1  \\\n",
       "0             0.0                 0.0           1.0           GYRFALCON_1.jpg   \n",
       "1             1.0                 1.0           1.0  ASIAN_DOLLARD_BIRD_2.jpg   \n",
       "2             2.0                 2.0           1.0                KIWI_3.jpg   \n",
       "3             3.0                 3.0           1.0           CASSOWARY_1.jpg   \n",
       "4             4.0                 4.0           1.0       ALPINE_CHOUGH_4.jpg   \n",
       "\n",
       "                       image2         subject  \n",
       "0               OSTRICH_1.jpg  A11F3MA5FWH6SJ  \n",
       "1  VIOLET_GREEN_SWALLOW_4.jpg  A11F3MA5FWH6SJ  \n",
       "2       ARARIPE_MANAKIN_4.jpg  A11F3MA5FWH6SJ  \n",
       "3         SCARLET_MACAW_1.jpg  A11F3MA5FWH6SJ  \n",
       "4              BOBOLINK_3.jpg  A11F3MA5FWH6SJ  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects_test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11F3MA5FWH6SJ</th>\n",
       "      <td>1.6953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.201833</td>\n",
       "      <td>3.711700</td>\n",
       "      <td>1.899860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1DZMZTXWOM9MR</th>\n",
       "      <td>0.4941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.277317</td>\n",
       "      <td>2.501200</td>\n",
       "      <td>2.165375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1FJGB5JLZ81XB</th>\n",
       "      <td>1.7127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.733967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.733967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OM5NWYYYJKQW</th>\n",
       "      <td>0.6385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.915917</td>\n",
       "      <td>2.775400</td>\n",
       "      <td>1.744020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1PHDT66U6IK4Q</th>\n",
       "      <td>0.7481</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>7.267867</td>\n",
       "      <td>9.103700</td>\n",
       "      <td>6.900700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1QT3YA7G8MO63</th>\n",
       "      <td>1.0597</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.551917</td>\n",
       "      <td>1.217300</td>\n",
       "      <td>1.886533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1SNC8UL8YFRH5</th>\n",
       "      <td>0.6413</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.468867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.468867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1TKZIBGTP7FE8</th>\n",
       "      <td>1.7873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.854383</td>\n",
       "      <td>1.621800</td>\n",
       "      <td>1.900900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A25PFSORDO3SWQ</th>\n",
       "      <td>0.6970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.491833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.491833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2IP3ZAFYGV8M9</th>\n",
       "      <td>0.5430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.553317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.553317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>0.6492</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.756800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.756800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2VLTSW6CXIUMR</th>\n",
       "      <td>0.5889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.188183</td>\n",
       "      <td>1.493000</td>\n",
       "      <td>2.535775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2YVQKJX3FO6P</th>\n",
       "      <td>0.8810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.537333</td>\n",
       "      <td>2.273333</td>\n",
       "      <td>2.801333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A39VAFCIGP83ER</th>\n",
       "      <td>1.9865</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.386050</td>\n",
       "      <td>2.732267</td>\n",
       "      <td>2.039833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3ATB5GC4BQIH0</th>\n",
       "      <td>1.0530</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5.599500</td>\n",
       "      <td>10.525000</td>\n",
       "      <td>3.136750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3BU8UL4W258UU</th>\n",
       "      <td>0.5040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.080667</td>\n",
       "      <td>3.154000</td>\n",
       "      <td>1.866000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3CH1Z6J9R38G9</th>\n",
       "      <td>0.4123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.319450</td>\n",
       "      <td>1.480133</td>\n",
       "      <td>1.158767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3KP8KFGG6734Q</th>\n",
       "      <td>1.0667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.486650</td>\n",
       "      <td>1.662100</td>\n",
       "      <td>2.651560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3SKE5B27HLVO6</th>\n",
       "      <td>0.9220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5.815333</td>\n",
       "      <td>7.733750</td>\n",
       "      <td>1.978500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A7VA2Y4H6U31O</th>\n",
       "      <td>0.6330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.786550</td>\n",
       "      <td>3.435600</td>\n",
       "      <td>2.656740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A9YPM325MKYLO</th>\n",
       "      <td>1.8896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.257900</td>\n",
       "      <td>3.288640</td>\n",
       "      <td>3.104200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAF1SJ9FCBF75</th>\n",
       "      <td>0.8860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.442833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.442833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACGGIBC0P38HU</th>\n",
       "      <td>1.5020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.393500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.393500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGZ3QJFK1BR8V</th>\n",
       "      <td>1.0110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.207000</td>\n",
       "      <td>2.594000</td>\n",
       "      <td>2.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARR9GKAG3JFE5</th>\n",
       "      <td>1.1300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.193667</td>\n",
       "      <td>2.670667</td>\n",
       "      <td>1.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXPZAP62ZYWP8</th>\n",
       "      <td>0.7595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.548283</td>\n",
       "      <td>1.399800</td>\n",
       "      <td>1.577980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A11F3MA5FWH6SJ         1.6953                 1.0            0.833333   \n",
       "A1DZMZTXWOM9MR         0.4941                 1.0            0.666667   \n",
       "A1FJGB5JLZ81XB         1.7127                 1.0            1.000000   \n",
       "A1OM5NWYYYJKQW         0.6385                 1.0            0.833333   \n",
       "A1PHDT66U6IK4Q         0.7481                 1.0            0.833333   \n",
       "A1QT3YA7G8MO63         1.0597                 1.0            0.500000   \n",
       "A1SNC8UL8YFRH5         0.6413                 1.0            1.000000   \n",
       "A1TKZIBGTP7FE8         1.7873                 1.0            0.833333   \n",
       "A25PFSORDO3SWQ         0.6970                 1.0            1.000000   \n",
       "A2IP3ZAFYGV8M9         0.5430                 1.0            1.000000   \n",
       "A2M183CETUMR96         0.6492                 1.0            1.000000   \n",
       "A2VLTSW6CXIUMR         0.5889                 1.0            0.666667   \n",
       "A2YVQKJX3FO6P          0.8810                 1.0            0.500000   \n",
       "A39VAFCIGP83ER         1.9865                 1.0            0.500000   \n",
       "A3ATB5GC4BQIH0         1.0530                 1.0            0.666667   \n",
       "A3BU8UL4W258UU         0.5040                 1.0            0.833333   \n",
       "A3CH1Z6J9R38G9         0.4123                 1.0            0.500000   \n",
       "A3KP8KFGG6734Q         1.0667                 1.0            0.833333   \n",
       "A3SKE5B27HLVO6         0.9220                 1.0            0.333333   \n",
       "A7VA2Y4H6U31O          0.6330                 1.0            0.833333   \n",
       "A9YPM325MKYLO          1.8896                 1.0            0.166667   \n",
       "AAF1SJ9FCBF75          0.8860                 1.0            1.000000   \n",
       "ACGGIBC0P38HU          1.5020                 1.0            1.000000   \n",
       "AGZ3QJFK1BR8V          1.0110                 1.0            0.666667   \n",
       "ARR9GKAG3JFE5          1.1300                 1.0            0.500000   \n",
       "AXPZAP62ZYWP8          0.7595                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A11F3MA5FWH6SJ              2.201833                3.711700   \n",
       "A1DZMZTXWOM9MR              2.277317                2.501200   \n",
       "A1FJGB5JLZ81XB              2.733967                     NaN   \n",
       "A1OM5NWYYYJKQW              1.915917                2.775400   \n",
       "A1PHDT66U6IK4Q              7.267867                9.103700   \n",
       "A1QT3YA7G8MO63              1.551917                1.217300   \n",
       "A1SNC8UL8YFRH5              2.468867                     NaN   \n",
       "A1TKZIBGTP7FE8              1.854383                1.621800   \n",
       "A25PFSORDO3SWQ              2.491833                     NaN   \n",
       "A2IP3ZAFYGV8M9              1.553317                     NaN   \n",
       "A2M183CETUMR96              2.756800                     NaN   \n",
       "A2VLTSW6CXIUMR              2.188183                1.493000   \n",
       "A2YVQKJX3FO6P               2.537333                2.273333   \n",
       "A39VAFCIGP83ER              2.386050                2.732267   \n",
       "A3ATB5GC4BQIH0              5.599500               10.525000   \n",
       "A3BU8UL4W258UU              2.080667                3.154000   \n",
       "A3CH1Z6J9R38G9              1.319450                1.480133   \n",
       "A3KP8KFGG6734Q              2.486650                1.662100   \n",
       "A3SKE5B27HLVO6              5.815333                7.733750   \n",
       "A7VA2Y4H6U31O               2.786550                3.435600   \n",
       "A9YPM325MKYLO               3.257900                3.288640   \n",
       "AAF1SJ9FCBF75               5.442833                     NaN   \n",
       "ACGGIBC0P38HU               2.393500                     NaN   \n",
       "AGZ3QJFK1BR8V               2.207000                2.594000   \n",
       "ARR9GKAG3JFE5               2.193667                2.670667   \n",
       "AXPZAP62ZYWP8               1.548283                1.399800   \n",
       "\n",
       "                demo_RT_correct_mean  \n",
       "A11F3MA5FWH6SJ              1.899860  \n",
       "A1DZMZTXWOM9MR              2.165375  \n",
       "A1FJGB5JLZ81XB              2.733967  \n",
       "A1OM5NWYYYJKQW              1.744020  \n",
       "A1PHDT66U6IK4Q              6.900700  \n",
       "A1QT3YA7G8MO63              1.886533  \n",
       "A1SNC8UL8YFRH5              2.468867  \n",
       "A1TKZIBGTP7FE8              1.900900  \n",
       "A25PFSORDO3SWQ              2.491833  \n",
       "A2IP3ZAFYGV8M9              1.553317  \n",
       "A2M183CETUMR96              2.756800  \n",
       "A2VLTSW6CXIUMR              2.535775  \n",
       "A2YVQKJX3FO6P               2.801333  \n",
       "A39VAFCIGP83ER              2.039833  \n",
       "A3ATB5GC4BQIH0              3.136750  \n",
       "A3BU8UL4W258UU              1.866000  \n",
       "A3CH1Z6J9R38G9              1.158767  \n",
       "A3KP8KFGG6734Q              2.651560  \n",
       "A3SKE5B27HLVO6              1.978500  \n",
       "A7VA2Y4H6U31O               2.656740  \n",
       "A9YPM325MKYLO               3.104200  \n",
       "AAF1SJ9FCBF75               5.442833  \n",
       "ACGGIBC0P38HU               2.393500  \n",
       "AGZ3QJFK1BR8V               2.013500  \n",
       "ARR9GKAG3JFE5               1.716667  \n",
       "AXPZAP62ZYWP8               1.577980  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this section extract information from the demo phase: it creates a df (all_subjects_summary_demo_info) containingsingle row per participants with metrics from the demo phase (average accuracy, RTs and so on (this can be used to screen participatns for further analysis)):\n",
    "all_subjects_summary_demo_info=pd.DataFrame(index=list(all_subjects_demo_df['subject'].unique()))\n",
    "\n",
    "for cur_subject in all_subjects_demo_df['subject'].unique():\n",
    "    cur_sub_demo_encoding=all_subjects_demo_df.loc[all_subjects_demo_df['subject']==cur_subject]\n",
    "    \n",
    "    #get only attention check related info: \n",
    "    curr_subjects_summary_demo_info=cur_sub_demo_encoding[['demo_encoding_response.keys','DemoCorrect','demo_encoding_response.rt']].copy().dropna()\n",
    "    if len(curr_subjects_summary_demo_info)==0: #empty - the participant didnt respond on the arrow at all: \n",
    "       all_subjects_summary_demo_info.loc[cur_subject,'arrow_correct']=0 \n",
    "       all_subjects_summary_demo_info.loc[cur_subject,'arrow_rt']=np.nan\n",
    "    else: \n",
    "        all_subjects_summary_demo_info.loc[cur_subject,'arrow_rt']=curr_subjects_summary_demo_info['demo_encoding_response.rt'].values\n",
    "        if all(curr_subjects_summary_demo_info['DemoCorrect']==curr_subjects_summary_demo_info['demo_encoding_response.keys']):\n",
    "            all_subjects_summary_demo_info.loc[cur_subject,'arrow_correct']=1\n",
    "        else:\n",
    "            all_subjects_summary_demo_info.loc[cur_subject,'arrow_correct']=0\n",
    "\n",
    "\n",
    "    #get the correctness of the demo testing phase: \n",
    "    cur_sub_demo_test_performence=cur_sub_demo_encoding[['DemoCorrectTest','demo_test_response.keys','demo_test_response.rt']].copy().dropna()\n",
    "    test_match_df=pd.DataFrame(columns=['arrow_correct'],data=cur_sub_demo_test_performence['DemoCorrectTest']==cur_sub_demo_test_performence['demo_test_response.keys'])\n",
    "    test_match_df['demo_test_response.rt']=cur_sub_demo_test_performence['demo_test_response.rt']\n",
    "    accuracy=test_match_df['arrow_correct'].mean()\n",
    "    mean_rt=test_match_df['demo_test_response.rt'].mean()\n",
    "    correct_and_incorrect_rts=test_match_df.groupby('arrow_correct').aggregate({'demo_test_response.rt':'mean'})\n",
    "    #update the summary info row: \n",
    "    all_subjects_summary_demo_info.loc[cur_subject,'demo_accuracy']=accuracy\n",
    "    all_subjects_summary_demo_info.loc[cur_subject,'RT_overall_mean']=mean_rt\n",
    "    all_subjects_summary_demo_info.loc[cur_subject,['RT_incorrect_mean','RT_correct_mean']]=np.nan\n",
    "\n",
    "    if False in correct_and_incorrect_rts.index:\n",
    "        all_subjects_summary_demo_info.loc[cur_subject,'RT_incorrect_mean']=correct_and_incorrect_rts.loc[False].values[0]\n",
    "    if True in correct_and_incorrect_rts.index:\n",
    "        all_subjects_summary_demo_info.loc[cur_subject,'RT_correct_mean']=correct_and_incorrect_rts.loc[True].values[0]\n",
    "\n",
    "\n",
    "#add a prefix to column names: \n",
    "all_subjects_summary_demo_info.columns=['demo_'+col for col in all_subjects_summary_demo_info.columns]\n",
    "all_subjects_summary_demo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11F3MA5FWH6SJ</th>\n",
       "      <td>1.200720</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1DZMZTXWOM9MR</th>\n",
       "      <td>0.553540</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1FJGB5JLZ81XB</th>\n",
       "      <td>1.530060</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OM5NWYYYJKQW</th>\n",
       "      <td>0.609960</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1PHDT66U6IK4Q</th>\n",
       "      <td>0.651920</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1QT3YA7G8MO63</th>\n",
       "      <td>0.879575</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1SNC8UL8YFRH5</th>\n",
       "      <td>0.595680</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1TKZIBGTP7FE8</th>\n",
       "      <td>1.713640</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A25PFSORDO3SWQ</th>\n",
       "      <td>0.590200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2IP3ZAFYGV8M9</th>\n",
       "      <td>0.646680</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>0.497520</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2VLTSW6CXIUMR</th>\n",
       "      <td>0.516100</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2YVQKJX3FO6P</th>\n",
       "      <td>0.867600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A39VAFCIGP83ER</th>\n",
       "      <td>0.965040</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3ATB5GC4BQIH0</th>\n",
       "      <td>0.921200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3BU8UL4W258UU</th>\n",
       "      <td>0.492000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3CH1Z6J9R38G9</th>\n",
       "      <td>0.534320</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3KP8KFGG6734Q</th>\n",
       "      <td>0.794800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3SKE5B27HLVO6</th>\n",
       "      <td>1.537400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A7VA2Y4H6U31O</th>\n",
       "      <td>0.525860</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A9YPM325MKYLO</th>\n",
       "      <td>1.256540</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAF1SJ9FCBF75</th>\n",
       "      <td>0.654800</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACGGIBC0P38HU</th>\n",
       "      <td>1.488800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGZ3QJFK1BR8V</th>\n",
       "      <td>1.155200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARR9GKAG3JFE5</th>\n",
       "      <td>1.574667</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXPZAP62ZYWP8</th>\n",
       "      <td>0.567080</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                encoding_arrow_mean_rt  encoding_arrow_accuracy\n",
       "A11F3MA5FWH6SJ                1.200720                      1.0\n",
       "A1DZMZTXWOM9MR                0.553540                      1.0\n",
       "A1FJGB5JLZ81XB                1.530060                      1.0\n",
       "A1OM5NWYYYJKQW                0.609960                      1.0\n",
       "A1PHDT66U6IK4Q                0.651920                      1.0\n",
       "A1QT3YA7G8MO63                0.879575                      0.8\n",
       "A1SNC8UL8YFRH5                0.595680                      1.0\n",
       "A1TKZIBGTP7FE8                1.713640                      1.0\n",
       "A25PFSORDO3SWQ                0.590200                      1.0\n",
       "A2IP3ZAFYGV8M9                0.646680                      1.0\n",
       "A2M183CETUMR96                0.497520                      1.0\n",
       "A2VLTSW6CXIUMR                0.516100                      0.8\n",
       "A2YVQKJX3FO6P                 0.867600                      1.0\n",
       "A39VAFCIGP83ER                0.965040                      1.0\n",
       "A3ATB5GC4BQIH0                0.921200                      1.0\n",
       "A3BU8UL4W258UU                0.492000                      1.0\n",
       "A3CH1Z6J9R38G9                0.534320                      0.8\n",
       "A3KP8KFGG6734Q                0.794800                      1.0\n",
       "A3SKE5B27HLVO6                1.537400                      1.0\n",
       "A7VA2Y4H6U31O                 0.525860                      1.0\n",
       "A9YPM325MKYLO                 1.256540                      1.0\n",
       "AAF1SJ9FCBF75                 0.654800                      0.8\n",
       "ACGGIBC0P38HU                 1.488800                      1.0\n",
       "AGZ3QJFK1BR8V                 1.155200                      1.0\n",
       "ARR9GKAG3JFE5                 1.574667                      0.6\n",
       "AXPZAP62ZYWP8                 0.567080                      1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this part extract summary information from the experiment encoding phase: attention check accuracy and timings: \n",
    "all_subjects_summary_encoding_info=pd.DataFrame(index=list(all_subjects_encoding_df['subject'].unique()))\n",
    "\n",
    "for cur_subject in all_subjects_encoding_df['subject'].unique():\n",
    "    cur_sub_encoding=all_subjects_encoding_df.loc[all_subjects_encoding_df['subject']==cur_subject]\n",
    "    \n",
    "    #get only attention check related info: \n",
    "    cur_sub_encoding=cur_sub_encoding[['test_encoding_response.keys','correct','test_encoding_response.rt']].copy().dropna(how = 'all')\n",
    "    if len(cur_sub_encoding)==0: #empty - the participant didnt respond on the arrow at all: \n",
    "       all_subjects_summary_encoding_info.loc[cur_subject,'arrow_accuracy']=0 \n",
    "       all_subjects_summary_encoding_info.loc[cur_subject,'arrow_mean_rt']=np.nan\n",
    "    else: \n",
    "        all_subjects_summary_encoding_info.loc[cur_subject,'arrow_mean_rt']=cur_sub_encoding['test_encoding_response.rt'].mean()\n",
    "        arrow_accuracy=(cur_sub_encoding['correct']==cur_sub_encoding['test_encoding_response.keys']).mean()\n",
    "        all_subjects_summary_encoding_info.loc[cur_subject,'arrow_accuracy']=arrow_accuracy\n",
    "\n",
    "\n",
    "\n",
    "#add a prefix to column names: \n",
    "all_subjects_summary_encoding_info.columns=['encoding_'+col for col in all_subjects_summary_encoding_info.columns]        \n",
    "all_subjects_summary_encoding_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>testing_RT_incorrect_mean</th>\n",
       "      <th>testing_RT_correct_mean</th>\n",
       "      <th>testing_layer_1_rt</th>\n",
       "      <th>testing_layer_1_accuracy</th>\n",
       "      <th>testing_layer_2_rt</th>\n",
       "      <th>testing_layer_2_accuracy</th>\n",
       "      <th>testing_layer_3_rt</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11F3MA5FWH6SJ</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>1.996455</td>\n",
       "      <td>2.024171</td>\n",
       "      <td>1.988020</td>\n",
       "      <td>2.252405</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.047725</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.689235</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1DZMZTXWOM9MR</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.044238</td>\n",
       "      <td>2.335260</td>\n",
       "      <td>1.986034</td>\n",
       "      <td>1.940875</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.122665</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.069175</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1FJGB5JLZ81XB</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>2.011600</td>\n",
       "      <td>2.293350</td>\n",
       "      <td>1.980294</td>\n",
       "      <td>2.044130</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.064860</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.925810</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OM5NWYYYJKQW</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.865277</td>\n",
       "      <td>1.954120</td>\n",
       "      <td>1.847508</td>\n",
       "      <td>1.978915</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.784820</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.832095</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1PHDT66U6IK4Q</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>3.402750</td>\n",
       "      <td>3.887212</td>\n",
       "      <td>3.328217</td>\n",
       "      <td>3.025835</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.630580</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.551835</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1QT3YA7G8MO63</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>2.179628</td>\n",
       "      <td>5.824137</td>\n",
       "      <td>4.566682</td>\n",
       "      <td>2.108613</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.419573</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1SNC8UL8YFRH5</th>\n",
       "      <td>0.950000</td>\n",
       "      <td>2.849197</td>\n",
       "      <td>5.251533</td>\n",
       "      <td>2.953868</td>\n",
       "      <td>2.531735</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.024775</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.998547</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1TKZIBGTP7FE8</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.991212</td>\n",
       "      <td>2.189186</td>\n",
       "      <td>1.797717</td>\n",
       "      <td>0.750100</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.256275</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.919040</td>\n",
       "      <td>0.45</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A25PFSORDO3SWQ</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>3.455526</td>\n",
       "      <td>6.371400</td>\n",
       "      <td>3.391540</td>\n",
       "      <td>2.568222</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4.338150</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.367053</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2IP3ZAFYGV8M9</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.459743</td>\n",
       "      <td>3.212108</td>\n",
       "      <td>2.271652</td>\n",
       "      <td>1.919185</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.397835</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.062210</td>\n",
       "      <td>0.80</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>3.395992</td>\n",
       "      <td>8.932178</td>\n",
       "      <td>4.735722</td>\n",
       "      <td>2.910815</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.436135</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3.677235</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2VLTSW6CXIUMR</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>2.576651</td>\n",
       "      <td>6.455925</td>\n",
       "      <td>4.265116</td>\n",
       "      <td>2.277589</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.048544</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.436055</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2YVQKJX3FO6P</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>2.029552</td>\n",
       "      <td>4.448885</td>\n",
       "      <td>2.122971</td>\n",
       "      <td>1.884474</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.110789</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.090200</td>\n",
       "      <td>0.65</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A39VAFCIGP83ER</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.386998</td>\n",
       "      <td>4.620622</td>\n",
       "      <td>7.244532</td>\n",
       "      <td>1.586317</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.274412</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.281918</td>\n",
       "      <td>0.30</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3ATB5GC4BQIH0</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>2.528883</td>\n",
       "      <td>2.190962</td>\n",
       "      <td>2.787294</td>\n",
       "      <td>2.360500</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.264600</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.961550</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3BU8UL4W258UU</th>\n",
       "      <td>0.883333</td>\n",
       "      <td>1.727167</td>\n",
       "      <td>1.518571</td>\n",
       "      <td>1.754717</td>\n",
       "      <td>1.580650</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.772500</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.828350</td>\n",
       "      <td>0.75</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3CH1Z6J9R38G9</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.072950</td>\n",
       "      <td>2.138444</td>\n",
       "      <td>2.044881</td>\n",
       "      <td>1.666555</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.488935</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.063360</td>\n",
       "      <td>0.70</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3KP8KFGG6734Q</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>3.296161</td>\n",
       "      <td>3.560283</td>\n",
       "      <td>3.359219</td>\n",
       "      <td>3.346635</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.184058</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3.352185</td>\n",
       "      <td>0.70</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3SKE5B27HLVO6</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.186576</td>\n",
       "      <td>1.165469</td>\n",
       "      <td>3.284714</td>\n",
       "      <td>1.594050</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.930550</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.027158</td>\n",
       "      <td>0.35</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A7VA2Y4H6U31O</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.886758</td>\n",
       "      <td>3.178275</td>\n",
       "      <td>2.813879</td>\n",
       "      <td>2.498670</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.968625</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.192980</td>\n",
       "      <td>0.90</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A9YPM325MKYLO</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>2.770224</td>\n",
       "      <td>3.618560</td>\n",
       "      <td>3.031076</td>\n",
       "      <td>2.587983</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.981685</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.722780</td>\n",
       "      <td>0.85</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAF1SJ9FCBF75</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>4.622000</td>\n",
       "      <td>11.600500</td>\n",
       "      <td>5.643500</td>\n",
       "      <td>5.164933</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.767941</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5.047000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACGGIBC0P38HU</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>3.626967</td>\n",
       "      <td>4.087800</td>\n",
       "      <td>3.473356</td>\n",
       "      <td>3.687350</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.229050</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.964500</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGZ3QJFK1BR8V</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.188233</td>\n",
       "      <td>0.045533</td>\n",
       "      <td>0.223550</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARR9GKAG3JFE5</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>2.778034</td>\n",
       "      <td>2.802258</td>\n",
       "      <td>3.989345</td>\n",
       "      <td>2.737150</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.769158</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.827350</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXPZAP62ZYWP8</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.050918</td>\n",
       "      <td>1.017580</td>\n",
       "      <td>1.074731</td>\n",
       "      <td>1.016435</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.033115</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.103205</td>\n",
       "      <td>0.55</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                testing_Test_overall_accuracy  testing_RT_overall_mean  \\\n",
       "A11F3MA5FWH6SJ                       0.766667                 1.996455   \n",
       "A1DZMZTXWOM9MR                       0.833333                 2.044238   \n",
       "A1FJGB5JLZ81XB                       0.900000                 2.011600   \n",
       "A1OM5NWYYYJKQW                       0.833333                 1.865277   \n",
       "A1PHDT66U6IK4Q                       0.866667                 3.402750   \n",
       "A1QT3YA7G8MO63                       0.550000                 2.179628   \n",
       "A1SNC8UL8YFRH5                       0.950000                 2.849197   \n",
       "A1TKZIBGTP7FE8                       0.400000                 0.991212   \n",
       "A25PFSORDO3SWQ                       0.833333                 3.455526   \n",
       "A2IP3ZAFYGV8M9                       0.800000                 2.459743   \n",
       "A2M183CETUMR96                       0.850000                 3.395992   \n",
       "A2VLTSW6CXIUMR                       0.733333                 2.576651   \n",
       "A2YVQKJX3FO6P                        0.566667                 2.029552   \n",
       "A39VAFCIGP83ER                       0.466667                 1.386998   \n",
       "A3ATB5GC4BQIH0                       0.566667                 2.528883   \n",
       "A3BU8UL4W258UU                       0.883333                 1.727167   \n",
       "A3CH1Z6J9R38G9                       0.700000                 2.072950   \n",
       "A3KP8KFGG6734Q                       0.700000                 3.296161   \n",
       "A3SKE5B27HLVO6                       0.466667                 1.186576   \n",
       "A7VA2Y4H6U31O                        0.800000                 2.886758   \n",
       "A9YPM325MKYLO                        0.916667                 2.770224   \n",
       "AAF1SJ9FCBF75                        0.766667                 4.622000   \n",
       "ACGGIBC0P38HU                        0.750000                 3.626967   \n",
       "AGZ3QJFK1BR8V                        0.500000                 0.116883   \n",
       "ARR9GKAG3JFE5                        0.483333                 2.778034   \n",
       "AXPZAP62ZYWP8                        0.583333                 1.050918   \n",
       "\n",
       "                testing_RT_incorrect_mean  testing_RT_correct_mean  \\\n",
       "A11F3MA5FWH6SJ                   2.024171                 1.988020   \n",
       "A1DZMZTXWOM9MR                   2.335260                 1.986034   \n",
       "A1FJGB5JLZ81XB                   2.293350                 1.980294   \n",
       "A1OM5NWYYYJKQW                   1.954120                 1.847508   \n",
       "A1PHDT66U6IK4Q                   3.887212                 3.328217   \n",
       "A1QT3YA7G8MO63                   5.824137                 4.566682   \n",
       "A1SNC8UL8YFRH5                   5.251533                 2.953868   \n",
       "A1TKZIBGTP7FE8                   2.189186                 1.797717   \n",
       "A25PFSORDO3SWQ                   6.371400                 3.391540   \n",
       "A2IP3ZAFYGV8M9                   3.212108                 2.271652   \n",
       "A2M183CETUMR96                   8.932178                 4.735722   \n",
       "A2VLTSW6CXIUMR                   6.455925                 4.265116   \n",
       "A2YVQKJX3FO6P                    4.448885                 2.122971   \n",
       "A39VAFCIGP83ER                   4.620622                 7.244532   \n",
       "A3ATB5GC4BQIH0                   2.190962                 2.787294   \n",
       "A3BU8UL4W258UU                   1.518571                 1.754717   \n",
       "A3CH1Z6J9R38G9                   2.138444                 2.044881   \n",
       "A3KP8KFGG6734Q                   3.560283                 3.359219   \n",
       "A3SKE5B27HLVO6                   1.165469                 3.284714   \n",
       "A7VA2Y4H6U31O                    3.178275                 2.813879   \n",
       "A9YPM325MKYLO                    3.618560                 3.031076   \n",
       "AAF1SJ9FCBF75                   11.600500                 5.643500   \n",
       "ACGGIBC0P38HU                    4.087800                 3.473356   \n",
       "AGZ3QJFK1BR8V                    0.188233                 0.045533   \n",
       "ARR9GKAG3JFE5                    2.802258                 3.989345   \n",
       "AXPZAP62ZYWP8                    1.017580                 1.074731   \n",
       "\n",
       "                testing_layer_1_rt  testing_layer_1_accuracy  \\\n",
       "A11F3MA5FWH6SJ            2.252405                      0.85   \n",
       "A1DZMZTXWOM9MR            1.940875                      0.65   \n",
       "A1FJGB5JLZ81XB            2.044130                      1.00   \n",
       "A1OM5NWYYYJKQW            1.978915                      0.75   \n",
       "A1PHDT66U6IK4Q            3.025835                      0.85   \n",
       "A1QT3YA7G8MO63            2.108613                      0.75   \n",
       "A1SNC8UL8YFRH5            2.531735                      0.95   \n",
       "A1TKZIBGTP7FE8            0.750100                      0.30   \n",
       "A25PFSORDO3SWQ            2.568222                      0.95   \n",
       "A2IP3ZAFYGV8M9            1.919185                      0.85   \n",
       "A2M183CETUMR96            2.910815                      0.75   \n",
       "A2VLTSW6CXIUMR            2.277589                      0.65   \n",
       "A2YVQKJX3FO6P             1.884474                      0.65   \n",
       "A39VAFCIGP83ER            1.586317                      0.50   \n",
       "A3ATB5GC4BQIH0            2.360500                      0.55   \n",
       "A3BU8UL4W258UU            1.580650                      0.90   \n",
       "A3CH1Z6J9R38G9            1.666555                      0.80   \n",
       "A3KP8KFGG6734Q            3.346635                      0.85   \n",
       "A3SKE5B27HLVO6            1.594050                      0.30   \n",
       "A7VA2Y4H6U31O             2.498670                      0.80   \n",
       "A9YPM325MKYLO             2.587983                      1.00   \n",
       "AAF1SJ9FCBF75             5.164933                      0.70   \n",
       "ACGGIBC0P38HU             3.687350                      0.80   \n",
       "AGZ3QJFK1BR8V             0.223550                      0.55   \n",
       "ARR9GKAG3JFE5             2.737150                      0.45   \n",
       "AXPZAP62ZYWP8             1.016435                      0.60   \n",
       "\n",
       "                testing_layer_2_rt  testing_layer_2_accuracy  \\\n",
       "A11F3MA5FWH6SJ            2.047725                      0.80   \n",
       "A1DZMZTXWOM9MR            2.122665                      1.00   \n",
       "A1FJGB5JLZ81XB            2.064860                      0.80   \n",
       "A1OM5NWYYYJKQW            1.784820                      0.90   \n",
       "A1PHDT66U6IK4Q            3.630580                      0.85   \n",
       "A1QT3YA7G8MO63            2.050000                      0.45   \n",
       "A1SNC8UL8YFRH5            3.024775                      0.95   \n",
       "A1TKZIBGTP7FE8            1.256275                      0.45   \n",
       "A25PFSORDO3SWQ            4.338150                      0.70   \n",
       "A2IP3ZAFYGV8M9            2.397835                      0.75   \n",
       "A2M183CETUMR96            3.436135                      0.90   \n",
       "A2VLTSW6CXIUMR            3.048544                      0.75   \n",
       "A2YVQKJX3FO6P             2.110789                      0.40   \n",
       "A39VAFCIGP83ER            1.274412                      0.60   \n",
       "A3ATB5GC4BQIH0            2.264600                      0.60   \n",
       "A3BU8UL4W258UU            1.772500                      1.00   \n",
       "A3CH1Z6J9R38G9            2.488935                      0.60   \n",
       "A3KP8KFGG6734Q            3.184058                      0.55   \n",
       "A3SKE5B27HLVO6            0.930550                      0.75   \n",
       "A7VA2Y4H6U31O             2.968625                      0.70   \n",
       "A9YPM325MKYLO             2.981685                      0.90   \n",
       "AAF1SJ9FCBF75             3.767941                      0.90   \n",
       "ACGGIBC0P38HU             3.229050                      0.70   \n",
       "AGZ3QJFK1BR8V             0.043100                      0.45   \n",
       "ARR9GKAG3JFE5             2.769158                      0.50   \n",
       "AXPZAP62ZYWP8             1.033115                      0.60   \n",
       "\n",
       "                testing_layer_3_rt  testing_layer_3_accuracy  \\\n",
       "A11F3MA5FWH6SJ            1.689235                      0.65   \n",
       "A1DZMZTXWOM9MR            2.069175                      0.85   \n",
       "A1FJGB5JLZ81XB            1.925810                      0.90   \n",
       "A1OM5NWYYYJKQW            1.832095                      0.85   \n",
       "A1PHDT66U6IK4Q            3.551835                      0.90   \n",
       "A1QT3YA7G8MO63            2.419573                      0.45   \n",
       "A1SNC8UL8YFRH5            2.998547                      0.95   \n",
       "A1TKZIBGTP7FE8            0.919040                      0.45   \n",
       "A25PFSORDO3SWQ            3.367053                      0.85   \n",
       "A2IP3ZAFYGV8M9            3.062210                      0.80   \n",
       "A2M183CETUMR96            3.677235                      0.90   \n",
       "A2VLTSW6CXIUMR            2.436055                      0.80   \n",
       "A2YVQKJX3FO6P             2.090200                      0.65   \n",
       "A39VAFCIGP83ER            1.281918                      0.30   \n",
       "A3ATB5GC4BQIH0            2.961550                      0.55   \n",
       "A3BU8UL4W258UU            1.828350                      0.75   \n",
       "A3CH1Z6J9R38G9            2.063360                      0.70   \n",
       "A3KP8KFGG6734Q            3.352185                      0.70   \n",
       "A3SKE5B27HLVO6            1.027158                      0.35   \n",
       "A7VA2Y4H6U31O             3.192980                      0.90   \n",
       "A9YPM325MKYLO             2.722780                      0.85   \n",
       "AAF1SJ9FCBF75             5.047000                      0.70   \n",
       "ACGGIBC0P38HU             3.964500                      0.75   \n",
       "AGZ3QJFK1BR8V             0.084000                      0.50   \n",
       "ARR9GKAG3JFE5             2.827350                      0.50   \n",
       "AXPZAP62ZYWP8             1.103205                      0.55   \n",
       "\n",
       "                testing_longest_response_strike  \n",
       "A11F3MA5FWH6SJ                              4.0  \n",
       "A1DZMZTXWOM9MR                              5.0  \n",
       "A1FJGB5JLZ81XB                              6.0  \n",
       "A1OM5NWYYYJKQW                              5.0  \n",
       "A1PHDT66U6IK4Q                              4.0  \n",
       "A1QT3YA7G8MO63                              4.0  \n",
       "A1SNC8UL8YFRH5                              5.0  \n",
       "A1TKZIBGTP7FE8                              7.0  \n",
       "A25PFSORDO3SWQ                              4.0  \n",
       "A2IP3ZAFYGV8M9                              6.0  \n",
       "A2M183CETUMR96                              6.0  \n",
       "A2VLTSW6CXIUMR                              3.0  \n",
       "A2YVQKJX3FO6P                               5.0  \n",
       "A39VAFCIGP83ER                             13.0  \n",
       "A3ATB5GC4BQIH0                              3.0  \n",
       "A3BU8UL4W258UU                              6.0  \n",
       "A3CH1Z6J9R38G9                              6.0  \n",
       "A3KP8KFGG6734Q                              6.0  \n",
       "A3SKE5B27HLVO6                             11.0  \n",
       "A7VA2Y4H6U31O                               8.0  \n",
       "A9YPM325MKYLO                               6.0  \n",
       "AAF1SJ9FCBF75                               4.0  \n",
       "ACGGIBC0P38HU                               5.0  \n",
       "AGZ3QJFK1BR8V                               3.0  \n",
       "ARR9GKAG3JFE5                               4.0  \n",
       "AXPZAP62ZYWP8                               5.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this part extract summary information from the experiment testing phase: attention check accuracy and timings: \n",
    "all_subjects_summary_testing_info=pd.DataFrame(index=list(all_subjects_test_df['subject'].unique()))\n",
    "\n",
    "\n",
    "#this code calculates response time averages (RT) exlcusing the trials that are TOO long: \n",
    "trial_too_long_exclusion_criteria=10\n",
    "\n",
    "\n",
    "for cur_subject in all_subjects_test_df['subject'].unique():\n",
    "    cur_sub_testing=all_subjects_test_df.loc[all_subjects_test_df['subject']==cur_subject]\n",
    "\n",
    "    #get the correctness of the testing phase: \n",
    "    cur_sub_testing_performence=cur_sub_testing[['correct','test_test_response.keys','test_test_response.rt','layer','test_test_response.corr']].copy().dropna()\n",
    "\n",
    "\n",
    "    test_match_df=pd.DataFrame(columns=['correct'],data=cur_sub_testing_performence['correct']==cur_sub_testing_performence['test_test_response.keys'])\n",
    "    test_match_df['test_test_response.rt']=cur_sub_testing_performence['test_test_response.rt']\n",
    "    accuracy=test_match_df['correct'].mean()\n",
    "\n",
    "    # if there is one rt that is very long, lets not include it in the mean calculation \n",
    "    \n",
    "    mean_rt=(test_match_df.loc[test_match_df['test_test_response.rt']<=trial_too_long_exclusion_criteria,'test_test_response.rt']).mean()\n",
    "    correct_and_incorrect_rts_overall=test_match_df.groupby('correct').aggregate({'test_test_response.rt':'mean'})\n",
    "    \n",
    "    #update the summary info row: \n",
    "    all_subjects_summary_testing_info.loc[cur_subject,'Test_overall_accuracy']=accuracy\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,'RT_overall_mean']=mean_rt\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,['RT_incorrect_mean','RT_correct_mean']]=np.nan\n",
    "\n",
    "    if False in correct_and_incorrect_rts_overall.index:\n",
    "        all_subjects_summary_testing_info.loc[cur_subject,'RT_incorrect_mean']=correct_and_incorrect_rts_overall.loc[False].values[0]\n",
    "    if True in correct_and_incorrect_rts_overall.index:\n",
    "        all_subjects_summary_testing_info.loc[cur_subject,'RT_correct_mean']=correct_and_incorrect_rts_overall.loc[True].values[0]\n",
    "\n",
    "\n",
    "\n",
    "    #extract layer wise information (accuracy and rt):\n",
    "    cur_sub_testing_performence_copy=cur_sub_testing_performence.copy()\n",
    "    cur_sub_testing_performence_copy.loc[cur_sub_testing_performence_copy['test_test_response.rt']>trial_too_long_exclusion_criteria,'test_test_response.rt']=nan\n",
    "    correct_and_incorrect_rts=cur_sub_testing_performence_copy.groupby('layer').aggregate({'test_test_response.rt':'mean','test_test_response.corr':'mean'})\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,['layer_1_rt','layer_1_accuracy','layer_2_rt','layer_2_accuracy','layer_3_rt','layer_3_accuracy']]=correct_and_incorrect_rts.values.flatten()\n",
    "\n",
    "\n",
    "    #check the longest structured strike (to find bots or very unattentive participants):\n",
    "    responses=cur_sub_testing_performence['test_test_response.keys'].replace({'left':1,'right':2}).values\n",
    "    max_iter=find_largest_consequtive_repetition(responses)\n",
    "\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,'longest_response_strike']=max_iter\n",
    "\n",
    "#add a prefix to column names: \n",
    "all_subjects_summary_testing_info.columns=['testing_'+col for col in all_subjects_summary_testing_info.columns]        \n",
    "all_subjects_summary_testing_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>test_test_response.keys</th>\n",
       "      <th>test_test_response.rt</th>\n",
       "      <th>layer</th>\n",
       "      <th>test_test_response.corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.3672</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0474</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>0.9064</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0347</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.1509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.1402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.2994</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0686</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.9004</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>0.9939</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.8215</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.9447</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>0.9341</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.6534</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.5532</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.1674</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0342</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.3504</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.3287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0531</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.2105</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.2238</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>0.7081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.2418</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.4417</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.1941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.1591</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.8218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>0.8495</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>0.8925</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>0.8247</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>0.7942</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.1579</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.4864</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.4962</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.7903</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>0.9562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.4161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.1362</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.1711</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>0.7961</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>0.7197</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.1483</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.1005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.2401</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.8534</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>0.6422</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.5974</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     correct test_test_response.keys  test_test_response.rt  layer  \\\n",
       "1500   right                   right                 1.3672    1.0   \n",
       "1501    left                   right                 1.0474    3.0   \n",
       "1502    left                    left                 0.9064    3.0   \n",
       "1503   right                   right                 0.9375    1.0   \n",
       "1504    left                   right                 1.0347    3.0   \n",
       "1505   right                    left                 1.1509    1.0   \n",
       "1506   right                   right                 1.1402    1.0   \n",
       "1507    left                   right                 1.2994    3.0   \n",
       "1508   right                   right                 1.0686    2.0   \n",
       "1509    left                   right                 0.9004    3.0   \n",
       "1510    left                    left                 0.9939    3.0   \n",
       "1511   right                    left                 0.8215    2.0   \n",
       "1512    left                   right                 0.9447    3.0   \n",
       "1513    left                    left                 0.9341    3.0   \n",
       "1514    left                    left                 1.6534    3.0   \n",
       "1515    left                   right                 0.7614    3.0   \n",
       "1516   right                    left                 1.5532    2.0   \n",
       "1517   right                   right                 1.2835    1.0   \n",
       "1518   right                   right                 0.8005    1.0   \n",
       "1519    left                    left                 1.1674    2.0   \n",
       "1520   right                   right                 1.0342    2.0   \n",
       "1521    left                    left                 1.3504    2.0   \n",
       "1522   right                   right                 1.3287    2.0   \n",
       "1523   right                   right                 1.0531    3.0   \n",
       "1524    left                   right                 1.2105    3.0   \n",
       "1525    left                    left                 1.2238    3.0   \n",
       "1526    left                    left                 0.7081    2.0   \n",
       "1527   right                    left                 0.5850    1.0   \n",
       "1528   right                    left                 1.2418    2.0   \n",
       "1529    left                    left                 1.4417    3.0   \n",
       "1530   right                   right                 1.1941    1.0   \n",
       "1531    left                   right                 1.1591    1.0   \n",
       "1532    left                   right                 0.8218    1.0   \n",
       "1533   right                   right                 0.8495    1.0   \n",
       "1534    left                    left                 0.8925    3.0   \n",
       "1535   right                    left                 0.9688    2.0   \n",
       "1536    left                   right                 0.9830    1.0   \n",
       "1537    left                    left                 0.8247    3.0   \n",
       "1538    left                    left                 0.7942    1.0   \n",
       "1539    left                   right                 1.1579    1.0   \n",
       "1540    left                   right                 1.4864    3.0   \n",
       "1541   right                   right                 0.9643    1.0   \n",
       "1542   right                   right                 1.4962    2.0   \n",
       "1543    left                   right                 0.7903    2.0   \n",
       "1544   right                   right                 0.9562    1.0   \n",
       "1545    left                    left                 1.4161    2.0   \n",
       "1546    left                    left                 1.0520    1.0   \n",
       "1547    left                   right                 1.0400    1.0   \n",
       "1548   right                   right                 1.1362    3.0   \n",
       "1549    left                   right                 0.9913    1.0   \n",
       "1550   right                    left                 1.1711    3.0   \n",
       "1551   right                    left                 0.8681    2.0   \n",
       "1552   right                   right                 0.7961    2.0   \n",
       "1553   right                   right                 0.7197    2.0   \n",
       "1554    left                    left                 1.1483    3.0   \n",
       "1555    left                    left                 1.1005    1.0   \n",
       "1556   right                   right                 1.2401    2.0   \n",
       "1557   right                    left                 0.8534    2.0   \n",
       "1558    left                    left                 0.6422    2.0   \n",
       "1559    left                   right                 0.5974    2.0   \n",
       "\n",
       "      test_test_response.corr  \n",
       "1500                      1.0  \n",
       "1501                      0.0  \n",
       "1502                      1.0  \n",
       "1503                      1.0  \n",
       "1504                      0.0  \n",
       "1505                      0.0  \n",
       "1506                      1.0  \n",
       "1507                      0.0  \n",
       "1508                      1.0  \n",
       "1509                      0.0  \n",
       "1510                      1.0  \n",
       "1511                      0.0  \n",
       "1512                      0.0  \n",
       "1513                      1.0  \n",
       "1514                      1.0  \n",
       "1515                      0.0  \n",
       "1516                      0.0  \n",
       "1517                      1.0  \n",
       "1518                      1.0  \n",
       "1519                      1.0  \n",
       "1520                      1.0  \n",
       "1521                      1.0  \n",
       "1522                      1.0  \n",
       "1523                      1.0  \n",
       "1524                      0.0  \n",
       "1525                      1.0  \n",
       "1526                      1.0  \n",
       "1527                      0.0  \n",
       "1528                      0.0  \n",
       "1529                      1.0  \n",
       "1530                      1.0  \n",
       "1531                      0.0  \n",
       "1532                      0.0  \n",
       "1533                      1.0  \n",
       "1534                      1.0  \n",
       "1535                      0.0  \n",
       "1536                      0.0  \n",
       "1537                      1.0  \n",
       "1538                      1.0  \n",
       "1539                      0.0  \n",
       "1540                      0.0  \n",
       "1541                      1.0  \n",
       "1542                      1.0  \n",
       "1543                      0.0  \n",
       "1544                      1.0  \n",
       "1545                      1.0  \n",
       "1546                      1.0  \n",
       "1547                      0.0  \n",
       "1548                      1.0  \n",
       "1549                      0.0  \n",
       "1550                      0.0  \n",
       "1551                      0.0  \n",
       "1552                      1.0  \n",
       "1553                      1.0  \n",
       "1554                      1.0  \n",
       "1555                      1.0  \n",
       "1556                      1.0  \n",
       "1557                      0.0  \n",
       "1558                      1.0  \n",
       "1559                      0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_sub_testing_performence.loc[cur_sub_testing_performence['test_test_response.rt']>trial_too_long_exclusion_criteria,'test_test_response.rt']=nan\n",
    "cur_sub_testing_performence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outlier_responses(sub_test_dataframe,fast_threshold=0.1,fast_allowed_count=2,slow_threshold=10,slow_allowed_count=2):\n",
    "    isfast_outlier=(sub_test_dataframe['test_test_response.rt']<fast_threshold).sum()>fast_allowed_count\n",
    "    isslow_outlier=(sub_test_dataframe['test_test_response.rt']>slow_threshold).sum()>slow_allowed_count\n",
    "    return isfast_outlier,isslow_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary for criterions:\n",
      "demo accuracy higher than 0.0 - qualified: 26\n",
      "demo attention check correctness equals 1.0 - qualified: 26\n",
      "experiment encoding attention check accuracy 0.6 - qualified: 25\n",
      "experiment longest consequtive strike of maximum of  15.0 responses - qualified: 26\n",
      "test too fast (thresold: 0.3, allowed count: 5.0 qualified: 22\n",
      "test too slow (thresold: 15.0, allowed count: 5.0 qualified: 25\n",
      "above chance accuracy in test, qualified: 24\n",
      "OVERALL: number of qualified participants (adhere to all criterions): 20\n"
     ]
    }
   ],
   "source": [
    "#combine all oneliners into a single matrix - 1 line per participant with all information we want:\n",
    "data_df_for_analysis=pd.concat([all_subjects_summary_demo_info,all_subjects_summary_encoding_info,all_subjects_summary_testing_info],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#as each participant saw 20 distractors per layer, we need atleast 0.75 (15/20) accuracy in one of the layers or above 0.616 (37/60) in the overall: \n",
    "\n",
    "#how many participants would fail the demo (did not correctly answered the arrow or had less than 60% performence)\n",
    "demo_criterions_accuracy=data_df_for_analysis['demo_demo_accuracy']>=criterions_df['demo_accuracy_treshold']\n",
    "demo_criterions_attention_check=data_df_for_analysis['demo_arrow_correct']>=criterions_df['demo_arrow_correctness']\n",
    "#find which participants performed pooly on the attention checks of the experiment encoding phase: \n",
    "encoding_ciriterions=data_df_for_analysis['encoding_arrow_accuracy']>criterions_df['encoding_arrow_accuracy']\n",
    "#remove participants that are too slow: \n",
    "test_criterions_strike=data_df_for_analysis['testing_longest_response_strike']<criterions_df['longest_allowed_consequtive_strike']\n",
    "\n",
    "too_fast_criterions=[]\n",
    "too_slow_criterions=[]\n",
    "for subject in data_df_for_analysis.index:\n",
    "    sub_test_dataframe=all_subjects_test_df[all_subjects_test_df['subject']==subject]\n",
    "    toofast_criterion,tooslow_criterion=find_outlier_responses(sub_test_dataframe,fast_threshold=criterions_df['fast_threshold'],fast_allowed_count=criterions_df['fast_allowed_count'],slow_threshold=criterions_df['slow_threshold'],slow_allowed_count=criterions_df['slow_allowed_count'])\n",
    "    too_slow_criterions.append(not tooslow_criterion)\n",
    "    too_fast_criterions.append(not toofast_criterion)\n",
    "\n",
    "\n",
    "\n",
    "print(f'summary for criterions:')\n",
    "print(f'demo accuracy higher than {criterions_df.demo_accuracy_treshold} - qualified: {demo_criterions_accuracy.sum()}')\n",
    "print(f'demo attention check correctness equals {criterions_df.demo_arrow_correctness} - qualified: {demo_criterions_attention_check.sum()}')\n",
    "print(f'experiment encoding attention check accuracy {criterions_df.encoding_arrow_accuracy} - qualified: {encoding_ciriterions.sum()}')\n",
    "print(f'experiment longest consequtive strike of maximum of  {criterions_df.longest_allowed_consequtive_strike} responses - qualified: {test_criterions_strike.sum()}')\n",
    "print(f'test too fast (thresold: {criterions_df.fast_threshold}, allowed count: {criterions_df.fast_allowed_count} qualified: {sum(too_fast_criterions)}')\n",
    "print(f'test too slow (thresold: {criterions_df.slow_threshold}, allowed count: {criterions_df.slow_allowed_count} qualified: {sum(too_slow_criterions)}')\n",
    "#accuracy criterion on the test: \n",
    "test_accuracy_critertions=(data_df_for_analysis['testing_Test_overall_accuracy']>=criterions_df['binom_averages']) | (data_df_for_analysis[['testing_layer_1_accuracy' ,'testing_layer_2_accuracy' ,'testing_layer_3_accuracy']]>=criterions_df['binom_single_layer']).T.any()\n",
    "#remove participants that were discarded based on behavior up to the test and now qualify or disqualify based on test accuracy (do they have atleast 1 significant (binomial test) accuracy in one layer, or above threshold in overall accuracy )\n",
    "only_qualified=demo_criterions_accuracy & demo_criterions_attention_check & encoding_ciriterions & test_criterions_strike & too_fast_criterions & too_slow_criterions & test_accuracy_critertions\n",
    "print(f'above chance accuracy in test, qualified: {sum(test_accuracy_critertions)}')\n",
    "print(f'OVERALL: number of qualified participants (adhere to all criterions): {sum(only_qualified)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A3BU8UL4W258UU': [0, 1672259949355, 1672330353312, 1672338011502],\n",
       " 'A2YC6PEMIRSOAA': [999, 1672259992394, 1672260336538],\n",
       " 'A2IQ0QCTQ3KWLT': [2, 1672259962573],\n",
       " 'APVZGZM1RA3AZ': [999, 1672259965919, 1672451513039],\n",
       " 'A27PVIL93ZMY46': [999, 1672259976932, 1672431903284],\n",
       " 'A11F3MA5FWH6SJ': [5, 1672259987509, 1672330050392, 1672335745754],\n",
       " 'A2PPTQXFVA9H38': [999, 1672259987861],\n",
       " 'A1FJGB5JLZ81XB': [7, 1672260025367, 1672334776164, 1672337091803],\n",
       " 'AYWHJVYLOA2B5': [999, 1672260029473],\n",
       " 'A9YPM325MKYLO': [9,\n",
       "  1672260039075,\n",
       "  1672330447238,\n",
       "  1672330627138,\n",
       "  1672333360670,\n",
       "  1672343237383],\n",
       " 'AGZ3QJFK1BR8V': [10,\n",
       "  1672260111857,\n",
       "  1672330308647,\n",
       "  1672330477505,\n",
       "  1672331290953,\n",
       "  1672336504122],\n",
       " 'AW9T591E49DCX': [11, 1672260117172, 1672331320568],\n",
       " 'A6M7YIG6KKHPA': [12, 1672260301475, 1672329813672, 1672329849584],\n",
       " 'A1TKZIBGTP7FE8': [13, 1672260321296, 1672346014127],\n",
       " 'A3HZFB2JLF3JMY': [14, 1672260345507],\n",
       " 'ARR9GKAG3JFE5': [15, 1672260410283, 1672344293514],\n",
       " 'A1PHDT66U6IK4Q': [16,\n",
       "  1672260558724,\n",
       "  1672330013374,\n",
       "  1672330273345,\n",
       "  1672331907909,\n",
       "  1672333999861,\n",
       "  1672335867212,\n",
       "  1672337055604],\n",
       " 'A3SKE5B27HLVO6': [17, 1672260574773, 1672331588331, 1672336764278],\n",
       " 'A1QT3YA7G8MO63': [18, 1672260449206, 1672342649908],\n",
       " 'A2VLTSW6CXIUMR': [19, 1672260855599, 1672350028452],\n",
       " 'A1FMVUYV72MUO3': [999, 1672260889474, 1672366520395],\n",
       " 'A2376IXNKHYB22': [999, 999, 999],\n",
       " 'A2XDWB9NVYI3LQ': [999, 1672260987435, 1672368570043],\n",
       " 'AWX3PLN2FS0SW': [999, 999, 999],\n",
       " 'A2IP3ZAFYGV8M9': [23, 1672261263996, 1672348660773],\n",
       " 'A1QUQ0TV9KVD4C': [21, 1672261682060],\n",
       " 'A1YV7SCB1OHMUT': [24, 1672261683329, 1672329977079],\n",
       " 'A3CH1Z6J9R38G9': [26,\n",
       "  1672261908133,\n",
       "  1672331114658,\n",
       "  1672331943263,\n",
       "  1672334404561,\n",
       "  1672336907779,\n",
       "  1672337767267],\n",
       " 'A3KP8KFGG6734Q': [25,\n",
       "  1672262067284,\n",
       "  1672262637385,\n",
       "  1672330879530,\n",
       "  1672356371483],\n",
       " 'hjfhhyhy46478': [999, 999, 999],\n",
       " 'ksgsuhf644': [999, 999, 999],\n",
       " 'A1OM5NWYYYJKQW': [27, 1672262466157, 1672329743884, 1672340507840],\n",
       " 'A7VA2Y4H6U31O': [28, 1672262935938, 1672330641939, 1672338822690],\n",
       " 'A2B153AHPWHLH1': [29, 1672263102293],\n",
       " 'A39M9PZLH3J1NF': [999, 1672263106065],\n",
       " 'AXPZAP62ZYWP8': [31, 1672263205796, 1672337433968, 1672343630318],\n",
       " 'A41APS6V2Z1FJ': [32, 1672263770329, 1672339809777],\n",
       " 'A1Y2W25NF6T431': [999, 1672264261852],\n",
       " 'A2M183CETUMR96': [34, 1672264350184, 1672358532686],\n",
       " 'A1SNC8UL8YFRH5': [35, 1672264395481, 1672347780832],\n",
       " 'A31T2PF4RV3GTF': [36, 1672272089756, 1672331302872, 1672336100994],\n",
       " 'A1DZMZTXWOM9MR': [37, 1672273012190, 1672365046651],\n",
       " 'A11J9UQ036KJA1': [38, 1672274476434],\n",
       " 'A25PFSORDO3SWQ': [39, 1672274742971, 1672352498510],\n",
       " 'A3ATB5GC4BQIH0': [40, 1672274902382, 1672330349861, 1672362175130],\n",
       " 'ACGGIBC0P38HU': [41, 1672277137233, 1672360652315],\n",
       " 'A2YVQKJX3FO6P': [42, 1672278953409, 1672340145634, 1672366806134],\n",
       " 'AAF1SJ9FCBF75': [43, 1672281438975, 1672370976812],\n",
       " 'A39VAFCIGP83ER': [44,\n",
       "  1672282360982,\n",
       "  1672337934811,\n",
       "  1672346205293,\n",
       "  1672346443137,\n",
       "  1672352366678,\n",
       "  1672353595279,\n",
       "  1672355418377,\n",
       "  1672366834322],\n",
       " 'A16JG2M1SEGWPW': [999,\n",
       "  1672316383870,\n",
       "  1672317139595,\n",
       "  1672317516600,\n",
       "  1672319128198,\n",
       "  1672320185583],\n",
       " 'AHXQCR64E5GUE': [999, 999, 999],\n",
       " 'AMPR904VJJFZY': [46,\n",
       "  1672323849721,\n",
       "  1672329782081,\n",
       "  1672329848269,\n",
       "  1672330877873,\n",
       "  1672347114435],\n",
       " 'A22HIX1M4QXZBB': [1, 1672330046121],\n",
       " 'A248QG4DPULP46': [6, 1672330756613],\n",
       " 'A2ASR7XQA7KERU': [3, 1672497020995]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this section loads the shelf dict in the state it is after finishing the testing session for this batch. \n",
    "shelf_dict_after_test_name=PATH_TO_BATCH / 'shelf after test session closed.txt' #define the name of the relevant shelf for this stage\n",
    "with open(shelf_dict_after_test_name) as f:\n",
    "    data = f.read()\n",
    "shelf_dict = json.loads(data)\n",
    "shelf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section reads all the relevant files: \n",
    "if (PATH_TO_BATCH / 'Batch_encoding_batch_results.csv').exists():\n",
    "    encoding_df=pd.read_csv(PATH_TO_BATCH / 'Batch_encoding_batch_results.csv')\n",
    "else: \n",
    "    print(f'no \"Batch_encoding_batch_results.csv\" was found in data')\n",
    "\n",
    "if (PATH_TO_BATCH / 'Batch_testing_batch_results.csv').exists():\n",
    "    testing_df=pd.read_csv(PATH_TO_BATCH / 'Batch_testing_batch_results.csv')\n",
    "else: \n",
    "    print(f'no \"Batch_testing_batch_results.csv\" was found in data (probably because only the encoding session finished)')\n",
    "if (PATH_TO_BATCH / 'Batch_workers_after_test.csv').exists():\n",
    "    workers_df=pd.read_csv(PATH_TO_BATCH / 'Batch_workers_after_test.csv')\n",
    "else:\n",
    "    print('No AMAZON worker list was found: please make sure to upload one and name it correctly')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_consequtive_repetition(responses_array):\n",
    "#add a stop value so the loop will use the logic also if the end of the responses is all repeating: \n",
    "    responses_array=np.append(responses_array,[99])\n",
    "    longest_rep_dict=dict()\n",
    "    last_input=responses_array[0]\n",
    "    consequtive_rep_counter=0\n",
    "    for response in responses_array[1:]: \n",
    "        if response==last_input: #if consequtive rep: \n",
    "            consequtive_rep_counter=consequtive_rep_counter+1 #add to counter\n",
    "        else: #once a new entry is in the vector - store the counter rep information \n",
    "            if last_input in longest_rep_dict.keys(): #if it was allready stored in our dictionary\n",
    "                if longest_rep_dict[last_input]<consequtive_rep_counter: #replace the counter only if it is higher than what stored in dict\n",
    "                    longest_rep_dict[last_input]=consequtive_rep_counter\n",
    "            else: #this entry is not yet in the dictionary: add it \n",
    "                longest_rep_dict[last_input]=consequtive_rep_counter\n",
    "            \n",
    "            consequtive_rep_counter=0\n",
    "            last_input=response\n",
    "    return max(longest_rep_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_worker_results(PATH_TO_BATCH_DATA,subject_name,parse_type='encoding'):\n",
    "    cur_sub=pd.read_csv(PATH_TO_BATCH_DATA / subject_name)\n",
    "    sub_demographics=cur_sub[['workID','Age','Gender']].iloc[0]\n",
    "\n",
    "    #extract demo related information: \n",
    "\n",
    "    #if participant did not click on the arrow during the demo a 'demo_encoding_response.rt' colmumn wont exists: \n",
    "    #thus we will create one and fill it with nans (so everything will be consistent with other participants)\n",
    "    if not('demo_encoding_response.rt' in cur_sub.columns):\n",
    "        cur_sub['demo_encoding_response.rt']=np.nan\n",
    "    demo_columns=['demo_encoding_loop.thisTrialN','DemoImage','DemoCorrect','demo_encoding_response.rt','demo_encoding_response.keys']\n",
    "\n",
    "    if (parse_type=='encoding'):\n",
    "        sub_demo_information=cur_sub[demo_columns]\n",
    "        empty_inds=sub_demo_information.loc[sub_demo_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "        #drop irrelevant columns: \n",
    "        sub_demo_information=sub_demo_information.drop(index=empty_inds)\n",
    "\n",
    "\n",
    "        #extract the demo test columns: \n",
    "        demo_test_columns=['demo_test_response.keys','demo_test_response.corr','demo_test_response.rt','demo_test_loop.thisTrialN','DemoImage1','DemoImage2','DemoCorrectTest']\n",
    "        sub_demo_test_information=cur_sub[demo_test_columns]\n",
    "        empty_inds=sub_demo_test_information.loc[sub_demo_test_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "        #drop irrelevant columns: \n",
    "        sub_demo_test_information=sub_demo_test_information.drop(index=empty_inds)\n",
    "\n",
    "        demo_df=pd.concat([sub_demo_information.reset_index(),sub_demo_test_information.reset_index()],axis=1)\n",
    "\n",
    "    #extract real experiment related information: \n",
    "\n",
    "    #if participant did not click on the arrow during the encoding a 'test_encoding_response.rt' column wont exists: \n",
    "    #thus we will create one and fill it with nans (so everything will be consistent with other participants)\n",
    "    if not('test_encoding_response.rt' in cur_sub.columns):\n",
    "        cur_sub['test_encoding_response.rt']=np.nan\n",
    "\n",
    "\n",
    "    if (parse_type=='encoding') | (parse_type=='all'):\n",
    "        encoding_related_columns=['test_encoding_response.keys','test_encoding_response.corr','trials.thisTrialN','target_image','pair','layer','correct','test_encoding_response.rt','key_resp_end.keys']\n",
    "        sub_encoding_information=cur_sub[encoding_related_columns]\n",
    "        #encoding section ends with a key press of the space key: so seperate this phase by finding this space key row\n",
    "        end_of_section_ind=np.where(sub_encoding_information['key_resp_end.keys']=='space')[0][0]\n",
    "        sub_encoding_information=sub_encoding_information.iloc[0:end_of_section_ind]\n",
    "        #remove all the rows that precede the real encoding phase: \n",
    "        empty_inds=sub_encoding_information.loc[sub_encoding_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "        sub_encoding_information=sub_encoding_information.drop(index=empty_inds).reset_index()\n",
    "\n",
    "    if (parse_type=='test') | (parse_type=='all'):\n",
    "    #extract real experiment TEST related information: \n",
    "        test_related_columns=['layer','correct','test_test_response.keys','test_test_response.corr','test_test_response.rt','trials_2.thisRepN','trials_2.thisTrialN','trials_2.thisN','trials_2.thisIndex','trials_2.ran','image1','image2']\n",
    "        sub_test_information=cur_sub[test_related_columns].dropna()\n",
    "\n",
    "\n",
    "    subject_dictionary=dict()\n",
    "    subject_dictionary['demographics']=sub_demographics\n",
    "    if (parse_type=='encoding') | (parse_type=='all'):\n",
    "        subject_dictionary['demo_df']=demo_df\n",
    "    if (parse_type=='encoding') | (parse_type=='all'):\n",
    "        subject_dictionary['encoding_df']=sub_encoding_information\n",
    "    if (parse_type=='test') | (parse_type=='all'):\n",
    "        subject_dictionary['test_df']=sub_test_information\n",
    "\n",
    "    return subject_dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get all results with Encoding information - extract the arrow attention check accuracy and RT (RT is currently not usd as a criterion)\n",
    "\n",
    "#this section extract the list of participants from the downloaded results files (and not via the workers or session list csvs) \n",
    "# - it will create the qualification_df (a table with information on the worker ids and encoding behavior of all participants that we have files for)\n",
    "all_filenames=[file for file in PATH_TO_BATCH_DATA.iterdir() if 'csv' in file.name and 'ENCODING' in file.name]\n",
    "#print(f'current csv files:\\n{all_filenames}')\n",
    "\n",
    "qualification_for_test_df=pd.DataFrame(columns=['workerID','arrow_acc','mean_arrow_RT'])\n",
    "for subject_csv in all_filenames:\n",
    "    subject_dict=process_worker_results(PATH_TO_BATCH_DATA,path.Path(subject_csv))\n",
    "    cur_sub_encoding=subject_dict['encoding_df']\n",
    "\n",
    "    sname=subject_csv.name.split('_')[1] #change according to actuall format. \n",
    "\n",
    "    #get only attention check related info: \n",
    "    cur_sub_encoding=cur_sub_encoding[['test_encoding_response.keys','correct','test_encoding_response.rt']].copy().dropna(how = 'all')\n",
    "    if len(cur_sub_encoding)==0: #empty - the participant didnt respond on the arrow at all\n",
    "        arrow_acc=0\n",
    "        RT=nan\n",
    "    else: \n",
    "        RT=cur_sub_encoding['test_encoding_response.rt'].mean()\n",
    "        arrow_acc=(cur_sub_encoding['correct']==cur_sub_encoding['test_encoding_response.keys']).mean()\n",
    "    sub_df=pd.DataFrame({'workerID':sname,'arrow_acc':arrow_acc,'mean_arrow_RT':RT},index=[sname])\n",
    "    qualification_for_test_df=pd.concat([qualification_for_test_df,sub_df],axis=0)\n",
    "\n",
    "#the following part update the qualification_df with information on wether the participant id exists in the amazon workers list: \n",
    "\n",
    "#change participants qualifications if they exists in the workers list based on thier encoding arrow accuracy\n",
    "qualification_for_test_df['in_encoding_workers_list']=nan\n",
    "\n",
    "for curr_worker_ID in qualification_for_test_df.index:\n",
    "    if curr_worker_ID in encoding_df['WorkerId'].values:\n",
    "        qualification_for_test_df.loc[curr_worker_ID,'in_encoding_workers_list']=int(1)\n",
    "    else:\n",
    "        qualification_for_test_df.loc[curr_worker_ID,'in_encoding_workers_list']=int(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects_demo_df=pd.DataFrame()\n",
    "all_subjects_encoding_df=pd.DataFrame()\n",
    "all_subjects_test_df=pd.DataFrame()\n",
    "all_subjects_biographics_df=pd.DataFrame()\n",
    "all_filenames=[file.name for file in PATH_TO_BATCH_DATA.iterdir() if 'csv' in file.name and 'TEST' in file.name]\n",
    "\n",
    "for subject_test_filename in all_filenames:\n",
    "    subject_name=subject_test_filename.split('_')[1]\n",
    "    subject_encoding_filename=[file.name for file in PATH_TO_BATCH_DATA.iterdir() if 'csv' in file.name and 'ENCODING' in file.name and subject_name in file.name][0]\n",
    "    curr_subject_dictionary=process_worker_results(PATH_TO_BATCH_DATA,subject_encoding_filename,parse_type='encoding')\n",
    "    curr_demo_df=curr_subject_dictionary['demo_df']\n",
    "    curr_demo_df['subject']=subject_name\n",
    "    curr_encoding_df=curr_subject_dictionary['encoding_df']\n",
    "    curr_encoding_df['subject']=subject_name\n",
    "    curr_demographics_df=curr_subject_dictionary['demographics']\n",
    "    curr_demographics_df['subject']=subject_name\n",
    "\n",
    "    #get the name of this participant encoding: \n",
    "\n",
    "    curr_subject_dictionary=process_worker_results(PATH_TO_BATCH_DATA,subject_test_filename,parse_type='test')\n",
    "    curr_test_df=curr_subject_dictionary['test_df']\n",
    "    curr_test_df['subject']=subject_name\n",
    "\n",
    "\n",
    "\n",
    "    all_subjects_demo_df=pd.concat([all_subjects_demo_df,curr_demo_df],axis=0,ignore_index=True)\n",
    "    all_subjects_encoding_df=pd.concat([all_subjects_encoding_df,curr_encoding_df],axis=0,ignore_index=True)\n",
    "    all_subjects_test_df=pd.concat([all_subjects_test_df,curr_test_df],axis=0,ignore_index=True)\n",
    "    all_subjects_biographics_df=pd.concat([all_subjects_biographics_df,pd.DataFrame(curr_demographics_df).T],axis=0,ignore_index=True)\n",
    "\n",
    "\n",
    "all_subjects_demo_df.to_csv(PATH_TO_BATCH / 'all_subjects_demo_df.csv')\n",
    "all_subjects_encoding_df.to_csv(PATH_TO_BATCH / 'all_subjects_encoding_df.csv')\n",
    "all_subjects_test_df.to_csv(PATH_TO_BATCH / 'all_subjects_test_df.csv')\n",
    "all_subjects_biographics_df.to_csv(PATH_TO_BATCH / 'all_subjects_biographics_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed the gender column to be consistent having two possible values: ['female' 'male']\n",
      "Mean age: 37.58, range: [22 - 69], 0.19% female\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import category\n",
    "\n",
    "# if there are any empty values - fill with mean of subjects age \n",
    "mean_value = all_subjects_biographics_df['Age'].mean()\n",
    "all_subjects_biographics_df['Age'].fillna(value=mean_value, inplace=True)\n",
    "all_subjects_biographics_df['Age'] = all_subjects_biographics_df['Age'].astype(np.int64)\n",
    "\n",
    "all_subjects_biographics_df['Age']=all_subjects_biographics_df['Age'].astype(int)\n",
    "all_subjects_biographics_df['Gender'].replace({'ma':'male','Femae': 'female','woman':'female','FEMLAE':'female','Male':'male','MALE':'male','FEMALE':'female','Female':'female','ale':'male'},inplace=True)\n",
    "if len(np.unique(all_subjects_biographics_df['Gender'].values))<=2:\n",
    "    print('transformed the gender column to be consistent having two possible values:',np.unique(all_subjects_biographics_df['Gender'].values))\n",
    "else: \n",
    "    print('gender is still inconsistent with more than 2 unique values:',np.unique(all_subjects_biographics_df['Gender'].values))\n",
    "all_subjects_biographics_df['Gender']=all_subjects_biographics_df['Gender'].astype(\"category\")\n",
    "\n",
    "mean_age,min_age,max_age=all_subjects_biographics_df['Age'].mean(),all_subjects_biographics_df['Age'].min(),all_subjects_biographics_df['Age'].max()\n",
    "female_prop=all_subjects_biographics_df.loc[all_subjects_biographics_df['Gender']=='female','Gender'].count()/all_subjects_biographics_df['Gender'].count()\n",
    "\n",
    "print(f'Mean age: {mean_age:.2f}, range: [{min_age} - {max_age}], {female_prop:.2f}% female')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this part plots the seperate dataframes: \n",
    "### demo phase (encoding and test in the same dataframe)\n",
    "### encoding experiment phase\n",
    "### test experiment phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>demo_encoding_loop.thisTrialN</th>\n",
       "      <th>DemoImage</th>\n",
       "      <th>DemoCorrect</th>\n",
       "      <th>demo_encoding_response.rt</th>\n",
       "      <th>demo_encoding_response.keys</th>\n",
       "      <th>index</th>\n",
       "      <th>demo_test_response.keys</th>\n",
       "      <th>demo_test_response.corr</th>\n",
       "      <th>demo_test_response.rt</th>\n",
       "      <th>demo_test_loop.thisTrialN</th>\n",
       "      <th>DemoImage1</th>\n",
       "      <th>DemoImage2</th>\n",
       "      <th>DemoCorrectTest</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>flower1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>flower1.jpg</td>\n",
       "      <td>flower1_pair.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>flower2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>left</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>flower2_pair.jpg</td>\n",
       "      <td>flower2.jpg</td>\n",
       "      <td>right</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>1.6953</td>\n",
       "      <td>left</td>\n",
       "      <td>14.0</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>flower3.jpg</td>\n",
       "      <td>flower3_pair.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>flower3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4288</td>\n",
       "      <td>3.0</td>\n",
       "      <td>flower4.jpg</td>\n",
       "      <td>flower4_pair.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>flower4.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8950</td>\n",
       "      <td>4.0</td>\n",
       "      <td>flower5_pair.jpg</td>\n",
       "      <td>flower5.jpg</td>\n",
       "      <td>right</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  demo_encoding_loop.thisTrialN    DemoImage DemoCorrect  \\\n",
       "0      4                            0.0  flower1.jpg         NaN   \n",
       "1      5                            1.0  flower2.jpg         NaN   \n",
       "2      6                            2.0     left.jpg        left   \n",
       "3      7                            3.0  flower3.jpg         NaN   \n",
       "4      8                            4.0  flower4.jpg         NaN   \n",
       "\n",
       "   demo_encoding_response.rt demo_encoding_response.keys  index  \\\n",
       "0                        NaN                         NaN   12.0   \n",
       "1                        NaN                         NaN   13.0   \n",
       "2                     1.6953                        left   14.0   \n",
       "3                        NaN                         NaN   15.0   \n",
       "4                        NaN                         NaN   16.0   \n",
       "\n",
       "  demo_test_response.keys  demo_test_response.corr  demo_test_response.rt  \\\n",
       "0                    left                      1.0                 2.8031   \n",
       "1                    left                      0.0                 3.7117   \n",
       "2                    left                      1.0                 2.2200   \n",
       "3                    left                      1.0                 1.4288   \n",
       "4                   right                      1.0                 1.8950   \n",
       "\n",
       "   demo_test_loop.thisTrialN        DemoImage1        DemoImage2  \\\n",
       "0                        0.0       flower1.jpg  flower1_pair.jpg   \n",
       "1                        1.0  flower2_pair.jpg       flower2.jpg   \n",
       "2                        2.0       flower3.jpg  flower3_pair.jpg   \n",
       "3                        3.0       flower4.jpg  flower4_pair.jpg   \n",
       "4                        4.0  flower5_pair.jpg       flower5.jpg   \n",
       "\n",
       "  DemoCorrectTest         subject  \n",
       "0            left  A11F3MA5FWH6SJ  \n",
       "1           right  A11F3MA5FWH6SJ  \n",
       "2            left  A11F3MA5FWH6SJ  \n",
       "3            left  A11F3MA5FWH6SJ  \n",
       "4           right  A11F3MA5FWH6SJ  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects_demo_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_encoding_response.keys</th>\n",
       "      <th>test_encoding_response.corr</th>\n",
       "      <th>trials.thisTrialN</th>\n",
       "      <th>target_image</th>\n",
       "      <th>pair</th>\n",
       "      <th>layer</th>\n",
       "      <th>correct</th>\n",
       "      <th>test_encoding_response.rt</th>\n",
       "      <th>key_resp_end.keys</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STRIPPED_SWALLOW_1.jpg</td>\n",
       "      <td>MAGPIE_GOOSE_4.jpg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BALI_STARLING_1.jpg</td>\n",
       "      <td>IBERIAN_MAGPIE_1.jpg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>RUBY_THROATED_HUMMINGBIRD_3.jpg</td>\n",
       "      <td>MYNA_5.jpg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>LARK_BUNTING_2.jpg</td>\n",
       "      <td>PEACOCK_1.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HAWAIIAN_GOOSE_4.jpg</td>\n",
       "      <td>HIMALAYAN_MONAL_2.jpg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index test_encoding_response.keys  test_encoding_response.corr  \\\n",
       "0     20                         NaN                          1.0   \n",
       "1     21                         NaN                          1.0   \n",
       "2     22                         NaN                          1.0   \n",
       "3     23                         NaN                          1.0   \n",
       "4     24                         NaN                          1.0   \n",
       "\n",
       "   trials.thisTrialN                     target_image                   pair  \\\n",
       "0                0.0           STRIPPED_SWALLOW_1.jpg     MAGPIE_GOOSE_4.jpg   \n",
       "1                1.0              BALI_STARLING_1.jpg   IBERIAN_MAGPIE_1.jpg   \n",
       "2                2.0  RUBY_THROATED_HUMMINGBIRD_3.jpg             MYNA_5.jpg   \n",
       "3                3.0               LARK_BUNTING_2.jpg          PEACOCK_1.jpg   \n",
       "4                4.0             HAWAIIAN_GOOSE_4.jpg  HIMALAYAN_MONAL_2.jpg   \n",
       "\n",
       "   layer correct  test_encoding_response.rt key_resp_end.keys         subject  \n",
       "0    2.0     NaN                        NaN               NaN  A11F3MA5FWH6SJ  \n",
       "1    3.0     NaN                        NaN               NaN  A11F3MA5FWH6SJ  \n",
       "2    2.0     NaN                        NaN               NaN  A11F3MA5FWH6SJ  \n",
       "3    1.0     NaN                        NaN               NaN  A11F3MA5FWH6SJ  \n",
       "4    2.0     NaN                        NaN               NaN  A11F3MA5FWH6SJ  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects_encoding_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>correct</th>\n",
       "      <th>test_test_response.keys</th>\n",
       "      <th>test_test_response.corr</th>\n",
       "      <th>test_test_response.rt</th>\n",
       "      <th>trials_2.thisRepN</th>\n",
       "      <th>trials_2.thisTrialN</th>\n",
       "      <th>trials_2.thisN</th>\n",
       "      <th>trials_2.thisIndex</th>\n",
       "      <th>trials_2.ran</th>\n",
       "      <th>image1</th>\n",
       "      <th>image2</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.1472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GYRFALCON_1.jpg</td>\n",
       "      <td>OSTRICH_1.jpg</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ASIAN_DOLLARD_BIRD_2.jpg</td>\n",
       "      <td>VIOLET_GREEN_SWALLOW_4.jpg</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.9381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KIWI_3.jpg</td>\n",
       "      <td>ARARIPE_MANAKIN_4.jpg</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CASSOWARY_1.jpg</td>\n",
       "      <td>SCARLET_MACAW_1.jpg</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALPINE_CHOUGH_4.jpg</td>\n",
       "      <td>BOBOLINK_3.jpg</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer correct test_test_response.keys  test_test_response.corr  \\\n",
       "0    1.0    left                    left                      1.0   \n",
       "1    3.0    left                    left                      1.0   \n",
       "2    1.0   right                   right                      1.0   \n",
       "3    2.0    left                    left                      1.0   \n",
       "4    3.0    left                   right                      0.0   \n",
       "\n",
       "   test_test_response.rt  trials_2.thisRepN  trials_2.thisTrialN  \\\n",
       "0                 6.1472                0.0                  0.0   \n",
       "1                 1.8693                0.0                  1.0   \n",
       "2                 2.9381                0.0                  2.0   \n",
       "3                 3.6978                0.0                  3.0   \n",
       "4                 1.7443                0.0                  4.0   \n",
       "\n",
       "   trials_2.thisN  trials_2.thisIndex  trials_2.ran                    image1  \\\n",
       "0             0.0                 0.0           1.0           GYRFALCON_1.jpg   \n",
       "1             1.0                 1.0           1.0  ASIAN_DOLLARD_BIRD_2.jpg   \n",
       "2             2.0                 2.0           1.0                KIWI_3.jpg   \n",
       "3             3.0                 3.0           1.0           CASSOWARY_1.jpg   \n",
       "4             4.0                 4.0           1.0       ALPINE_CHOUGH_4.jpg   \n",
       "\n",
       "                       image2         subject  \n",
       "0               OSTRICH_1.jpg  A11F3MA5FWH6SJ  \n",
       "1  VIOLET_GREEN_SWALLOW_4.jpg  A11F3MA5FWH6SJ  \n",
       "2       ARARIPE_MANAKIN_4.jpg  A11F3MA5FWH6SJ  \n",
       "3         SCARLET_MACAW_1.jpg  A11F3MA5FWH6SJ  \n",
       "4              BOBOLINK_3.jpg  A11F3MA5FWH6SJ  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects_test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11F3MA5FWH6SJ</th>\n",
       "      <td>1.6953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.201833</td>\n",
       "      <td>3.711700</td>\n",
       "      <td>1.899860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1DZMZTXWOM9MR</th>\n",
       "      <td>0.4941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.277317</td>\n",
       "      <td>2.501200</td>\n",
       "      <td>2.165375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1FJGB5JLZ81XB</th>\n",
       "      <td>1.7127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.733967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.733967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OM5NWYYYJKQW</th>\n",
       "      <td>0.6385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.915917</td>\n",
       "      <td>2.775400</td>\n",
       "      <td>1.744020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1PHDT66U6IK4Q</th>\n",
       "      <td>0.7481</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>7.267867</td>\n",
       "      <td>9.103700</td>\n",
       "      <td>6.900700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1QT3YA7G8MO63</th>\n",
       "      <td>1.0597</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.551917</td>\n",
       "      <td>1.217300</td>\n",
       "      <td>1.886533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1SNC8UL8YFRH5</th>\n",
       "      <td>0.6413</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.468867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.468867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1TKZIBGTP7FE8</th>\n",
       "      <td>1.7873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.854383</td>\n",
       "      <td>1.621800</td>\n",
       "      <td>1.900900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A25PFSORDO3SWQ</th>\n",
       "      <td>0.6970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.491833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.491833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2IP3ZAFYGV8M9</th>\n",
       "      <td>0.5430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.553317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.553317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>0.6492</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.756800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.756800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2VLTSW6CXIUMR</th>\n",
       "      <td>0.5889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.188183</td>\n",
       "      <td>1.493000</td>\n",
       "      <td>2.535775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2YVQKJX3FO6P</th>\n",
       "      <td>0.8810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.537333</td>\n",
       "      <td>2.273333</td>\n",
       "      <td>2.801333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A39VAFCIGP83ER</th>\n",
       "      <td>1.9865</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.386050</td>\n",
       "      <td>2.732267</td>\n",
       "      <td>2.039833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3ATB5GC4BQIH0</th>\n",
       "      <td>1.0530</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5.599500</td>\n",
       "      <td>10.525000</td>\n",
       "      <td>3.136750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3BU8UL4W258UU</th>\n",
       "      <td>0.5040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.080667</td>\n",
       "      <td>3.154000</td>\n",
       "      <td>1.866000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3CH1Z6J9R38G9</th>\n",
       "      <td>0.4123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.319450</td>\n",
       "      <td>1.480133</td>\n",
       "      <td>1.158767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3KP8KFGG6734Q</th>\n",
       "      <td>1.0667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.486650</td>\n",
       "      <td>1.662100</td>\n",
       "      <td>2.651560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3SKE5B27HLVO6</th>\n",
       "      <td>0.9220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5.815333</td>\n",
       "      <td>7.733750</td>\n",
       "      <td>1.978500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A7VA2Y4H6U31O</th>\n",
       "      <td>0.6330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.786550</td>\n",
       "      <td>3.435600</td>\n",
       "      <td>2.656740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A9YPM325MKYLO</th>\n",
       "      <td>1.8896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.257900</td>\n",
       "      <td>3.288640</td>\n",
       "      <td>3.104200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAF1SJ9FCBF75</th>\n",
       "      <td>0.8860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.442833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.442833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACGGIBC0P38HU</th>\n",
       "      <td>1.5020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.393500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.393500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGZ3QJFK1BR8V</th>\n",
       "      <td>1.0110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.207000</td>\n",
       "      <td>2.594000</td>\n",
       "      <td>2.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARR9GKAG3JFE5</th>\n",
       "      <td>1.1300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.193667</td>\n",
       "      <td>2.670667</td>\n",
       "      <td>1.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXPZAP62ZYWP8</th>\n",
       "      <td>0.7595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.548283</td>\n",
       "      <td>1.399800</td>\n",
       "      <td>1.577980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A11F3MA5FWH6SJ         1.6953                 1.0            0.833333   \n",
       "A1DZMZTXWOM9MR         0.4941                 1.0            0.666667   \n",
       "A1FJGB5JLZ81XB         1.7127                 1.0            1.000000   \n",
       "A1OM5NWYYYJKQW         0.6385                 1.0            0.833333   \n",
       "A1PHDT66U6IK4Q         0.7481                 1.0            0.833333   \n",
       "A1QT3YA7G8MO63         1.0597                 1.0            0.500000   \n",
       "A1SNC8UL8YFRH5         0.6413                 1.0            1.000000   \n",
       "A1TKZIBGTP7FE8         1.7873                 1.0            0.833333   \n",
       "A25PFSORDO3SWQ         0.6970                 1.0            1.000000   \n",
       "A2IP3ZAFYGV8M9         0.5430                 1.0            1.000000   \n",
       "A2M183CETUMR96         0.6492                 1.0            1.000000   \n",
       "A2VLTSW6CXIUMR         0.5889                 1.0            0.666667   \n",
       "A2YVQKJX3FO6P          0.8810                 1.0            0.500000   \n",
       "A39VAFCIGP83ER         1.9865                 1.0            0.500000   \n",
       "A3ATB5GC4BQIH0         1.0530                 1.0            0.666667   \n",
       "A3BU8UL4W258UU         0.5040                 1.0            0.833333   \n",
       "A3CH1Z6J9R38G9         0.4123                 1.0            0.500000   \n",
       "A3KP8KFGG6734Q         1.0667                 1.0            0.833333   \n",
       "A3SKE5B27HLVO6         0.9220                 1.0            0.333333   \n",
       "A7VA2Y4H6U31O          0.6330                 1.0            0.833333   \n",
       "A9YPM325MKYLO          1.8896                 1.0            0.166667   \n",
       "AAF1SJ9FCBF75          0.8860                 1.0            1.000000   \n",
       "ACGGIBC0P38HU          1.5020                 1.0            1.000000   \n",
       "AGZ3QJFK1BR8V          1.0110                 1.0            0.666667   \n",
       "ARR9GKAG3JFE5          1.1300                 1.0            0.500000   \n",
       "AXPZAP62ZYWP8          0.7595                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A11F3MA5FWH6SJ              2.201833                3.711700   \n",
       "A1DZMZTXWOM9MR              2.277317                2.501200   \n",
       "A1FJGB5JLZ81XB              2.733967                     NaN   \n",
       "A1OM5NWYYYJKQW              1.915917                2.775400   \n",
       "A1PHDT66U6IK4Q              7.267867                9.103700   \n",
       "A1QT3YA7G8MO63              1.551917                1.217300   \n",
       "A1SNC8UL8YFRH5              2.468867                     NaN   \n",
       "A1TKZIBGTP7FE8              1.854383                1.621800   \n",
       "A25PFSORDO3SWQ              2.491833                     NaN   \n",
       "A2IP3ZAFYGV8M9              1.553317                     NaN   \n",
       "A2M183CETUMR96              2.756800                     NaN   \n",
       "A2VLTSW6CXIUMR              2.188183                1.493000   \n",
       "A2YVQKJX3FO6P               2.537333                2.273333   \n",
       "A39VAFCIGP83ER              2.386050                2.732267   \n",
       "A3ATB5GC4BQIH0              5.599500               10.525000   \n",
       "A3BU8UL4W258UU              2.080667                3.154000   \n",
       "A3CH1Z6J9R38G9              1.319450                1.480133   \n",
       "A3KP8KFGG6734Q              2.486650                1.662100   \n",
       "A3SKE5B27HLVO6              5.815333                7.733750   \n",
       "A7VA2Y4H6U31O               2.786550                3.435600   \n",
       "A9YPM325MKYLO               3.257900                3.288640   \n",
       "AAF1SJ9FCBF75               5.442833                     NaN   \n",
       "ACGGIBC0P38HU               2.393500                     NaN   \n",
       "AGZ3QJFK1BR8V               2.207000                2.594000   \n",
       "ARR9GKAG3JFE5               2.193667                2.670667   \n",
       "AXPZAP62ZYWP8               1.548283                1.399800   \n",
       "\n",
       "                demo_RT_correct_mean  \n",
       "A11F3MA5FWH6SJ              1.899860  \n",
       "A1DZMZTXWOM9MR              2.165375  \n",
       "A1FJGB5JLZ81XB              2.733967  \n",
       "A1OM5NWYYYJKQW              1.744020  \n",
       "A1PHDT66U6IK4Q              6.900700  \n",
       "A1QT3YA7G8MO63              1.886533  \n",
       "A1SNC8UL8YFRH5              2.468867  \n",
       "A1TKZIBGTP7FE8              1.900900  \n",
       "A25PFSORDO3SWQ              2.491833  \n",
       "A2IP3ZAFYGV8M9              1.553317  \n",
       "A2M183CETUMR96              2.756800  \n",
       "A2VLTSW6CXIUMR              2.535775  \n",
       "A2YVQKJX3FO6P               2.801333  \n",
       "A39VAFCIGP83ER              2.039833  \n",
       "A3ATB5GC4BQIH0              3.136750  \n",
       "A3BU8UL4W258UU              1.866000  \n",
       "A3CH1Z6J9R38G9              1.158767  \n",
       "A3KP8KFGG6734Q              2.651560  \n",
       "A3SKE5B27HLVO6              1.978500  \n",
       "A7VA2Y4H6U31O               2.656740  \n",
       "A9YPM325MKYLO               3.104200  \n",
       "AAF1SJ9FCBF75               5.442833  \n",
       "ACGGIBC0P38HU               2.393500  \n",
       "AGZ3QJFK1BR8V               2.013500  \n",
       "ARR9GKAG3JFE5               1.716667  \n",
       "AXPZAP62ZYWP8               1.577980  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this section extract information from the demo phase: it creates a df (all_subjects_summary_demo_info) containingsingle row per participants with metrics from the demo phase (average accuracy, RTs and so on (this can be used to screen participatns for further analysis)):\n",
    "all_subjects_summary_demo_info=pd.DataFrame(index=list(all_subjects_demo_df['subject'].unique()))\n",
    "\n",
    "for cur_subject in all_subjects_demo_df['subject'].unique():\n",
    "    cur_sub_demo_encoding=all_subjects_demo_df.loc[all_subjects_demo_df['subject']==cur_subject]\n",
    "    \n",
    "    #get only attention check related info: \n",
    "    curr_subjects_summary_demo_info=cur_sub_demo_encoding[['demo_encoding_response.keys','DemoCorrect','demo_encoding_response.rt']].copy().dropna()\n",
    "    if len(curr_subjects_summary_demo_info)==0: #empty - the participant didnt respond on the arrow at all: \n",
    "       all_subjects_summary_demo_info.loc[cur_subject,'arrow_correct']=0 \n",
    "       all_subjects_summary_demo_info.loc[cur_subject,'arrow_rt']=np.nan\n",
    "    else: \n",
    "        all_subjects_summary_demo_info.loc[cur_subject,'arrow_rt']=curr_subjects_summary_demo_info['demo_encoding_response.rt'].values\n",
    "        if all(curr_subjects_summary_demo_info['DemoCorrect']==curr_subjects_summary_demo_info['demo_encoding_response.keys']):\n",
    "            all_subjects_summary_demo_info.loc[cur_subject,'arrow_correct']=1\n",
    "        else:\n",
    "            all_subjects_summary_demo_info.loc[cur_subject,'arrow_correct']=0\n",
    "\n",
    "\n",
    "    #get the correctness of the demo testing phase: \n",
    "    cur_sub_demo_test_performence=cur_sub_demo_encoding[['DemoCorrectTest','demo_test_response.keys','demo_test_response.rt']].copy().dropna()\n",
    "    test_match_df=pd.DataFrame(columns=['arrow_correct'],data=cur_sub_demo_test_performence['DemoCorrectTest']==cur_sub_demo_test_performence['demo_test_response.keys'])\n",
    "    test_match_df['demo_test_response.rt']=cur_sub_demo_test_performence['demo_test_response.rt']\n",
    "    accuracy=test_match_df['arrow_correct'].mean()\n",
    "    mean_rt=test_match_df['demo_test_response.rt'].mean()\n",
    "    correct_and_incorrect_rts=test_match_df.groupby('arrow_correct').aggregate({'demo_test_response.rt':'mean'})\n",
    "    #update the summary info row: \n",
    "    all_subjects_summary_demo_info.loc[cur_subject,'demo_accuracy']=accuracy\n",
    "    all_subjects_summary_demo_info.loc[cur_subject,'RT_overall_mean']=mean_rt\n",
    "    all_subjects_summary_demo_info.loc[cur_subject,['RT_incorrect_mean','RT_correct_mean']]=np.nan\n",
    "\n",
    "    if False in correct_and_incorrect_rts.index:\n",
    "        all_subjects_summary_demo_info.loc[cur_subject,'RT_incorrect_mean']=correct_and_incorrect_rts.loc[False].values[0]\n",
    "    if True in correct_and_incorrect_rts.index:\n",
    "        all_subjects_summary_demo_info.loc[cur_subject,'RT_correct_mean']=correct_and_incorrect_rts.loc[True].values[0]\n",
    "\n",
    "\n",
    "#add a prefix to column names: \n",
    "all_subjects_summary_demo_info.columns=['demo_'+col for col in all_subjects_summary_demo_info.columns]\n",
    "all_subjects_summary_demo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11F3MA5FWH6SJ</th>\n",
       "      <td>1.200720</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1DZMZTXWOM9MR</th>\n",
       "      <td>0.553540</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1FJGB5JLZ81XB</th>\n",
       "      <td>1.530060</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OM5NWYYYJKQW</th>\n",
       "      <td>0.609960</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1PHDT66U6IK4Q</th>\n",
       "      <td>0.651920</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1QT3YA7G8MO63</th>\n",
       "      <td>0.879575</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1SNC8UL8YFRH5</th>\n",
       "      <td>0.595680</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1TKZIBGTP7FE8</th>\n",
       "      <td>1.713640</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A25PFSORDO3SWQ</th>\n",
       "      <td>0.590200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2IP3ZAFYGV8M9</th>\n",
       "      <td>0.646680</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>0.497520</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2VLTSW6CXIUMR</th>\n",
       "      <td>0.516100</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2YVQKJX3FO6P</th>\n",
       "      <td>0.867600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A39VAFCIGP83ER</th>\n",
       "      <td>0.965040</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3ATB5GC4BQIH0</th>\n",
       "      <td>0.921200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3BU8UL4W258UU</th>\n",
       "      <td>0.492000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3CH1Z6J9R38G9</th>\n",
       "      <td>0.534320</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3KP8KFGG6734Q</th>\n",
       "      <td>0.794800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3SKE5B27HLVO6</th>\n",
       "      <td>1.537400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A7VA2Y4H6U31O</th>\n",
       "      <td>0.525860</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A9YPM325MKYLO</th>\n",
       "      <td>1.256540</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAF1SJ9FCBF75</th>\n",
       "      <td>0.654800</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACGGIBC0P38HU</th>\n",
       "      <td>1.488800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGZ3QJFK1BR8V</th>\n",
       "      <td>1.155200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARR9GKAG3JFE5</th>\n",
       "      <td>1.574667</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXPZAP62ZYWP8</th>\n",
       "      <td>0.567080</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                encoding_arrow_mean_rt  encoding_arrow_accuracy\n",
       "A11F3MA5FWH6SJ                1.200720                      1.0\n",
       "A1DZMZTXWOM9MR                0.553540                      1.0\n",
       "A1FJGB5JLZ81XB                1.530060                      1.0\n",
       "A1OM5NWYYYJKQW                0.609960                      1.0\n",
       "A1PHDT66U6IK4Q                0.651920                      1.0\n",
       "A1QT3YA7G8MO63                0.879575                      0.8\n",
       "A1SNC8UL8YFRH5                0.595680                      1.0\n",
       "A1TKZIBGTP7FE8                1.713640                      1.0\n",
       "A25PFSORDO3SWQ                0.590200                      1.0\n",
       "A2IP3ZAFYGV8M9                0.646680                      1.0\n",
       "A2M183CETUMR96                0.497520                      1.0\n",
       "A2VLTSW6CXIUMR                0.516100                      0.8\n",
       "A2YVQKJX3FO6P                 0.867600                      1.0\n",
       "A39VAFCIGP83ER                0.965040                      1.0\n",
       "A3ATB5GC4BQIH0                0.921200                      1.0\n",
       "A3BU8UL4W258UU                0.492000                      1.0\n",
       "A3CH1Z6J9R38G9                0.534320                      0.8\n",
       "A3KP8KFGG6734Q                0.794800                      1.0\n",
       "A3SKE5B27HLVO6                1.537400                      1.0\n",
       "A7VA2Y4H6U31O                 0.525860                      1.0\n",
       "A9YPM325MKYLO                 1.256540                      1.0\n",
       "AAF1SJ9FCBF75                 0.654800                      0.8\n",
       "ACGGIBC0P38HU                 1.488800                      1.0\n",
       "AGZ3QJFK1BR8V                 1.155200                      1.0\n",
       "ARR9GKAG3JFE5                 1.574667                      0.6\n",
       "AXPZAP62ZYWP8                 0.567080                      1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this part extract summary information from the experiment encoding phase: attention check accuracy and timings: \n",
    "all_subjects_summary_encoding_info=pd.DataFrame(index=list(all_subjects_encoding_df['subject'].unique()))\n",
    "\n",
    "for cur_subject in all_subjects_encoding_df['subject'].unique():\n",
    "    cur_sub_encoding=all_subjects_encoding_df.loc[all_subjects_encoding_df['subject']==cur_subject]\n",
    "    \n",
    "    #get only attention check related info: \n",
    "    cur_sub_encoding=cur_sub_encoding[['test_encoding_response.keys','correct','test_encoding_response.rt']].copy().dropna(how = 'all')\n",
    "    if len(cur_sub_encoding)==0: #empty - the participant didnt respond on the arrow at all: \n",
    "       all_subjects_summary_encoding_info.loc[cur_subject,'arrow_accuracy']=0 \n",
    "       all_subjects_summary_encoding_info.loc[cur_subject,'arrow_mean_rt']=np.nan\n",
    "    else: \n",
    "        all_subjects_summary_encoding_info.loc[cur_subject,'arrow_mean_rt']=cur_sub_encoding['test_encoding_response.rt'].mean()\n",
    "        arrow_accuracy=(cur_sub_encoding['correct']==cur_sub_encoding['test_encoding_response.keys']).mean()\n",
    "        all_subjects_summary_encoding_info.loc[cur_subject,'arrow_accuracy']=arrow_accuracy\n",
    "\n",
    "\n",
    "\n",
    "#add a prefix to column names: \n",
    "all_subjects_summary_encoding_info.columns=['encoding_'+col for col in all_subjects_summary_encoding_info.columns]        \n",
    "all_subjects_summary_encoding_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>testing_RT_incorrect_mean</th>\n",
       "      <th>testing_RT_correct_mean</th>\n",
       "      <th>testing_layer_1_rt</th>\n",
       "      <th>testing_layer_1_accuracy</th>\n",
       "      <th>testing_layer_2_rt</th>\n",
       "      <th>testing_layer_2_accuracy</th>\n",
       "      <th>testing_layer_3_rt</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11F3MA5FWH6SJ</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>1.996455</td>\n",
       "      <td>2.024171</td>\n",
       "      <td>1.988020</td>\n",
       "      <td>2.252405</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.047725</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.689235</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1DZMZTXWOM9MR</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.044238</td>\n",
       "      <td>2.335260</td>\n",
       "      <td>1.986034</td>\n",
       "      <td>1.940875</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.122665</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.069175</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1FJGB5JLZ81XB</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>2.011600</td>\n",
       "      <td>2.293350</td>\n",
       "      <td>1.980294</td>\n",
       "      <td>2.044130</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.064860</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.925810</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OM5NWYYYJKQW</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.865277</td>\n",
       "      <td>1.954120</td>\n",
       "      <td>1.847508</td>\n",
       "      <td>1.978915</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.784820</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.832095</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1PHDT66U6IK4Q</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>3.402750</td>\n",
       "      <td>3.887212</td>\n",
       "      <td>3.328217</td>\n",
       "      <td>3.025835</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.630580</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.551835</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1QT3YA7G8MO63</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>2.179628</td>\n",
       "      <td>5.824137</td>\n",
       "      <td>4.566682</td>\n",
       "      <td>2.108613</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.419573</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1SNC8UL8YFRH5</th>\n",
       "      <td>0.950000</td>\n",
       "      <td>2.849197</td>\n",
       "      <td>5.251533</td>\n",
       "      <td>2.953868</td>\n",
       "      <td>2.531735</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.024775</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.998547</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1TKZIBGTP7FE8</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.991212</td>\n",
       "      <td>2.189186</td>\n",
       "      <td>1.797717</td>\n",
       "      <td>0.750100</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.256275</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.919040</td>\n",
       "      <td>0.45</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A25PFSORDO3SWQ</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>3.455526</td>\n",
       "      <td>6.371400</td>\n",
       "      <td>3.391540</td>\n",
       "      <td>2.568222</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4.338150</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.367053</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2IP3ZAFYGV8M9</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.459743</td>\n",
       "      <td>3.212108</td>\n",
       "      <td>2.271652</td>\n",
       "      <td>1.919185</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.397835</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.062210</td>\n",
       "      <td>0.80</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>3.395992</td>\n",
       "      <td>8.932178</td>\n",
       "      <td>4.735722</td>\n",
       "      <td>2.910815</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.436135</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3.677235</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2VLTSW6CXIUMR</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>2.576651</td>\n",
       "      <td>6.455925</td>\n",
       "      <td>4.265116</td>\n",
       "      <td>2.277589</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.048544</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.436055</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2YVQKJX3FO6P</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>2.029552</td>\n",
       "      <td>4.448885</td>\n",
       "      <td>2.122971</td>\n",
       "      <td>1.884474</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.110789</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.090200</td>\n",
       "      <td>0.65</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A39VAFCIGP83ER</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.386998</td>\n",
       "      <td>4.620622</td>\n",
       "      <td>7.244532</td>\n",
       "      <td>1.586317</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.274412</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.281918</td>\n",
       "      <td>0.30</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3ATB5GC4BQIH0</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>2.528883</td>\n",
       "      <td>2.190962</td>\n",
       "      <td>2.787294</td>\n",
       "      <td>2.360500</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.264600</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.961550</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3BU8UL4W258UU</th>\n",
       "      <td>0.883333</td>\n",
       "      <td>1.727167</td>\n",
       "      <td>1.518571</td>\n",
       "      <td>1.754717</td>\n",
       "      <td>1.580650</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.772500</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.828350</td>\n",
       "      <td>0.75</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3CH1Z6J9R38G9</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.072950</td>\n",
       "      <td>2.138444</td>\n",
       "      <td>2.044881</td>\n",
       "      <td>1.666555</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.488935</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.063360</td>\n",
       "      <td>0.70</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3KP8KFGG6734Q</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>3.296161</td>\n",
       "      <td>3.560283</td>\n",
       "      <td>3.359219</td>\n",
       "      <td>3.346635</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.184058</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3.352185</td>\n",
       "      <td>0.70</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3SKE5B27HLVO6</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.186576</td>\n",
       "      <td>1.165469</td>\n",
       "      <td>3.284714</td>\n",
       "      <td>1.594050</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.930550</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.027158</td>\n",
       "      <td>0.35</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A7VA2Y4H6U31O</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.886758</td>\n",
       "      <td>3.178275</td>\n",
       "      <td>2.813879</td>\n",
       "      <td>2.498670</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.968625</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.192980</td>\n",
       "      <td>0.90</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A9YPM325MKYLO</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>2.770224</td>\n",
       "      <td>3.618560</td>\n",
       "      <td>3.031076</td>\n",
       "      <td>2.587983</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.981685</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.722780</td>\n",
       "      <td>0.85</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAF1SJ9FCBF75</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>4.622000</td>\n",
       "      <td>11.600500</td>\n",
       "      <td>5.643500</td>\n",
       "      <td>5.164933</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.767941</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5.047000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACGGIBC0P38HU</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>3.626967</td>\n",
       "      <td>4.087800</td>\n",
       "      <td>3.473356</td>\n",
       "      <td>3.687350</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.229050</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.964500</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGZ3QJFK1BR8V</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.188233</td>\n",
       "      <td>0.045533</td>\n",
       "      <td>0.223550</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARR9GKAG3JFE5</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>2.778034</td>\n",
       "      <td>2.802258</td>\n",
       "      <td>3.989345</td>\n",
       "      <td>2.737150</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.769158</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.827350</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXPZAP62ZYWP8</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.050918</td>\n",
       "      <td>1.017580</td>\n",
       "      <td>1.074731</td>\n",
       "      <td>1.016435</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.033115</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.103205</td>\n",
       "      <td>0.55</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                testing_Test_overall_accuracy  testing_RT_overall_mean  \\\n",
       "A11F3MA5FWH6SJ                       0.766667                 1.996455   \n",
       "A1DZMZTXWOM9MR                       0.833333                 2.044238   \n",
       "A1FJGB5JLZ81XB                       0.900000                 2.011600   \n",
       "A1OM5NWYYYJKQW                       0.833333                 1.865277   \n",
       "A1PHDT66U6IK4Q                       0.866667                 3.402750   \n",
       "A1QT3YA7G8MO63                       0.550000                 2.179628   \n",
       "A1SNC8UL8YFRH5                       0.950000                 2.849197   \n",
       "A1TKZIBGTP7FE8                       0.400000                 0.991212   \n",
       "A25PFSORDO3SWQ                       0.833333                 3.455526   \n",
       "A2IP3ZAFYGV8M9                       0.800000                 2.459743   \n",
       "A2M183CETUMR96                       0.850000                 3.395992   \n",
       "A2VLTSW6CXIUMR                       0.733333                 2.576651   \n",
       "A2YVQKJX3FO6P                        0.566667                 2.029552   \n",
       "A39VAFCIGP83ER                       0.466667                 1.386998   \n",
       "A3ATB5GC4BQIH0                       0.566667                 2.528883   \n",
       "A3BU8UL4W258UU                       0.883333                 1.727167   \n",
       "A3CH1Z6J9R38G9                       0.700000                 2.072950   \n",
       "A3KP8KFGG6734Q                       0.700000                 3.296161   \n",
       "A3SKE5B27HLVO6                       0.466667                 1.186576   \n",
       "A7VA2Y4H6U31O                        0.800000                 2.886758   \n",
       "A9YPM325MKYLO                        0.916667                 2.770224   \n",
       "AAF1SJ9FCBF75                        0.766667                 4.622000   \n",
       "ACGGIBC0P38HU                        0.750000                 3.626967   \n",
       "AGZ3QJFK1BR8V                        0.500000                 0.116883   \n",
       "ARR9GKAG3JFE5                        0.483333                 2.778034   \n",
       "AXPZAP62ZYWP8                        0.583333                 1.050918   \n",
       "\n",
       "                testing_RT_incorrect_mean  testing_RT_correct_mean  \\\n",
       "A11F3MA5FWH6SJ                   2.024171                 1.988020   \n",
       "A1DZMZTXWOM9MR                   2.335260                 1.986034   \n",
       "A1FJGB5JLZ81XB                   2.293350                 1.980294   \n",
       "A1OM5NWYYYJKQW                   1.954120                 1.847508   \n",
       "A1PHDT66U6IK4Q                   3.887212                 3.328217   \n",
       "A1QT3YA7G8MO63                   5.824137                 4.566682   \n",
       "A1SNC8UL8YFRH5                   5.251533                 2.953868   \n",
       "A1TKZIBGTP7FE8                   2.189186                 1.797717   \n",
       "A25PFSORDO3SWQ                   6.371400                 3.391540   \n",
       "A2IP3ZAFYGV8M9                   3.212108                 2.271652   \n",
       "A2M183CETUMR96                   8.932178                 4.735722   \n",
       "A2VLTSW6CXIUMR                   6.455925                 4.265116   \n",
       "A2YVQKJX3FO6P                    4.448885                 2.122971   \n",
       "A39VAFCIGP83ER                   4.620622                 7.244532   \n",
       "A3ATB5GC4BQIH0                   2.190962                 2.787294   \n",
       "A3BU8UL4W258UU                   1.518571                 1.754717   \n",
       "A3CH1Z6J9R38G9                   2.138444                 2.044881   \n",
       "A3KP8KFGG6734Q                   3.560283                 3.359219   \n",
       "A3SKE5B27HLVO6                   1.165469                 3.284714   \n",
       "A7VA2Y4H6U31O                    3.178275                 2.813879   \n",
       "A9YPM325MKYLO                    3.618560                 3.031076   \n",
       "AAF1SJ9FCBF75                   11.600500                 5.643500   \n",
       "ACGGIBC0P38HU                    4.087800                 3.473356   \n",
       "AGZ3QJFK1BR8V                    0.188233                 0.045533   \n",
       "ARR9GKAG3JFE5                    2.802258                 3.989345   \n",
       "AXPZAP62ZYWP8                    1.017580                 1.074731   \n",
       "\n",
       "                testing_layer_1_rt  testing_layer_1_accuracy  \\\n",
       "A11F3MA5FWH6SJ            2.252405                      0.85   \n",
       "A1DZMZTXWOM9MR            1.940875                      0.65   \n",
       "A1FJGB5JLZ81XB            2.044130                      1.00   \n",
       "A1OM5NWYYYJKQW            1.978915                      0.75   \n",
       "A1PHDT66U6IK4Q            3.025835                      0.85   \n",
       "A1QT3YA7G8MO63            2.108613                      0.75   \n",
       "A1SNC8UL8YFRH5            2.531735                      0.95   \n",
       "A1TKZIBGTP7FE8            0.750100                      0.30   \n",
       "A25PFSORDO3SWQ            2.568222                      0.95   \n",
       "A2IP3ZAFYGV8M9            1.919185                      0.85   \n",
       "A2M183CETUMR96            2.910815                      0.75   \n",
       "A2VLTSW6CXIUMR            2.277589                      0.65   \n",
       "A2YVQKJX3FO6P             1.884474                      0.65   \n",
       "A39VAFCIGP83ER            1.586317                      0.50   \n",
       "A3ATB5GC4BQIH0            2.360500                      0.55   \n",
       "A3BU8UL4W258UU            1.580650                      0.90   \n",
       "A3CH1Z6J9R38G9            1.666555                      0.80   \n",
       "A3KP8KFGG6734Q            3.346635                      0.85   \n",
       "A3SKE5B27HLVO6            1.594050                      0.30   \n",
       "A7VA2Y4H6U31O             2.498670                      0.80   \n",
       "A9YPM325MKYLO             2.587983                      1.00   \n",
       "AAF1SJ9FCBF75             5.164933                      0.70   \n",
       "ACGGIBC0P38HU             3.687350                      0.80   \n",
       "AGZ3QJFK1BR8V             0.223550                      0.55   \n",
       "ARR9GKAG3JFE5             2.737150                      0.45   \n",
       "AXPZAP62ZYWP8             1.016435                      0.60   \n",
       "\n",
       "                testing_layer_2_rt  testing_layer_2_accuracy  \\\n",
       "A11F3MA5FWH6SJ            2.047725                      0.80   \n",
       "A1DZMZTXWOM9MR            2.122665                      1.00   \n",
       "A1FJGB5JLZ81XB            2.064860                      0.80   \n",
       "A1OM5NWYYYJKQW            1.784820                      0.90   \n",
       "A1PHDT66U6IK4Q            3.630580                      0.85   \n",
       "A1QT3YA7G8MO63            2.050000                      0.45   \n",
       "A1SNC8UL8YFRH5            3.024775                      0.95   \n",
       "A1TKZIBGTP7FE8            1.256275                      0.45   \n",
       "A25PFSORDO3SWQ            4.338150                      0.70   \n",
       "A2IP3ZAFYGV8M9            2.397835                      0.75   \n",
       "A2M183CETUMR96            3.436135                      0.90   \n",
       "A2VLTSW6CXIUMR            3.048544                      0.75   \n",
       "A2YVQKJX3FO6P             2.110789                      0.40   \n",
       "A39VAFCIGP83ER            1.274412                      0.60   \n",
       "A3ATB5GC4BQIH0            2.264600                      0.60   \n",
       "A3BU8UL4W258UU            1.772500                      1.00   \n",
       "A3CH1Z6J9R38G9            2.488935                      0.60   \n",
       "A3KP8KFGG6734Q            3.184058                      0.55   \n",
       "A3SKE5B27HLVO6            0.930550                      0.75   \n",
       "A7VA2Y4H6U31O             2.968625                      0.70   \n",
       "A9YPM325MKYLO             2.981685                      0.90   \n",
       "AAF1SJ9FCBF75             3.767941                      0.90   \n",
       "ACGGIBC0P38HU             3.229050                      0.70   \n",
       "AGZ3QJFK1BR8V             0.043100                      0.45   \n",
       "ARR9GKAG3JFE5             2.769158                      0.50   \n",
       "AXPZAP62ZYWP8             1.033115                      0.60   \n",
       "\n",
       "                testing_layer_3_rt  testing_layer_3_accuracy  \\\n",
       "A11F3MA5FWH6SJ            1.689235                      0.65   \n",
       "A1DZMZTXWOM9MR            2.069175                      0.85   \n",
       "A1FJGB5JLZ81XB            1.925810                      0.90   \n",
       "A1OM5NWYYYJKQW            1.832095                      0.85   \n",
       "A1PHDT66U6IK4Q            3.551835                      0.90   \n",
       "A1QT3YA7G8MO63            2.419573                      0.45   \n",
       "A1SNC8UL8YFRH5            2.998547                      0.95   \n",
       "A1TKZIBGTP7FE8            0.919040                      0.45   \n",
       "A25PFSORDO3SWQ            3.367053                      0.85   \n",
       "A2IP3ZAFYGV8M9            3.062210                      0.80   \n",
       "A2M183CETUMR96            3.677235                      0.90   \n",
       "A2VLTSW6CXIUMR            2.436055                      0.80   \n",
       "A2YVQKJX3FO6P             2.090200                      0.65   \n",
       "A39VAFCIGP83ER            1.281918                      0.30   \n",
       "A3ATB5GC4BQIH0            2.961550                      0.55   \n",
       "A3BU8UL4W258UU            1.828350                      0.75   \n",
       "A3CH1Z6J9R38G9            2.063360                      0.70   \n",
       "A3KP8KFGG6734Q            3.352185                      0.70   \n",
       "A3SKE5B27HLVO6            1.027158                      0.35   \n",
       "A7VA2Y4H6U31O             3.192980                      0.90   \n",
       "A9YPM325MKYLO             2.722780                      0.85   \n",
       "AAF1SJ9FCBF75             5.047000                      0.70   \n",
       "ACGGIBC0P38HU             3.964500                      0.75   \n",
       "AGZ3QJFK1BR8V             0.084000                      0.50   \n",
       "ARR9GKAG3JFE5             2.827350                      0.50   \n",
       "AXPZAP62ZYWP8             1.103205                      0.55   \n",
       "\n",
       "                testing_longest_response_strike  \n",
       "A11F3MA5FWH6SJ                              4.0  \n",
       "A1DZMZTXWOM9MR                              5.0  \n",
       "A1FJGB5JLZ81XB                              6.0  \n",
       "A1OM5NWYYYJKQW                              5.0  \n",
       "A1PHDT66U6IK4Q                              4.0  \n",
       "A1QT3YA7G8MO63                              4.0  \n",
       "A1SNC8UL8YFRH5                              5.0  \n",
       "A1TKZIBGTP7FE8                              7.0  \n",
       "A25PFSORDO3SWQ                              4.0  \n",
       "A2IP3ZAFYGV8M9                              6.0  \n",
       "A2M183CETUMR96                              6.0  \n",
       "A2VLTSW6CXIUMR                              3.0  \n",
       "A2YVQKJX3FO6P                               5.0  \n",
       "A39VAFCIGP83ER                             13.0  \n",
       "A3ATB5GC4BQIH0                              3.0  \n",
       "A3BU8UL4W258UU                              6.0  \n",
       "A3CH1Z6J9R38G9                              6.0  \n",
       "A3KP8KFGG6734Q                              6.0  \n",
       "A3SKE5B27HLVO6                             11.0  \n",
       "A7VA2Y4H6U31O                               8.0  \n",
       "A9YPM325MKYLO                               6.0  \n",
       "AAF1SJ9FCBF75                               4.0  \n",
       "ACGGIBC0P38HU                               5.0  \n",
       "AGZ3QJFK1BR8V                               3.0  \n",
       "ARR9GKAG3JFE5                               4.0  \n",
       "AXPZAP62ZYWP8                               5.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this part extract summary information from the experiment testing phase: attention check accuracy and timings: \n",
    "all_subjects_summary_testing_info=pd.DataFrame(index=list(all_subjects_test_df['subject'].unique()))\n",
    "\n",
    "\n",
    "#this code calculates response time averages (RT) exlcusing the trials that are TOO long: \n",
    "trial_too_long_exclusion_criteria=10\n",
    "\n",
    "\n",
    "for cur_subject in all_subjects_test_df['subject'].unique():\n",
    "    cur_sub_testing=all_subjects_test_df.loc[all_subjects_test_df['subject']==cur_subject]\n",
    "\n",
    "    #get the correctness of the testing phase: \n",
    "    cur_sub_testing_performence=cur_sub_testing[['correct','test_test_response.keys','test_test_response.rt','layer','test_test_response.corr']].copy().dropna()\n",
    "\n",
    "\n",
    "    test_match_df=pd.DataFrame(columns=['correct'],data=cur_sub_testing_performence['correct']==cur_sub_testing_performence['test_test_response.keys'])\n",
    "    test_match_df['test_test_response.rt']=cur_sub_testing_performence['test_test_response.rt']\n",
    "    accuracy=test_match_df['correct'].mean()\n",
    "\n",
    "    # if there is one rt that is very long, lets not include it in the mean calculation \n",
    "    \n",
    "    mean_rt=(test_match_df.loc[test_match_df['test_test_response.rt']<=trial_too_long_exclusion_criteria,'test_test_response.rt']).mean()\n",
    "    correct_and_incorrect_rts_overall=test_match_df.groupby('correct').aggregate({'test_test_response.rt':'mean'})\n",
    "    \n",
    "    #update the summary info row: \n",
    "    all_subjects_summary_testing_info.loc[cur_subject,'Test_overall_accuracy']=accuracy\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,'RT_overall_mean']=mean_rt\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,['RT_incorrect_mean','RT_correct_mean']]=np.nan\n",
    "\n",
    "    if False in correct_and_incorrect_rts_overall.index:\n",
    "        all_subjects_summary_testing_info.loc[cur_subject,'RT_incorrect_mean']=correct_and_incorrect_rts_overall.loc[False].values[0]\n",
    "    if True in correct_and_incorrect_rts_overall.index:\n",
    "        all_subjects_summary_testing_info.loc[cur_subject,'RT_correct_mean']=correct_and_incorrect_rts_overall.loc[True].values[0]\n",
    "\n",
    "\n",
    "\n",
    "    #extract layer wise information (accuracy and rt):\n",
    "    cur_sub_testing_performence_copy=cur_sub_testing_performence.copy()\n",
    "    cur_sub_testing_performence_copy.loc[cur_sub_testing_performence_copy['test_test_response.rt']>trial_too_long_exclusion_criteria,'test_test_response.rt']=nan\n",
    "    correct_and_incorrect_rts=cur_sub_testing_performence_copy.groupby('layer').aggregate({'test_test_response.rt':'mean','test_test_response.corr':'mean'})\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,['layer_1_rt','layer_1_accuracy','layer_2_rt','layer_2_accuracy','layer_3_rt','layer_3_accuracy']]=correct_and_incorrect_rts.values.flatten()\n",
    "\n",
    "\n",
    "    #check the longest structured strike (to find bots or very unattentive participants):\n",
    "    responses=cur_sub_testing_performence['test_test_response.keys'].replace({'left':1,'right':2}).values\n",
    "    max_iter=find_largest_consequtive_repetition(responses)\n",
    "\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,'longest_response_strike']=max_iter\n",
    "\n",
    "#add a prefix to column names: \n",
    "all_subjects_summary_testing_info.columns=['testing_'+col for col in all_subjects_summary_testing_info.columns]        \n",
    "all_subjects_summary_testing_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>test_test_response.keys</th>\n",
       "      <th>test_test_response.rt</th>\n",
       "      <th>layer</th>\n",
       "      <th>test_test_response.corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.3672</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0474</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>0.9064</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0347</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.1509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.1402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.2994</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0686</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.9004</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>0.9939</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.8215</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.9447</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>0.9341</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.6534</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.5532</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.1674</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0342</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.3504</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.3287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0531</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.2105</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.2238</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>0.7081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.2418</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.4417</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.1941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.1591</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.8218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>0.8495</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>0.8925</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>0.8247</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>0.7942</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.1579</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.4864</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.4962</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.7903</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>0.9562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.4161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.1362</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.1711</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>0.7961</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>0.7197</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.1483</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.1005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.2401</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.8534</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>0.6422</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.5974</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     correct test_test_response.keys  test_test_response.rt  layer  \\\n",
       "1500   right                   right                 1.3672    1.0   \n",
       "1501    left                   right                 1.0474    3.0   \n",
       "1502    left                    left                 0.9064    3.0   \n",
       "1503   right                   right                 0.9375    1.0   \n",
       "1504    left                   right                 1.0347    3.0   \n",
       "1505   right                    left                 1.1509    1.0   \n",
       "1506   right                   right                 1.1402    1.0   \n",
       "1507    left                   right                 1.2994    3.0   \n",
       "1508   right                   right                 1.0686    2.0   \n",
       "1509    left                   right                 0.9004    3.0   \n",
       "1510    left                    left                 0.9939    3.0   \n",
       "1511   right                    left                 0.8215    2.0   \n",
       "1512    left                   right                 0.9447    3.0   \n",
       "1513    left                    left                 0.9341    3.0   \n",
       "1514    left                    left                 1.6534    3.0   \n",
       "1515    left                   right                 0.7614    3.0   \n",
       "1516   right                    left                 1.5532    2.0   \n",
       "1517   right                   right                 1.2835    1.0   \n",
       "1518   right                   right                 0.8005    1.0   \n",
       "1519    left                    left                 1.1674    2.0   \n",
       "1520   right                   right                 1.0342    2.0   \n",
       "1521    left                    left                 1.3504    2.0   \n",
       "1522   right                   right                 1.3287    2.0   \n",
       "1523   right                   right                 1.0531    3.0   \n",
       "1524    left                   right                 1.2105    3.0   \n",
       "1525    left                    left                 1.2238    3.0   \n",
       "1526    left                    left                 0.7081    2.0   \n",
       "1527   right                    left                 0.5850    1.0   \n",
       "1528   right                    left                 1.2418    2.0   \n",
       "1529    left                    left                 1.4417    3.0   \n",
       "1530   right                   right                 1.1941    1.0   \n",
       "1531    left                   right                 1.1591    1.0   \n",
       "1532    left                   right                 0.8218    1.0   \n",
       "1533   right                   right                 0.8495    1.0   \n",
       "1534    left                    left                 0.8925    3.0   \n",
       "1535   right                    left                 0.9688    2.0   \n",
       "1536    left                   right                 0.9830    1.0   \n",
       "1537    left                    left                 0.8247    3.0   \n",
       "1538    left                    left                 0.7942    1.0   \n",
       "1539    left                   right                 1.1579    1.0   \n",
       "1540    left                   right                 1.4864    3.0   \n",
       "1541   right                   right                 0.9643    1.0   \n",
       "1542   right                   right                 1.4962    2.0   \n",
       "1543    left                   right                 0.7903    2.0   \n",
       "1544   right                   right                 0.9562    1.0   \n",
       "1545    left                    left                 1.4161    2.0   \n",
       "1546    left                    left                 1.0520    1.0   \n",
       "1547    left                   right                 1.0400    1.0   \n",
       "1548   right                   right                 1.1362    3.0   \n",
       "1549    left                   right                 0.9913    1.0   \n",
       "1550   right                    left                 1.1711    3.0   \n",
       "1551   right                    left                 0.8681    2.0   \n",
       "1552   right                   right                 0.7961    2.0   \n",
       "1553   right                   right                 0.7197    2.0   \n",
       "1554    left                    left                 1.1483    3.0   \n",
       "1555    left                    left                 1.1005    1.0   \n",
       "1556   right                   right                 1.2401    2.0   \n",
       "1557   right                    left                 0.8534    2.0   \n",
       "1558    left                    left                 0.6422    2.0   \n",
       "1559    left                   right                 0.5974    2.0   \n",
       "\n",
       "      test_test_response.corr  \n",
       "1500                      1.0  \n",
       "1501                      0.0  \n",
       "1502                      1.0  \n",
       "1503                      1.0  \n",
       "1504                      0.0  \n",
       "1505                      0.0  \n",
       "1506                      1.0  \n",
       "1507                      0.0  \n",
       "1508                      1.0  \n",
       "1509                      0.0  \n",
       "1510                      1.0  \n",
       "1511                      0.0  \n",
       "1512                      0.0  \n",
       "1513                      1.0  \n",
       "1514                      1.0  \n",
       "1515                      0.0  \n",
       "1516                      0.0  \n",
       "1517                      1.0  \n",
       "1518                      1.0  \n",
       "1519                      1.0  \n",
       "1520                      1.0  \n",
       "1521                      1.0  \n",
       "1522                      1.0  \n",
       "1523                      1.0  \n",
       "1524                      0.0  \n",
       "1525                      1.0  \n",
       "1526                      1.0  \n",
       "1527                      0.0  \n",
       "1528                      0.0  \n",
       "1529                      1.0  \n",
       "1530                      1.0  \n",
       "1531                      0.0  \n",
       "1532                      0.0  \n",
       "1533                      1.0  \n",
       "1534                      1.0  \n",
       "1535                      0.0  \n",
       "1536                      0.0  \n",
       "1537                      1.0  \n",
       "1538                      1.0  \n",
       "1539                      0.0  \n",
       "1540                      0.0  \n",
       "1541                      1.0  \n",
       "1542                      1.0  \n",
       "1543                      0.0  \n",
       "1544                      1.0  \n",
       "1545                      1.0  \n",
       "1546                      1.0  \n",
       "1547                      0.0  \n",
       "1548                      1.0  \n",
       "1549                      0.0  \n",
       "1550                      0.0  \n",
       "1551                      0.0  \n",
       "1552                      1.0  \n",
       "1553                      1.0  \n",
       "1554                      1.0  \n",
       "1555                      1.0  \n",
       "1556                      1.0  \n",
       "1557                      0.0  \n",
       "1558                      1.0  \n",
       "1559                      0.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_sub_testing_performence.loc[cur_sub_testing_performence['test_test_response.rt']>trial_too_long_exclusion_criteria,'test_test_response.rt']=nan\n",
    "cur_sub_testing_performence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outlier_responses(sub_test_dataframe,fast_threshold=0.1,fast_allowed_count=2,slow_threshold=10,slow_allowed_count=2):\n",
    "    isfast_outlier=(sub_test_dataframe['test_test_response.rt']<fast_threshold).sum()>fast_allowed_count\n",
    "    isslow_outlier=(sub_test_dataframe['test_test_response.rt']>slow_threshold).sum()>slow_allowed_count\n",
    "    return isfast_outlier,isslow_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary for criterions:\n",
      "demo accuracy higher than 0.0 - qualified: 26\n",
      "demo attention check correctness equals 1.0 - qualified: 26\n",
      "experiment encoding attention check accuracy 0.6 - qualified: 25\n",
      "experiment longest consequtive strike of maximum of  15.0 responses - qualified: 26\n",
      "test too fast (thresold: 0.3, allowed count: 5.0 qualified: 22\n",
      "test too slow (thresold: 15.0, allowed count: 5.0 qualified: 25\n",
      "above chance accuracy in test, qualified: 24\n",
      "OVERALL: number of qualified participants (adhere to all criterions): 20\n"
     ]
    }
   ],
   "source": [
    "#combine all oneliners into a single matrix - 1 line per participant with all information we want:\n",
    "data_df_for_analysis=pd.concat([all_subjects_summary_demo_info,all_subjects_summary_encoding_info,all_subjects_summary_testing_info],axis=1)\n",
    "data_df_for_analysis\n",
    "\n",
    "\n",
    "\n",
    "#as each participant saw 20 distractors per layer, we need atleast 0.75 (15/20) accuracy in one of the layers or above 0.616 (37/60) in the overall: \n",
    "\n",
    "#how many participants would fail the demo (did not correctly answered the arrow or had less than 60% performence)\n",
    "demo_criterions_accuracy=data_df_for_analysis['demo_demo_accuracy']>=criterions_df['demo_accuracy_treshold']\n",
    "demo_criterions_attention_check=data_df_for_analysis['demo_arrow_correct']>=criterions_df['demo_arrow_correctness']\n",
    "#find which participants performed pooly on the attention checks of the experiment encoding phase: \n",
    "encoding_ciriterions=data_df_for_analysis['encoding_arrow_accuracy']>criterions_df['encoding_arrow_accuracy']\n",
    "#remove participants that are too slow: \n",
    "test_criterions_strike=data_df_for_analysis['testing_longest_response_strike']<criterions_df['longest_allowed_consequtive_strike']\n",
    "\n",
    "too_fast_criterions=[]\n",
    "too_slow_criterions=[]\n",
    "for subject in data_df_for_analysis.index:\n",
    "    sub_test_dataframe=all_subjects_test_df[all_subjects_test_df['subject']==subject]\n",
    "    toofast_criterion,tooslow_criterion=find_outlier_responses(sub_test_dataframe,fast_threshold=criterions_df['fast_threshold'],fast_allowed_count=criterions_df['fast_allowed_count'],slow_threshold=criterions_df['slow_threshold'],slow_allowed_count=criterions_df['slow_allowed_count'])\n",
    "    too_slow_criterions.append(not tooslow_criterion)\n",
    "    too_fast_criterions.append(not toofast_criterion)\n",
    "\n",
    "\n",
    "\n",
    "print(f'summary for criterions:')\n",
    "print(f'demo accuracy higher than {criterions_df.demo_accuracy_treshold} - qualified: {demo_criterions_accuracy.sum()}')\n",
    "print(f'demo attention check correctness equals {criterions_df.demo_arrow_correctness} - qualified: {demo_criterions_attention_check.sum()}')\n",
    "print(f'experiment encoding attention check accuracy {criterions_df.encoding_arrow_accuracy} - qualified: {encoding_ciriterions.sum()}')\n",
    "print(f'experiment longest consequtive strike of maximum of  {criterions_df.longest_allowed_consequtive_strike} responses - qualified: {test_criterions_strike.sum()}')\n",
    "print(f'test too fast (thresold: {criterions_df.fast_threshold}, allowed count: {criterions_df.fast_allowed_count} qualified: {sum(too_fast_criterions)}')\n",
    "print(f'test too slow (thresold: {criterions_df.slow_threshold}, allowed count: {criterions_df.slow_allowed_count} qualified: {sum(too_slow_criterions)}')\n",
    "#accuracy criterion on the test: \n",
    "test_accuracy_critertions=(data_df_for_analysis['testing_Test_overall_accuracy']>=criterions_df['binom_averages']) | (data_df_for_analysis[['testing_layer_1_accuracy' ,'testing_layer_2_accuracy' ,'testing_layer_3_accuracy']]>=criterions_df['binom_single_layer']).T.any()\n",
    "#remove participants that were discarded based on behavior up to the test and now qualify or disqualify based on test accuracy (do they have atleast 1 significant (binomial test) accuracy in one layer, or above threshold in overall accuracy )\n",
    "only_qualified=demo_criterions_accuracy & demo_criterions_attention_check & encoding_ciriterions & test_criterions_strike & too_fast_criterions & too_slow_criterions & test_accuracy_critertions\n",
    "print(f'above chance accuracy in test, qualified: {sum(test_accuracy_critertions)}')\n",
    "print(f'OVERALL: number of qualified participants (adhere to all criterions): {sum(only_qualified)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>testing_RT_incorrect_mean</th>\n",
       "      <th>testing_RT_correct_mean</th>\n",
       "      <th>testing_layer_1_rt</th>\n",
       "      <th>testing_layer_1_accuracy</th>\n",
       "      <th>testing_layer_2_rt</th>\n",
       "      <th>testing_layer_2_accuracy</th>\n",
       "      <th>testing_layer_3_rt</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11F3MA5FWH6SJ</th>\n",
       "      <td>1.6953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.201833</td>\n",
       "      <td>3.7117</td>\n",
       "      <td>1.899860</td>\n",
       "      <td>1.20072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1.996455</td>\n",
       "      <td>2.024171</td>\n",
       "      <td>1.988020</td>\n",
       "      <td>2.252405</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.047725</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.689235</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1DZMZTXWOM9MR</th>\n",
       "      <td>0.4941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.277317</td>\n",
       "      <td>2.5012</td>\n",
       "      <td>2.165375</td>\n",
       "      <td>0.55354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.044238</td>\n",
       "      <td>2.335260</td>\n",
       "      <td>1.986034</td>\n",
       "      <td>1.940875</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.122665</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.069175</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1FJGB5JLZ81XB</th>\n",
       "      <td>1.7127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.733967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.733967</td>\n",
       "      <td>1.53006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>2.011600</td>\n",
       "      <td>2.293350</td>\n",
       "      <td>1.980294</td>\n",
       "      <td>2.044130</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.064860</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.925810</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OM5NWYYYJKQW</th>\n",
       "      <td>0.6385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.915917</td>\n",
       "      <td>2.7754</td>\n",
       "      <td>1.744020</td>\n",
       "      <td>0.60996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.865277</td>\n",
       "      <td>1.954120</td>\n",
       "      <td>1.847508</td>\n",
       "      <td>1.978915</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.784820</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.832095</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1PHDT66U6IK4Q</th>\n",
       "      <td>0.7481</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>7.267867</td>\n",
       "      <td>9.1037</td>\n",
       "      <td>6.900700</td>\n",
       "      <td>0.65192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>3.402750</td>\n",
       "      <td>3.887212</td>\n",
       "      <td>3.328217</td>\n",
       "      <td>3.025835</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.630580</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.551835</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A11F3MA5FWH6SJ         1.6953                 1.0            0.833333   \n",
       "A1DZMZTXWOM9MR         0.4941                 1.0            0.666667   \n",
       "A1FJGB5JLZ81XB         1.7127                 1.0            1.000000   \n",
       "A1OM5NWYYYJKQW         0.6385                 1.0            0.833333   \n",
       "A1PHDT66U6IK4Q         0.7481                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A11F3MA5FWH6SJ              2.201833                  3.7117   \n",
       "A1DZMZTXWOM9MR              2.277317                  2.5012   \n",
       "A1FJGB5JLZ81XB              2.733967                     NaN   \n",
       "A1OM5NWYYYJKQW              1.915917                  2.7754   \n",
       "A1PHDT66U6IK4Q              7.267867                  9.1037   \n",
       "\n",
       "                demo_RT_correct_mean  encoding_arrow_mean_rt  \\\n",
       "A11F3MA5FWH6SJ              1.899860                 1.20072   \n",
       "A1DZMZTXWOM9MR              2.165375                 0.55354   \n",
       "A1FJGB5JLZ81XB              2.733967                 1.53006   \n",
       "A1OM5NWYYYJKQW              1.744020                 0.60996   \n",
       "A1PHDT66U6IK4Q              6.900700                 0.65192   \n",
       "\n",
       "                encoding_arrow_accuracy  testing_Test_overall_accuracy  \\\n",
       "A11F3MA5FWH6SJ                      1.0                       0.766667   \n",
       "A1DZMZTXWOM9MR                      1.0                       0.833333   \n",
       "A1FJGB5JLZ81XB                      1.0                       0.900000   \n",
       "A1OM5NWYYYJKQW                      1.0                       0.833333   \n",
       "A1PHDT66U6IK4Q                      1.0                       0.866667   \n",
       "\n",
       "                testing_RT_overall_mean  testing_RT_incorrect_mean  \\\n",
       "A11F3MA5FWH6SJ                 1.996455                   2.024171   \n",
       "A1DZMZTXWOM9MR                 2.044238                   2.335260   \n",
       "A1FJGB5JLZ81XB                 2.011600                   2.293350   \n",
       "A1OM5NWYYYJKQW                 1.865277                   1.954120   \n",
       "A1PHDT66U6IK4Q                 3.402750                   3.887212   \n",
       "\n",
       "                testing_RT_correct_mean  testing_layer_1_rt  \\\n",
       "A11F3MA5FWH6SJ                 1.988020            2.252405   \n",
       "A1DZMZTXWOM9MR                 1.986034            1.940875   \n",
       "A1FJGB5JLZ81XB                 1.980294            2.044130   \n",
       "A1OM5NWYYYJKQW                 1.847508            1.978915   \n",
       "A1PHDT66U6IK4Q                 3.328217            3.025835   \n",
       "\n",
       "                testing_layer_1_accuracy  testing_layer_2_rt  \\\n",
       "A11F3MA5FWH6SJ                      0.85            2.047725   \n",
       "A1DZMZTXWOM9MR                      0.65            2.122665   \n",
       "A1FJGB5JLZ81XB                      1.00            2.064860   \n",
       "A1OM5NWYYYJKQW                      0.75            1.784820   \n",
       "A1PHDT66U6IK4Q                      0.85            3.630580   \n",
       "\n",
       "                testing_layer_2_accuracy  testing_layer_3_rt  \\\n",
       "A11F3MA5FWH6SJ                      0.80            1.689235   \n",
       "A1DZMZTXWOM9MR                      1.00            2.069175   \n",
       "A1FJGB5JLZ81XB                      0.80            1.925810   \n",
       "A1OM5NWYYYJKQW                      0.90            1.832095   \n",
       "A1PHDT66U6IK4Q                      0.85            3.551835   \n",
       "\n",
       "                testing_layer_3_accuracy  testing_longest_response_strike  \n",
       "A11F3MA5FWH6SJ                      0.65                              4.0  \n",
       "A1DZMZTXWOM9MR                      0.85                              5.0  \n",
       "A1FJGB5JLZ81XB                      0.90                              6.0  \n",
       "A1OM5NWYYYJKQW                      0.85                              5.0  \n",
       "A1PHDT66U6IK4Q                      0.90                              4.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_for_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "      <th>not_too_slow</th>\n",
       "      <th>not_too_Fast</th>\n",
       "      <th>sufficient_test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11F3MA5FWH6SJ</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1DZMZTXWOM9MR</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1FJGB5JLZ81XB</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OM5NWYYYJKQW</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1PHDT66U6IK4Q</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1QT3YA7G8MO63</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1SNC8UL8YFRH5</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1TKZIBGTP7FE8</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A25PFSORDO3SWQ</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2IP3ZAFYGV8M9</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2VLTSW6CXIUMR</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2YVQKJX3FO6P</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A39VAFCIGP83ER</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3ATB5GC4BQIH0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3BU8UL4W258UU</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3CH1Z6J9R38G9</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3KP8KFGG6734Q</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3SKE5B27HLVO6</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A7VA2Y4H6U31O</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A9YPM325MKYLO</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAF1SJ9FCBF75</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACGGIBC0P38HU</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGZ3QJFK1BR8V</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARR9GKAG3JFE5</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXPZAP62ZYWP8</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_demo_accuracy  demo_arrow_correct  \\\n",
       "A11F3MA5FWH6SJ                True                True   \n",
       "A1DZMZTXWOM9MR                True                True   \n",
       "A1FJGB5JLZ81XB                True                True   \n",
       "A1OM5NWYYYJKQW                True                True   \n",
       "A1PHDT66U6IK4Q                True                True   \n",
       "A1QT3YA7G8MO63                True                True   \n",
       "A1SNC8UL8YFRH5                True                True   \n",
       "A1TKZIBGTP7FE8                True                True   \n",
       "A25PFSORDO3SWQ                True                True   \n",
       "A2IP3ZAFYGV8M9                True                True   \n",
       "A2M183CETUMR96                True                True   \n",
       "A2VLTSW6CXIUMR                True                True   \n",
       "A2YVQKJX3FO6P                 True                True   \n",
       "A39VAFCIGP83ER                True                True   \n",
       "A3ATB5GC4BQIH0                True                True   \n",
       "A3BU8UL4W258UU                True                True   \n",
       "A3CH1Z6J9R38G9                True                True   \n",
       "A3KP8KFGG6734Q                True                True   \n",
       "A3SKE5B27HLVO6                True                True   \n",
       "A7VA2Y4H6U31O                 True                True   \n",
       "A9YPM325MKYLO                 True                True   \n",
       "AAF1SJ9FCBF75                 True                True   \n",
       "ACGGIBC0P38HU                 True                True   \n",
       "AGZ3QJFK1BR8V                 True                True   \n",
       "ARR9GKAG3JFE5                 True                True   \n",
       "AXPZAP62ZYWP8                 True                True   \n",
       "\n",
       "                encoding_arrow_accuracy  testing_longest_response_strike  \\\n",
       "A11F3MA5FWH6SJ                     True                             True   \n",
       "A1DZMZTXWOM9MR                     True                             True   \n",
       "A1FJGB5JLZ81XB                     True                             True   \n",
       "A1OM5NWYYYJKQW                     True                             True   \n",
       "A1PHDT66U6IK4Q                     True                             True   \n",
       "A1QT3YA7G8MO63                     True                             True   \n",
       "A1SNC8UL8YFRH5                     True                             True   \n",
       "A1TKZIBGTP7FE8                     True                             True   \n",
       "A25PFSORDO3SWQ                     True                             True   \n",
       "A2IP3ZAFYGV8M9                     True                             True   \n",
       "A2M183CETUMR96                     True                             True   \n",
       "A2VLTSW6CXIUMR                     True                             True   \n",
       "A2YVQKJX3FO6P                      True                             True   \n",
       "A39VAFCIGP83ER                     True                             True   \n",
       "A3ATB5GC4BQIH0                     True                             True   \n",
       "A3BU8UL4W258UU                     True                             True   \n",
       "A3CH1Z6J9R38G9                     True                             True   \n",
       "A3KP8KFGG6734Q                     True                             True   \n",
       "A3SKE5B27HLVO6                     True                             True   \n",
       "A7VA2Y4H6U31O                      True                             True   \n",
       "A9YPM325MKYLO                      True                             True   \n",
       "AAF1SJ9FCBF75                      True                             True   \n",
       "ACGGIBC0P38HU                      True                             True   \n",
       "AGZ3QJFK1BR8V                      True                             True   \n",
       "ARR9GKAG3JFE5                     False                             True   \n",
       "AXPZAP62ZYWP8                      True                             True   \n",
       "\n",
       "                not_too_slow  not_too_Fast  sufficient_test_acc  \n",
       "A11F3MA5FWH6SJ          True          True                 True  \n",
       "A1DZMZTXWOM9MR          True          True                 True  \n",
       "A1FJGB5JLZ81XB          True          True                 True  \n",
       "A1OM5NWYYYJKQW          True          True                 True  \n",
       "A1PHDT66U6IK4Q          True          True                 True  \n",
       "A1QT3YA7G8MO63         False          True                 True  \n",
       "A1SNC8UL8YFRH5          True          True                 True  \n",
       "A1TKZIBGTP7FE8          True         False                False  \n",
       "A25PFSORDO3SWQ          True          True                 True  \n",
       "A2IP3ZAFYGV8M9          True          True                 True  \n",
       "A2M183CETUMR96          True          True                 True  \n",
       "A2VLTSW6CXIUMR          True          True                 True  \n",
       "A2YVQKJX3FO6P           True          True                 True  \n",
       "A39VAFCIGP83ER          True         False                 True  \n",
       "A3ATB5GC4BQIH0          True          True                 True  \n",
       "A3BU8UL4W258UU          True          True                 True  \n",
       "A3CH1Z6J9R38G9          True          True                 True  \n",
       "A3KP8KFGG6734Q          True          True                 True  \n",
       "A3SKE5B27HLVO6          True         False                 True  \n",
       "A7VA2Y4H6U31O           True          True                 True  \n",
       "A9YPM325MKYLO           True          True                 True  \n",
       "AAF1SJ9FCBF75           True          True                 True  \n",
       "ACGGIBC0P38HU           True          True                 True  \n",
       "AGZ3QJFK1BR8V           True         False                 True  \n",
       "ARR9GKAG3JFE5           True          True                False  \n",
       "AXPZAP62ZYWP8           True          True                 True  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#update the batch_workers_df  with columns representing disqualification reasons: \n",
    "tooslow_df=pd.DataFrame(data=too_slow_criterions,index=data_df_for_analysis.index,columns=['not_too_slow'])\n",
    "toofast_df=pd.DataFrame(data=too_fast_criterions,index=data_df_for_analysis.index,columns=['not_too_Fast'])\n",
    "test_accuracy_critertions=pd.DataFrame(data=test_accuracy_critertions,index=data_df_for_analysis.index, columns=['sufficient_test_acc'])\n",
    "disqualification_df=pd.concat([demo_criterions_accuracy,demo_criterions_attention_check,encoding_ciriterions,test_criterions_strike,tooslow_df,toofast_df,test_accuracy_critertions],axis=1)\n",
    "disqualification_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge workers_df with disqualification and save: \n",
    "index_list=[ind.split('_')[0] for ind in disqualification_df.index]\n",
    "disqualification_df['WorkerId']=index_list\n",
    "\n",
    "batch_workers_df_extended = workers_df.merge(disqualification_df, left_on='Worker ID', right_on='WorkerId', how = 'inner')\n",
    "batch_workers_df_extended = workers_df.merge(disqualification_df, left_on='Worker ID', right_on='WorkerId', how = 'outer')\n",
    "\n",
    "#add qualification column: (currently any participant will get this qualification (even if he just openneded the experiment and quit, because we dont want him back)\n",
    "batch_workers_df_extended[qualification_name_for_entire_experiment]=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>testing_RT_incorrect_mean</th>\n",
       "      <th>testing_RT_correct_mean</th>\n",
       "      <th>testing_layer_1_rt</th>\n",
       "      <th>testing_layer_1_accuracy</th>\n",
       "      <th>testing_layer_2_rt</th>\n",
       "      <th>testing_layer_2_accuracy</th>\n",
       "      <th>testing_layer_3_rt</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11F3MA5FWH6SJ</th>\n",
       "      <td>1.6953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.201833</td>\n",
       "      <td>3.711700</td>\n",
       "      <td>1.899860</td>\n",
       "      <td>1.20072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1.996455</td>\n",
       "      <td>2.024171</td>\n",
       "      <td>1.988020</td>\n",
       "      <td>2.252405</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.047725</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.689235</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1DZMZTXWOM9MR</th>\n",
       "      <td>0.4941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.277317</td>\n",
       "      <td>2.501200</td>\n",
       "      <td>2.165375</td>\n",
       "      <td>0.55354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.044238</td>\n",
       "      <td>2.335260</td>\n",
       "      <td>1.986034</td>\n",
       "      <td>1.940875</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.122665</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.069175</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1FJGB5JLZ81XB</th>\n",
       "      <td>1.7127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.733967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.733967</td>\n",
       "      <td>1.53006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>2.011600</td>\n",
       "      <td>2.293350</td>\n",
       "      <td>1.980294</td>\n",
       "      <td>2.044130</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.064860</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.925810</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OM5NWYYYJKQW</th>\n",
       "      <td>0.6385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.915917</td>\n",
       "      <td>2.775400</td>\n",
       "      <td>1.744020</td>\n",
       "      <td>0.60996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.865277</td>\n",
       "      <td>1.954120</td>\n",
       "      <td>1.847508</td>\n",
       "      <td>1.978915</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.784820</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.832095</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1PHDT66U6IK4Q</th>\n",
       "      <td>0.7481</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>7.267867</td>\n",
       "      <td>9.103700</td>\n",
       "      <td>6.900700</td>\n",
       "      <td>0.65192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>3.402750</td>\n",
       "      <td>3.887212</td>\n",
       "      <td>3.328217</td>\n",
       "      <td>3.025835</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.630580</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.551835</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1SNC8UL8YFRH5</th>\n",
       "      <td>0.6413</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.468867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.468867</td>\n",
       "      <td>0.59568</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>2.849197</td>\n",
       "      <td>5.251533</td>\n",
       "      <td>2.953868</td>\n",
       "      <td>2.531735</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.024775</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.998547</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A25PFSORDO3SWQ</th>\n",
       "      <td>0.6970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.491833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.491833</td>\n",
       "      <td>0.59020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>3.455526</td>\n",
       "      <td>6.371400</td>\n",
       "      <td>3.391540</td>\n",
       "      <td>2.568222</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4.338150</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.367053</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2IP3ZAFYGV8M9</th>\n",
       "      <td>0.5430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.553317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.553317</td>\n",
       "      <td>0.64668</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.459743</td>\n",
       "      <td>3.212108</td>\n",
       "      <td>2.271652</td>\n",
       "      <td>1.919185</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.397835</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.062210</td>\n",
       "      <td>0.80</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>0.6492</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.756800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.756800</td>\n",
       "      <td>0.49752</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>3.395992</td>\n",
       "      <td>8.932178</td>\n",
       "      <td>4.735722</td>\n",
       "      <td>2.910815</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.436135</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3.677235</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2VLTSW6CXIUMR</th>\n",
       "      <td>0.5889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.188183</td>\n",
       "      <td>1.493000</td>\n",
       "      <td>2.535775</td>\n",
       "      <td>0.51610</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>2.576651</td>\n",
       "      <td>6.455925</td>\n",
       "      <td>4.265116</td>\n",
       "      <td>2.277589</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.048544</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.436055</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2YVQKJX3FO6P</th>\n",
       "      <td>0.8810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.537333</td>\n",
       "      <td>2.273333</td>\n",
       "      <td>2.801333</td>\n",
       "      <td>0.86760</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>2.029552</td>\n",
       "      <td>4.448885</td>\n",
       "      <td>2.122971</td>\n",
       "      <td>1.884474</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.110789</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.090200</td>\n",
       "      <td>0.65</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3ATB5GC4BQIH0</th>\n",
       "      <td>1.0530</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5.599500</td>\n",
       "      <td>10.525000</td>\n",
       "      <td>3.136750</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>2.528883</td>\n",
       "      <td>2.190962</td>\n",
       "      <td>2.787294</td>\n",
       "      <td>2.360500</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.264600</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.961550</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3BU8UL4W258UU</th>\n",
       "      <td>0.5040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.080667</td>\n",
       "      <td>3.154000</td>\n",
       "      <td>1.866000</td>\n",
       "      <td>0.49200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>1.727167</td>\n",
       "      <td>1.518571</td>\n",
       "      <td>1.754717</td>\n",
       "      <td>1.580650</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.772500</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.828350</td>\n",
       "      <td>0.75</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3CH1Z6J9R38G9</th>\n",
       "      <td>0.4123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.319450</td>\n",
       "      <td>1.480133</td>\n",
       "      <td>1.158767</td>\n",
       "      <td>0.53432</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.072950</td>\n",
       "      <td>2.138444</td>\n",
       "      <td>2.044881</td>\n",
       "      <td>1.666555</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.488935</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.063360</td>\n",
       "      <td>0.70</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3KP8KFGG6734Q</th>\n",
       "      <td>1.0667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.486650</td>\n",
       "      <td>1.662100</td>\n",
       "      <td>2.651560</td>\n",
       "      <td>0.79480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>3.296161</td>\n",
       "      <td>3.560283</td>\n",
       "      <td>3.359219</td>\n",
       "      <td>3.346635</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.184058</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3.352185</td>\n",
       "      <td>0.70</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A7VA2Y4H6U31O</th>\n",
       "      <td>0.6330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.786550</td>\n",
       "      <td>3.435600</td>\n",
       "      <td>2.656740</td>\n",
       "      <td>0.52586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.886758</td>\n",
       "      <td>3.178275</td>\n",
       "      <td>2.813879</td>\n",
       "      <td>2.498670</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.968625</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.192980</td>\n",
       "      <td>0.90</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A9YPM325MKYLO</th>\n",
       "      <td>1.8896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.257900</td>\n",
       "      <td>3.288640</td>\n",
       "      <td>3.104200</td>\n",
       "      <td>1.25654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>2.770224</td>\n",
       "      <td>3.618560</td>\n",
       "      <td>3.031076</td>\n",
       "      <td>2.587983</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.981685</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.722780</td>\n",
       "      <td>0.85</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAF1SJ9FCBF75</th>\n",
       "      <td>0.8860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.442833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.442833</td>\n",
       "      <td>0.65480</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>4.622000</td>\n",
       "      <td>11.600500</td>\n",
       "      <td>5.643500</td>\n",
       "      <td>5.164933</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.767941</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5.047000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACGGIBC0P38HU</th>\n",
       "      <td>1.5020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.393500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.393500</td>\n",
       "      <td>1.48880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3.626967</td>\n",
       "      <td>4.087800</td>\n",
       "      <td>3.473356</td>\n",
       "      <td>3.687350</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.229050</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.964500</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXPZAP62ZYWP8</th>\n",
       "      <td>0.7595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.548283</td>\n",
       "      <td>1.399800</td>\n",
       "      <td>1.577980</td>\n",
       "      <td>0.56708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.050918</td>\n",
       "      <td>1.017580</td>\n",
       "      <td>1.074731</td>\n",
       "      <td>1.016435</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.033115</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.103205</td>\n",
       "      <td>0.55</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A11F3MA5FWH6SJ         1.6953                 1.0            0.833333   \n",
       "A1DZMZTXWOM9MR         0.4941                 1.0            0.666667   \n",
       "A1FJGB5JLZ81XB         1.7127                 1.0            1.000000   \n",
       "A1OM5NWYYYJKQW         0.6385                 1.0            0.833333   \n",
       "A1PHDT66U6IK4Q         0.7481                 1.0            0.833333   \n",
       "A1SNC8UL8YFRH5         0.6413                 1.0            1.000000   \n",
       "A25PFSORDO3SWQ         0.6970                 1.0            1.000000   \n",
       "A2IP3ZAFYGV8M9         0.5430                 1.0            1.000000   \n",
       "A2M183CETUMR96         0.6492                 1.0            1.000000   \n",
       "A2VLTSW6CXIUMR         0.5889                 1.0            0.666667   \n",
       "A2YVQKJX3FO6P          0.8810                 1.0            0.500000   \n",
       "A3ATB5GC4BQIH0         1.0530                 1.0            0.666667   \n",
       "A3BU8UL4W258UU         0.5040                 1.0            0.833333   \n",
       "A3CH1Z6J9R38G9         0.4123                 1.0            0.500000   \n",
       "A3KP8KFGG6734Q         1.0667                 1.0            0.833333   \n",
       "A7VA2Y4H6U31O          0.6330                 1.0            0.833333   \n",
       "A9YPM325MKYLO          1.8896                 1.0            0.166667   \n",
       "AAF1SJ9FCBF75          0.8860                 1.0            1.000000   \n",
       "ACGGIBC0P38HU          1.5020                 1.0            1.000000   \n",
       "AXPZAP62ZYWP8          0.7595                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A11F3MA5FWH6SJ              2.201833                3.711700   \n",
       "A1DZMZTXWOM9MR              2.277317                2.501200   \n",
       "A1FJGB5JLZ81XB              2.733967                     NaN   \n",
       "A1OM5NWYYYJKQW              1.915917                2.775400   \n",
       "A1PHDT66U6IK4Q              7.267867                9.103700   \n",
       "A1SNC8UL8YFRH5              2.468867                     NaN   \n",
       "A25PFSORDO3SWQ              2.491833                     NaN   \n",
       "A2IP3ZAFYGV8M9              1.553317                     NaN   \n",
       "A2M183CETUMR96              2.756800                     NaN   \n",
       "A2VLTSW6CXIUMR              2.188183                1.493000   \n",
       "A2YVQKJX3FO6P               2.537333                2.273333   \n",
       "A3ATB5GC4BQIH0              5.599500               10.525000   \n",
       "A3BU8UL4W258UU              2.080667                3.154000   \n",
       "A3CH1Z6J9R38G9              1.319450                1.480133   \n",
       "A3KP8KFGG6734Q              2.486650                1.662100   \n",
       "A7VA2Y4H6U31O               2.786550                3.435600   \n",
       "A9YPM325MKYLO               3.257900                3.288640   \n",
       "AAF1SJ9FCBF75               5.442833                     NaN   \n",
       "ACGGIBC0P38HU               2.393500                     NaN   \n",
       "AXPZAP62ZYWP8               1.548283                1.399800   \n",
       "\n",
       "                demo_RT_correct_mean  encoding_arrow_mean_rt  \\\n",
       "A11F3MA5FWH6SJ              1.899860                 1.20072   \n",
       "A1DZMZTXWOM9MR              2.165375                 0.55354   \n",
       "A1FJGB5JLZ81XB              2.733967                 1.53006   \n",
       "A1OM5NWYYYJKQW              1.744020                 0.60996   \n",
       "A1PHDT66U6IK4Q              6.900700                 0.65192   \n",
       "A1SNC8UL8YFRH5              2.468867                 0.59568   \n",
       "A25PFSORDO3SWQ              2.491833                 0.59020   \n",
       "A2IP3ZAFYGV8M9              1.553317                 0.64668   \n",
       "A2M183CETUMR96              2.756800                 0.49752   \n",
       "A2VLTSW6CXIUMR              2.535775                 0.51610   \n",
       "A2YVQKJX3FO6P               2.801333                 0.86760   \n",
       "A3ATB5GC4BQIH0              3.136750                 0.92120   \n",
       "A3BU8UL4W258UU              1.866000                 0.49200   \n",
       "A3CH1Z6J9R38G9              1.158767                 0.53432   \n",
       "A3KP8KFGG6734Q              2.651560                 0.79480   \n",
       "A7VA2Y4H6U31O               2.656740                 0.52586   \n",
       "A9YPM325MKYLO               3.104200                 1.25654   \n",
       "AAF1SJ9FCBF75               5.442833                 0.65480   \n",
       "ACGGIBC0P38HU               2.393500                 1.48880   \n",
       "AXPZAP62ZYWP8               1.577980                 0.56708   \n",
       "\n",
       "                encoding_arrow_accuracy  testing_Test_overall_accuracy  \\\n",
       "A11F3MA5FWH6SJ                      1.0                       0.766667   \n",
       "A1DZMZTXWOM9MR                      1.0                       0.833333   \n",
       "A1FJGB5JLZ81XB                      1.0                       0.900000   \n",
       "A1OM5NWYYYJKQW                      1.0                       0.833333   \n",
       "A1PHDT66U6IK4Q                      1.0                       0.866667   \n",
       "A1SNC8UL8YFRH5                      1.0                       0.950000   \n",
       "A25PFSORDO3SWQ                      1.0                       0.833333   \n",
       "A2IP3ZAFYGV8M9                      1.0                       0.800000   \n",
       "A2M183CETUMR96                      1.0                       0.850000   \n",
       "A2VLTSW6CXIUMR                      0.8                       0.733333   \n",
       "A2YVQKJX3FO6P                       1.0                       0.566667   \n",
       "A3ATB5GC4BQIH0                      1.0                       0.566667   \n",
       "A3BU8UL4W258UU                      1.0                       0.883333   \n",
       "A3CH1Z6J9R38G9                      0.8                       0.700000   \n",
       "A3KP8KFGG6734Q                      1.0                       0.700000   \n",
       "A7VA2Y4H6U31O                       1.0                       0.800000   \n",
       "A9YPM325MKYLO                       1.0                       0.916667   \n",
       "AAF1SJ9FCBF75                       0.8                       0.766667   \n",
       "ACGGIBC0P38HU                       1.0                       0.750000   \n",
       "AXPZAP62ZYWP8                       1.0                       0.583333   \n",
       "\n",
       "                testing_RT_overall_mean  testing_RT_incorrect_mean  \\\n",
       "A11F3MA5FWH6SJ                 1.996455                   2.024171   \n",
       "A1DZMZTXWOM9MR                 2.044238                   2.335260   \n",
       "A1FJGB5JLZ81XB                 2.011600                   2.293350   \n",
       "A1OM5NWYYYJKQW                 1.865277                   1.954120   \n",
       "A1PHDT66U6IK4Q                 3.402750                   3.887212   \n",
       "A1SNC8UL8YFRH5                 2.849197                   5.251533   \n",
       "A25PFSORDO3SWQ                 3.455526                   6.371400   \n",
       "A2IP3ZAFYGV8M9                 2.459743                   3.212108   \n",
       "A2M183CETUMR96                 3.395992                   8.932178   \n",
       "A2VLTSW6CXIUMR                 2.576651                   6.455925   \n",
       "A2YVQKJX3FO6P                  2.029552                   4.448885   \n",
       "A3ATB5GC4BQIH0                 2.528883                   2.190962   \n",
       "A3BU8UL4W258UU                 1.727167                   1.518571   \n",
       "A3CH1Z6J9R38G9                 2.072950                   2.138444   \n",
       "A3KP8KFGG6734Q                 3.296161                   3.560283   \n",
       "A7VA2Y4H6U31O                  2.886758                   3.178275   \n",
       "A9YPM325MKYLO                  2.770224                   3.618560   \n",
       "AAF1SJ9FCBF75                  4.622000                  11.600500   \n",
       "ACGGIBC0P38HU                  3.626967                   4.087800   \n",
       "AXPZAP62ZYWP8                  1.050918                   1.017580   \n",
       "\n",
       "                testing_RT_correct_mean  testing_layer_1_rt  \\\n",
       "A11F3MA5FWH6SJ                 1.988020            2.252405   \n",
       "A1DZMZTXWOM9MR                 1.986034            1.940875   \n",
       "A1FJGB5JLZ81XB                 1.980294            2.044130   \n",
       "A1OM5NWYYYJKQW                 1.847508            1.978915   \n",
       "A1PHDT66U6IK4Q                 3.328217            3.025835   \n",
       "A1SNC8UL8YFRH5                 2.953868            2.531735   \n",
       "A25PFSORDO3SWQ                 3.391540            2.568222   \n",
       "A2IP3ZAFYGV8M9                 2.271652            1.919185   \n",
       "A2M183CETUMR96                 4.735722            2.910815   \n",
       "A2VLTSW6CXIUMR                 4.265116            2.277589   \n",
       "A2YVQKJX3FO6P                  2.122971            1.884474   \n",
       "A3ATB5GC4BQIH0                 2.787294            2.360500   \n",
       "A3BU8UL4W258UU                 1.754717            1.580650   \n",
       "A3CH1Z6J9R38G9                 2.044881            1.666555   \n",
       "A3KP8KFGG6734Q                 3.359219            3.346635   \n",
       "A7VA2Y4H6U31O                  2.813879            2.498670   \n",
       "A9YPM325MKYLO                  3.031076            2.587983   \n",
       "AAF1SJ9FCBF75                  5.643500            5.164933   \n",
       "ACGGIBC0P38HU                  3.473356            3.687350   \n",
       "AXPZAP62ZYWP8                  1.074731            1.016435   \n",
       "\n",
       "                testing_layer_1_accuracy  testing_layer_2_rt  \\\n",
       "A11F3MA5FWH6SJ                      0.85            2.047725   \n",
       "A1DZMZTXWOM9MR                      0.65            2.122665   \n",
       "A1FJGB5JLZ81XB                      1.00            2.064860   \n",
       "A1OM5NWYYYJKQW                      0.75            1.784820   \n",
       "A1PHDT66U6IK4Q                      0.85            3.630580   \n",
       "A1SNC8UL8YFRH5                      0.95            3.024775   \n",
       "A25PFSORDO3SWQ                      0.95            4.338150   \n",
       "A2IP3ZAFYGV8M9                      0.85            2.397835   \n",
       "A2M183CETUMR96                      0.75            3.436135   \n",
       "A2VLTSW6CXIUMR                      0.65            3.048544   \n",
       "A2YVQKJX3FO6P                       0.65            2.110789   \n",
       "A3ATB5GC4BQIH0                      0.55            2.264600   \n",
       "A3BU8UL4W258UU                      0.90            1.772500   \n",
       "A3CH1Z6J9R38G9                      0.80            2.488935   \n",
       "A3KP8KFGG6734Q                      0.85            3.184058   \n",
       "A7VA2Y4H6U31O                       0.80            2.968625   \n",
       "A9YPM325MKYLO                       1.00            2.981685   \n",
       "AAF1SJ9FCBF75                       0.70            3.767941   \n",
       "ACGGIBC0P38HU                       0.80            3.229050   \n",
       "AXPZAP62ZYWP8                       0.60            1.033115   \n",
       "\n",
       "                testing_layer_2_accuracy  testing_layer_3_rt  \\\n",
       "A11F3MA5FWH6SJ                      0.80            1.689235   \n",
       "A1DZMZTXWOM9MR                      1.00            2.069175   \n",
       "A1FJGB5JLZ81XB                      0.80            1.925810   \n",
       "A1OM5NWYYYJKQW                      0.90            1.832095   \n",
       "A1PHDT66U6IK4Q                      0.85            3.551835   \n",
       "A1SNC8UL8YFRH5                      0.95            2.998547   \n",
       "A25PFSORDO3SWQ                      0.70            3.367053   \n",
       "A2IP3ZAFYGV8M9                      0.75            3.062210   \n",
       "A2M183CETUMR96                      0.90            3.677235   \n",
       "A2VLTSW6CXIUMR                      0.75            2.436055   \n",
       "A2YVQKJX3FO6P                       0.40            2.090200   \n",
       "A3ATB5GC4BQIH0                      0.60            2.961550   \n",
       "A3BU8UL4W258UU                      1.00            1.828350   \n",
       "A3CH1Z6J9R38G9                      0.60            2.063360   \n",
       "A3KP8KFGG6734Q                      0.55            3.352185   \n",
       "A7VA2Y4H6U31O                       0.70            3.192980   \n",
       "A9YPM325MKYLO                       0.90            2.722780   \n",
       "AAF1SJ9FCBF75                       0.90            5.047000   \n",
       "ACGGIBC0P38HU                       0.70            3.964500   \n",
       "AXPZAP62ZYWP8                       0.60            1.103205   \n",
       "\n",
       "                testing_layer_3_accuracy  testing_longest_response_strike  \n",
       "A11F3MA5FWH6SJ                      0.65                              4.0  \n",
       "A1DZMZTXWOM9MR                      0.85                              5.0  \n",
       "A1FJGB5JLZ81XB                      0.90                              6.0  \n",
       "A1OM5NWYYYJKQW                      0.85                              5.0  \n",
       "A1PHDT66U6IK4Q                      0.90                              4.0  \n",
       "A1SNC8UL8YFRH5                      0.95                              5.0  \n",
       "A25PFSORDO3SWQ                      0.85                              4.0  \n",
       "A2IP3ZAFYGV8M9                      0.80                              6.0  \n",
       "A2M183CETUMR96                      0.90                              6.0  \n",
       "A2VLTSW6CXIUMR                      0.80                              3.0  \n",
       "A2YVQKJX3FO6P                       0.65                              5.0  \n",
       "A3ATB5GC4BQIH0                      0.55                              3.0  \n",
       "A3BU8UL4W258UU                      0.75                              6.0  \n",
       "A3CH1Z6J9R38G9                      0.70                              6.0  \n",
       "A3KP8KFGG6734Q                      0.70                              6.0  \n",
       "A7VA2Y4H6U31O                       0.90                              8.0  \n",
       "A9YPM325MKYLO                       0.85                              6.0  \n",
       "AAF1SJ9FCBF75                       0.70                              4.0  \n",
       "ACGGIBC0P38HU                       0.75                              5.0  \n",
       "AXPZAP62ZYWP8                       0.55                              5.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract data that passes all criterions: \n",
    "final_participants_df=data_df_for_analysis[only_qualified]\n",
    "final_participants_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "      <th>not_too_slow</th>\n",
       "      <th>not_too_Fast</th>\n",
       "      <th>sufficient_test_acc</th>\n",
       "      <th>WorkerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11F3MA5FWH6SJ</th>\n",
       "      <td>1.6953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.201833</td>\n",
       "      <td>3.7117</td>\n",
       "      <td>1.899860</td>\n",
       "      <td>1.20072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1.996455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A11F3MA5FWH6SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1DZMZTXWOM9MR</th>\n",
       "      <td>0.4941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.277317</td>\n",
       "      <td>2.5012</td>\n",
       "      <td>2.165375</td>\n",
       "      <td>0.55354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.044238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A1DZMZTXWOM9MR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1FJGB5JLZ81XB</th>\n",
       "      <td>1.7127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.733967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.733967</td>\n",
       "      <td>1.53006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>2.011600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A1FJGB5JLZ81XB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OM5NWYYYJKQW</th>\n",
       "      <td>0.6385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.915917</td>\n",
       "      <td>2.7754</td>\n",
       "      <td>1.744020</td>\n",
       "      <td>0.60996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.865277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A1OM5NWYYYJKQW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1PHDT66U6IK4Q</th>\n",
       "      <td>0.7481</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>7.267867</td>\n",
       "      <td>9.1037</td>\n",
       "      <td>6.900700</td>\n",
       "      <td>0.65192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>3.402750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A1PHDT66U6IK4Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A11F3MA5FWH6SJ         1.6953                 1.0            0.833333   \n",
       "A1DZMZTXWOM9MR         0.4941                 1.0            0.666667   \n",
       "A1FJGB5JLZ81XB         1.7127                 1.0            1.000000   \n",
       "A1OM5NWYYYJKQW         0.6385                 1.0            0.833333   \n",
       "A1PHDT66U6IK4Q         0.7481                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A11F3MA5FWH6SJ              2.201833                  3.7117   \n",
       "A1DZMZTXWOM9MR              2.277317                  2.5012   \n",
       "A1FJGB5JLZ81XB              2.733967                     NaN   \n",
       "A1OM5NWYYYJKQW              1.915917                  2.7754   \n",
       "A1PHDT66U6IK4Q              7.267867                  9.1037   \n",
       "\n",
       "                demo_RT_correct_mean  encoding_arrow_mean_rt  \\\n",
       "A11F3MA5FWH6SJ              1.899860                 1.20072   \n",
       "A1DZMZTXWOM9MR              2.165375                 0.55354   \n",
       "A1FJGB5JLZ81XB              2.733967                 1.53006   \n",
       "A1OM5NWYYYJKQW              1.744020                 0.60996   \n",
       "A1PHDT66U6IK4Q              6.900700                 0.65192   \n",
       "\n",
       "                encoding_arrow_accuracy  testing_Test_overall_accuracy  \\\n",
       "A11F3MA5FWH6SJ                      1.0                       0.766667   \n",
       "A1DZMZTXWOM9MR                      1.0                       0.833333   \n",
       "A1FJGB5JLZ81XB                      1.0                       0.900000   \n",
       "A1OM5NWYYYJKQW                      1.0                       0.833333   \n",
       "A1PHDT66U6IK4Q                      1.0                       0.866667   \n",
       "\n",
       "                testing_RT_overall_mean  ...  testing_layer_3_accuracy  \\\n",
       "A11F3MA5FWH6SJ                 1.996455  ...                      0.65   \n",
       "A1DZMZTXWOM9MR                 2.044238  ...                      0.85   \n",
       "A1FJGB5JLZ81XB                 2.011600  ...                      0.90   \n",
       "A1OM5NWYYYJKQW                 1.865277  ...                      0.85   \n",
       "A1PHDT66U6IK4Q                 3.402750  ...                      0.90   \n",
       "\n",
       "                testing_longest_response_strike  demo_demo_accuracy  \\\n",
       "A11F3MA5FWH6SJ                              4.0                True   \n",
       "A1DZMZTXWOM9MR                              5.0                True   \n",
       "A1FJGB5JLZ81XB                              6.0                True   \n",
       "A1OM5NWYYYJKQW                              5.0                True   \n",
       "A1PHDT66U6IK4Q                              4.0                True   \n",
       "\n",
       "                demo_arrow_correct  encoding_arrow_accuracy  \\\n",
       "A11F3MA5FWH6SJ                True                     True   \n",
       "A1DZMZTXWOM9MR                True                     True   \n",
       "A1FJGB5JLZ81XB                True                     True   \n",
       "A1OM5NWYYYJKQW                True                     True   \n",
       "A1PHDT66U6IK4Q                True                     True   \n",
       "\n",
       "                testing_longest_response_strike  not_too_slow  not_too_Fast  \\\n",
       "A11F3MA5FWH6SJ                             True          True          True   \n",
       "A1DZMZTXWOM9MR                             True          True          True   \n",
       "A1FJGB5JLZ81XB                             True          True          True   \n",
       "A1OM5NWYYYJKQW                             True          True          True   \n",
       "A1PHDT66U6IK4Q                             True          True          True   \n",
       "\n",
       "                sufficient_test_acc        WorkerId  \n",
       "A11F3MA5FWH6SJ                 True  A11F3MA5FWH6SJ  \n",
       "A1DZMZTXWOM9MR                 True  A1DZMZTXWOM9MR  \n",
       "A1FJGB5JLZ81XB                 True  A1FJGB5JLZ81XB  \n",
       "A1OM5NWYYYJKQW                 True  A1OM5NWYYYJKQW  \n",
       "A1PHDT66U6IK4Q                 True  A1PHDT66U6IK4Q  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = pd.concat([data_df_for_analysis,disqualification_df], axis = 1)\n",
    "total_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_participants_df.to_csv(PATH_TO_BATCH / ('one_line_per_participant_all_info_valid_subjects_only_' + qualification_method + '.csv'))\n",
    "total_data.to_csv(PATH_TO_BATCH / ('one_line_per_participant_all_info_all_subject_' + qualification_method + '.csv'))\n",
    "criterions_df.to_csv(PATH_TO_BATCH /('criterions_info_' + qualification_method + '.csv'),index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RT')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(10,5))\n",
    "sns.barplot(data=final_participants_df[['testing_layer_1_accuracy','testing_layer_2_accuracy','testing_layer_3_accuracy']],ax=axes[0])\n",
    "sns.swarmplot(data=final_participants_df[['testing_layer_1_accuracy','testing_layer_2_accuracy','testing_layer_3_accuracy']],ax=axes[0],color='k')\n",
    "\n",
    "axes[0].set_xticklabels(labels=['layer1','layer2','layer3'],rotation=30)\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "\n",
    "sns.barplot(data=final_participants_df[['testing_layer_1_rt','testing_layer_2_rt','testing_layer_3_rt']],ax=axes[1])\n",
    "sns.swarmplot(data=final_participants_df[['testing_layer_1_rt','testing_layer_2_rt','testing_layer_3_rt']],ax=axes[1],color='k')\n",
    "\n",
    "axes[1].set_xticklabels(labels=['layer1','layer2','layer3'],rotation=30)\n",
    "axes[1].set_ylabel('RT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RT')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(10,5))\n",
    "sns.pointplot(data=final_participants_df[['testing_layer_1_accuracy','testing_layer_2_accuracy','testing_layer_3_accuracy']],ax=axes[0])\n",
    "#sns.swarmplot(data=final_participants_df[['testing_layer_1_accuracy','testing_layer_2_accuracy','testing_layer_3_accuracy']],ax=axes[0],color='k')\n",
    "\n",
    "axes[0].set_xticklabels(labels=['layer1','layer2','layer3'],rotation=30)\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "\n",
    "sns.pointplot(data=final_participants_df[['testing_layer_1_rt','testing_layer_2_rt','testing_layer_3_rt']],ax=axes[1])\n",
    "#sns.swarmplot(data=final_participants_df[['testing_layer_1_rt','testing_layer_2_rt','testing_layer_3_rt']],ax=axes[1],color='k')\n",
    "\n",
    "axes[1].set_xticklabels(labels=['layer1','layer2','layer3'],rotation=30)\n",
    "axes[1].set_ylabel('RT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changed entrees for: ['A2IQ0QCTQ3KWLT', 'A2PPTQXFVA9H38', 'AYWHJVYLOA2B5', 'A3HZFB2JLF3JMY', 'A2376IXNKHYB22', 'AWX3PLN2FS0SW', 'A1QUQ0TV9KVD4C', 'hjfhhyhy46478', 'ksgsuhf644', 'A2B153AHPWHLH1', 'A39M9PZLH3J1NF', 'A1Y2W25NF6T431', 'A11J9UQ036KJA1', 'AHXQCR64E5GUE', 'A22HIX1M4QXZBB', 'A248QG4DPULP46', 'A2ASR7XQA7KERU']\n"
     ]
    }
   ],
   "source": [
    "#this is the updated shelf: copy from here and place in the shelf location in pavlovia.org\n",
    "new_shelf_dict=shelf_dict.copy()\n",
    "\n",
    "\n",
    "clean_shelf_after_test=True #change to true if you run this code after completing both encoding and test sessions and want to also resert participants that didnt come back at all... \n",
    "if clean_shelf_after_test: \n",
    "\n",
    "\n",
    "    allowed_interval_in_hours=24\n",
    "    allowed_jitter=3\n",
    "    allowed_interval_in_ms=[allowed_interval_in_hours-allowed_jitter,allowed_interval_in_hours+allowed_jitter]*3600*1000\n",
    "\n",
    "\n",
    "    new_shelf_dict=shelf_dict.copy()\n",
    "    changed_keys_list=[]\n",
    "    for key in new_shelf_dict.keys():\n",
    "        cur_entries=new_shelf_dict[key]\n",
    "        if len(cur_entries)==2: \n",
    "            cur_entries[0]=999\n",
    "            changed_keys_list.append(key)\n",
    "\n",
    "        if len(cur_entries)>2:\n",
    "            encoding_time=cur_entries[1]\n",
    "            last_entree=cur_entries[-1]\n",
    "            if (last_entree - encoding_time) < allowed_interval_in_ms[0]:\n",
    "                cur_entries[0]=999\n",
    "                changed_keys_list.append(key)\n",
    "\n",
    "\n",
    "        new_shelf_dict[key]=cur_entries\n",
    "\n",
    "    print('changed entrees for:',changed_keys_list)\n",
    "\n",
    "    ##### print the updated shelf dictionary so you can copy it from the cell output and paste in the shelf:  (change the shelf only if you run this code after both encoding and TEST has ended) ####\n",
    "    new_shelf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>testing_RT_incorrect_mean</th>\n",
       "      <th>testing_RT_correct_mean</th>\n",
       "      <th>testing_layer_1_rt</th>\n",
       "      <th>testing_layer_1_accuracy</th>\n",
       "      <th>testing_layer_2_rt</th>\n",
       "      <th>testing_layer_2_accuracy</th>\n",
       "      <th>testing_layer_3_rt</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11F3MA5FWH6SJ</th>\n",
       "      <td>1.6953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.201833</td>\n",
       "      <td>3.7117</td>\n",
       "      <td>1.899860</td>\n",
       "      <td>1.20072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1.996455</td>\n",
       "      <td>2.024171</td>\n",
       "      <td>1.988020</td>\n",
       "      <td>2.252405</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.047725</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.689235</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1DZMZTXWOM9MR</th>\n",
       "      <td>0.4941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.277317</td>\n",
       "      <td>2.5012</td>\n",
       "      <td>2.165375</td>\n",
       "      <td>0.55354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.044238</td>\n",
       "      <td>2.335260</td>\n",
       "      <td>1.986034</td>\n",
       "      <td>1.940875</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.122665</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.069175</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1FJGB5JLZ81XB</th>\n",
       "      <td>1.7127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.733967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.733967</td>\n",
       "      <td>1.53006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>2.011600</td>\n",
       "      <td>2.293350</td>\n",
       "      <td>1.980294</td>\n",
       "      <td>2.044130</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.064860</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.925810</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OM5NWYYYJKQW</th>\n",
       "      <td>0.6385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.915917</td>\n",
       "      <td>2.7754</td>\n",
       "      <td>1.744020</td>\n",
       "      <td>0.60996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.865277</td>\n",
       "      <td>1.954120</td>\n",
       "      <td>1.847508</td>\n",
       "      <td>1.978915</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.784820</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.832095</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1PHDT66U6IK4Q</th>\n",
       "      <td>0.7481</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>7.267867</td>\n",
       "      <td>9.1037</td>\n",
       "      <td>6.900700</td>\n",
       "      <td>0.65192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>3.402750</td>\n",
       "      <td>3.887212</td>\n",
       "      <td>3.328217</td>\n",
       "      <td>3.025835</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.630580</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.551835</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A11F3MA5FWH6SJ         1.6953                 1.0            0.833333   \n",
       "A1DZMZTXWOM9MR         0.4941                 1.0            0.666667   \n",
       "A1FJGB5JLZ81XB         1.7127                 1.0            1.000000   \n",
       "A1OM5NWYYYJKQW         0.6385                 1.0            0.833333   \n",
       "A1PHDT66U6IK4Q         0.7481                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A11F3MA5FWH6SJ              2.201833                  3.7117   \n",
       "A1DZMZTXWOM9MR              2.277317                  2.5012   \n",
       "A1FJGB5JLZ81XB              2.733967                     NaN   \n",
       "A1OM5NWYYYJKQW              1.915917                  2.7754   \n",
       "A1PHDT66U6IK4Q              7.267867                  9.1037   \n",
       "\n",
       "                demo_RT_correct_mean  encoding_arrow_mean_rt  \\\n",
       "A11F3MA5FWH6SJ              1.899860                 1.20072   \n",
       "A1DZMZTXWOM9MR              2.165375                 0.55354   \n",
       "A1FJGB5JLZ81XB              2.733967                 1.53006   \n",
       "A1OM5NWYYYJKQW              1.744020                 0.60996   \n",
       "A1PHDT66U6IK4Q              6.900700                 0.65192   \n",
       "\n",
       "                encoding_arrow_accuracy  testing_Test_overall_accuracy  \\\n",
       "A11F3MA5FWH6SJ                      1.0                       0.766667   \n",
       "A1DZMZTXWOM9MR                      1.0                       0.833333   \n",
       "A1FJGB5JLZ81XB                      1.0                       0.900000   \n",
       "A1OM5NWYYYJKQW                      1.0                       0.833333   \n",
       "A1PHDT66U6IK4Q                      1.0                       0.866667   \n",
       "\n",
       "                testing_RT_overall_mean  testing_RT_incorrect_mean  \\\n",
       "A11F3MA5FWH6SJ                 1.996455                   2.024171   \n",
       "A1DZMZTXWOM9MR                 2.044238                   2.335260   \n",
       "A1FJGB5JLZ81XB                 2.011600                   2.293350   \n",
       "A1OM5NWYYYJKQW                 1.865277                   1.954120   \n",
       "A1PHDT66U6IK4Q                 3.402750                   3.887212   \n",
       "\n",
       "                testing_RT_correct_mean  testing_layer_1_rt  \\\n",
       "A11F3MA5FWH6SJ                 1.988020            2.252405   \n",
       "A1DZMZTXWOM9MR                 1.986034            1.940875   \n",
       "A1FJGB5JLZ81XB                 1.980294            2.044130   \n",
       "A1OM5NWYYYJKQW                 1.847508            1.978915   \n",
       "A1PHDT66U6IK4Q                 3.328217            3.025835   \n",
       "\n",
       "                testing_layer_1_accuracy  testing_layer_2_rt  \\\n",
       "A11F3MA5FWH6SJ                      0.85            2.047725   \n",
       "A1DZMZTXWOM9MR                      0.65            2.122665   \n",
       "A1FJGB5JLZ81XB                      1.00            2.064860   \n",
       "A1OM5NWYYYJKQW                      0.75            1.784820   \n",
       "A1PHDT66U6IK4Q                      0.85            3.630580   \n",
       "\n",
       "                testing_layer_2_accuracy  testing_layer_3_rt  \\\n",
       "A11F3MA5FWH6SJ                      0.80            1.689235   \n",
       "A1DZMZTXWOM9MR                      1.00            2.069175   \n",
       "A1FJGB5JLZ81XB                      0.80            1.925810   \n",
       "A1OM5NWYYYJKQW                      0.90            1.832095   \n",
       "A1PHDT66U6IK4Q                      0.85            3.551835   \n",
       "\n",
       "                testing_layer_3_accuracy  testing_longest_response_strike  \n",
       "A11F3MA5FWH6SJ                      0.65                              4.0  \n",
       "A1DZMZTXWOM9MR                      0.85                              5.0  \n",
       "A1FJGB5JLZ81XB                      0.90                              6.0  \n",
       "A1OM5NWYYYJKQW                      0.85                              5.0  \n",
       "A1PHDT66U6IK4Q                      0.90                              4.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_participants_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 were given a UPDATE-completed birds memory rep, names: ['A3BU8UL4W258UU', 'A2YC6PEMIRSOAA', 'A2IQ0QCTQ3KWLT', 'APVZGZM1RA3AZ', 'A27PVIL93ZMY46', 'A11F3MA5FWH6SJ', 'A1FJGB5JLZ81XB', 'AYWHJVYLOA2B5', 'A9YPM325MKYLO', 'AGZ3QJFK1BR8V', 'AW9T591E49DCX', 'A6M7YIG6KKHPA', 'A1TKZIBGTP7FE8', 'A3HZFB2JLF3JMY', 'ARR9GKAG3JFE5', 'A1PHDT66U6IK4Q', 'A3SKE5B27HLVO6', 'A1QT3YA7G8MO63', 'A2VLTSW6CXIUMR', 'A1FMVUYV72MUO3', 'A2XDWB9NVYI3LQ', 'A2IP3ZAFYGV8M9', 'A1QUQ0TV9KVD4C', 'A1YV7SCB1OHMUT', 'A3CH1Z6J9R38G9', 'A3KP8KFGG6734Q', 'A1OM5NWYYYJKQW', 'A7VA2Y4H6U31O', 'A2B153AHPWHLH1', 'A39M9PZLH3J1NF', 'AXPZAP62ZYWP8', 'A41APS6V2Z1FJ', 'A1Y2W25NF6T431', 'A2M183CETUMR96', 'A1SNC8UL8YFRH5', 'A31T2PF4RV3GTF', 'A1DZMZTXWOM9MR', 'A11J9UQ036KJA1', 'A25PFSORDO3SWQ', 'A3ATB5GC4BQIH0', 'ACGGIBC0P38HU', 'A2YVQKJX3FO6P', 'AAF1SJ9FCBF75', 'A39VAFCIGP83ER', 'AHXQCR64E5GUE', 'AMPR904VJJFZY', 'A22HIX1M4QXZBB', 'A248QG4DPULP46', 'A2ASR7XQA7KERU']\n",
      "\n",
      "\n",
      "copy the following dictionary content to the pavlovia dictionary, and to the \"shelf final state.txt\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"A11F3MA5FWH6SJ\": [5, 1672259987509, 1672330050392, 1672335745754], \"A1DZMZTXWOM9MR\": [37, 1672273012190, 1672365046651], \"A1FJGB5JLZ81XB\": [7, 1672260025367, 1672334776164, 1672337091803], \"A1OM5NWYYYJKQW\": [27, 1672262466157, 1672329743884, 1672340507840], \"A1PHDT66U6IK4Q\": [16, 1672260558724, 1672330013374, 1672330273345, 1672331907909, 1672333999861, 1672335867212, 1672337055604], \"A1SNC8UL8YFRH5\": [35, 1672264395481, 1672347780832], \"A25PFSORDO3SWQ\": [39, 1672274742971, 1672352498510], \"A2IP3ZAFYGV8M9\": [23, 1672261263996, 1672348660773], \"A2M183CETUMR96\": [34, 1672264350184, 1672358532686], \"A2VLTSW6CXIUMR\": [19, 1672260855599, 1672350028452], \"A2YVQKJX3FO6P\": [42, 1672278953409, 1672340145634, 1672366806134], \"A3ATB5GC4BQIH0\": [40, 1672274902382, 1672330349861, 1672362175130], \"A3BU8UL4W258UU\": [0, 1672259949355, 1672330353312, 1672338011502], \"A3CH1Z6J9R38G9\": [26, 1672261908133, 1672331114658, 1672331943263, 1672334404561, 1672336907779, 1672337767267], \"A3KP8KFGG6734Q\": [25, 1672262067284, 1672262637385, 1672330879530, 1672356371483], \"A7VA2Y4H6U31O\": [28, 1672262935938, 1672330641939, 1672338822690], \"A9YPM325MKYLO\": [9, 1672260039075, 1672330447238, 1672330627138, 1672333360670, 1672343237383], \"AAF1SJ9FCBF75\": [43, 1672281438975, 1672370976812], \"ACGGIBC0P38HU\": [41, 1672277137233, 1672360652315], \"AXPZAP62ZYWP8\": [31, 1672263205796, 1672337433968, 1672343630318]}'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find all participants that exists in the shelf, and make sure they have a participantion code (so they wont be able to come back to this experiemnt)\n",
    "all_shelf_workers_that_are_assigned_participantion=[]\n",
    "for curr_key in shelf_dict.keys():\n",
    "    if curr_key in workers_df['Worker ID'].values:\n",
    "        workers_df.loc[workers_df['Worker ID']==curr_key,qualification_name_for_entire_experiment]=1\n",
    "        all_shelf_workers_that_are_assigned_participantion.append(curr_key)\n",
    "\n",
    "print(f'{len(all_shelf_workers_that_are_assigned_participantion)} were given a {qualification_name_for_entire_experiment}, names: {all_shelf_workers_that_are_assigned_participantion}')\n",
    "\n",
    "#create a new shelf, that only contains the ids and numbers of valid participants (this is so we wont re-use thier custom trials order (csvs))\n",
    "new_shelf_dict=dict()\n",
    "for sub_id in final_participants_df.index: \n",
    "    new_shelf_dict[sub_id]=shelf_dict[sub_id]\n",
    "new_shelf_dict  \n",
    "\n",
    "# add the final state of the previous batch \n",
    "previous_batch = 'batch ' + str(int(batch_name[-1]) - 1)\n",
    "root_dirs = list(PATH_TO_BATCH.parent.iterdir())\n",
    "target_dir = PATH_TO_BATCH.parent/ previous_batch\n",
    "if target_dir in root_dirs:\n",
    "    path_final_state_shelf = target_dir / 'shelf final state.txt'\n",
    "    with open(path_final_state_shelf) as f:\n",
    "        data = f.read()\n",
    "        shelf_dict = json.loads(data)\n",
    "    \n",
    "    new_shelf_dict = new_shelf_dict | shelf_dict\n",
    "\n",
    "\n",
    "print('\\n\\ncopy the following dictionary content to the pavlovia dictionary, and to the \"shelf final state.txt\"\\n')\n",
    "json.dumps(new_shelf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_workers_df_extended.to_csv(PATH_TO_BATCH / path.Path(batch_name+'_workers_results_extended_with_disqualification.csv'))\n",
    "workers_df.to_csv(PATH_TO_BATCH / path.Path(batch_name+'_workers_results_for_upload_after_encoding_and_test.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
