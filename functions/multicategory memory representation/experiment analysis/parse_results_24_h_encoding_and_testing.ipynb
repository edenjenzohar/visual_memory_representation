{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pathlib as path\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "from random import sample\n",
    "from cmath import nan\n",
    "import json\n",
    "\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch folder found at:\n",
      " c:\\Users\\User\\Desktop\\visual_memory_project\\visual-memory-project\\projects\\fungi\\experiment 1\\collected data\\pilot_24_hours\\batch 3\n"
     ]
    }
   ],
   "source": [
    "#define the relevant path to the current batch you wish to parse\n",
    "gap_name='pilot_24_hours' #dont change this as this parsing sciprt only handles the same day batches.  \n",
    "\n",
    "project_name='fungi'\n",
    "experiment_name='experiment 1'\n",
    "batch_name='batch 3'\n",
    "qualification_method='strict' #or 'loose'  - defines different disqualification criterions (add this suffix to the saved file)\n",
    "\n",
    "PATH_TO_BATCH=path.Path.cwd().parent.parent.parent / 'projects' / project_name / experiment_name / 'collected data' / gap_name / batch_name\n",
    "PATH_TO_BATCH_DATA = PATH_TO_BATCH / 'data'\n",
    "\n",
    "if PATH_TO_BATCH.exists():\n",
    "    print('batch folder found at:\\n' ,PATH_TO_BATCH)\n",
    "else: \n",
    "    print('path to batch is non existent:\\n',PATH_TO_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# it is important to copy the column names from the csv files so the right columns get updated\n",
    "qualification_name_for_testin='UPDATE-completed encoding successfully '  #note that the -space- after the title is improtant as for some reason this is how the qualification name is defined\n",
    "qualification_name_for_entire_experiment='UPDATE-completed birds memory rep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_criterions(type='strict'):\n",
    "    #the function sets the criterions and returns them as a pd.series\n",
    "    criterions_df=pd.Series(dtype=float)\n",
    "\n",
    "    #update the non changing ciretrions: \n",
    "    criterions_df['demo_arrow_correctness']=1\n",
    "    criterions_df['encoding_arrow_accuracy']=0.6\n",
    "    criterions_df['longest_allowed_consequtive_strike']=15\n",
    "    criterions_df['fast_threshold']=0.3\n",
    "\n",
    "    if type=='strict':\n",
    "        criterions_df['demo_accuracy_treshold']=0.5 \n",
    "        \n",
    "        criterions_df['fast_allowed_count']=3 \n",
    "        criterions_df['slow_threshold']=10\n",
    "        criterions_df['slow_allowed_count']=2\n",
    "        criterions_df['binom_single_layer']=0.75\n",
    "        criterions_df['binom_averages']=0.61\n",
    "    elif type=='loose': #here we change things to be easier to pass\n",
    "        criterions_df['demo_accuracy_treshold']=0\n",
    "        criterions_df['fast_threshold']=0.3\n",
    "        criterions_df['fast_allowed_count']=5 \n",
    "        criterions_df['slow_threshold']=15\n",
    "        criterions_df['slow_allowed_count']=5\n",
    "        criterions_df['binom_single_layer']=0.55\n",
    "        criterions_df['binom_averages']=0.55\n",
    "    else: \n",
    "        raise Exception('requested method is not defined')\n",
    "    \n",
    "    return criterions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "demo_arrow_correctness                 1.00\n",
       "encoding_arrow_accuracy                0.60\n",
       "longest_allowed_consequtive_strike    15.00\n",
       "fast_threshold                         0.30\n",
       "demo_accuracy_treshold                 0.00\n",
       "fast_allowed_count                     5.00\n",
       "slow_threshold                        15.00\n",
       "slow_allowed_count                     5.00\n",
       "binom_single_layer                     0.55\n",
       "binom_averages                         0.55\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "criterions_df=set_criterions(qualification_method)\n",
    "criterions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_criterions(type='strict'):\n",
    "    #the function sets the criterions and returns them as a pd.series\n",
    "    criterions_df=pd.Series(dtype=float)\n",
    "\n",
    "    #update the non changing ciretrions: \n",
    "    criterions_df['demo_arrow_correctness']=1\n",
    "    criterions_df['encoding_arrow_accuracy']=0.6\n",
    "    criterions_df['longest_allowed_consequtive_strike']=15\n",
    "    criterions_df['fast_threshold']=0.3\n",
    "\n",
    "    if type=='strict':\n",
    "        criterions_df['demo_accuracy_treshold']=0.5 \n",
    "        \n",
    "        criterions_df['fast_allowed_count']=3 \n",
    "        criterions_df['slow_threshold']=10\n",
    "        criterions_df['slow_allowed_count']=2\n",
    "        criterions_df['binom_single_layer']=0.75\n",
    "        criterions_df['binom_averages']=0.61\n",
    "    elif type=='loose': #here we change things to be easier to pass\n",
    "        criterions_df['demo_accuracy_treshold']=0\n",
    "        criterions_df['fast_threshold']=0.3\n",
    "        criterions_df['fast_allowed_count']=5 \n",
    "        criterions_df['slow_threshold']=15\n",
    "        criterions_df['slow_allowed_count']=5\n",
    "        criterions_df['binom_single_layer']=0.55\n",
    "        criterions_df['binom_averages']=0.55\n",
    "    else: \n",
    "        raise Exception('requested method is not defined')\n",
    "    \n",
    "    return criterions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "demo_arrow_correctness                 1.00\n",
       "encoding_arrow_accuracy                0.60\n",
       "longest_allowed_consequtive_strike    15.00\n",
       "fast_threshold                         0.30\n",
       "demo_accuracy_treshold                 0.50\n",
       "fast_allowed_count                     3.00\n",
       "slow_threshold                        10.00\n",
       "slow_allowed_count                     2.00\n",
       "binom_single_layer                     0.75\n",
       "binom_averages                         0.61\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "criterions_df=set_criterions(qualification_method)\n",
    "criterions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A21UA6O7ZFAIQJ': [33, 1672618541424, 1673265610931],\n",
       " 'ABVBYS63BZWZ6': [54, 1672691441654, 1673184321835, 1673268961032],\n",
       " 'AN4P0SU1YSPF2': [30,\n",
       "  1672608091759,\n",
       "  1673108004931,\n",
       "  1673115273107,\n",
       "  1673136507681,\n",
       "  1673150501613,\n",
       "  1673188398470],\n",
       " 'AOOLS8280CL0Z': [7,\n",
       "  1672601000146,\n",
       "  1673111749669,\n",
       "  1673137735525,\n",
       "  1673185641801],\n",
       " 'A2I6ZALE49CVSC': [0, 1673367367444],\n",
       " 'A1TPGXT718D68E': [1, 1673367560992, 1673967969504],\n",
       " 'A2MOU3YD664C0H': [2, 1673367619383, 1673972085784],\n",
       " 'A2LA3NEWBU30QT': [3, 1673367650470, 1673965164358],\n",
       " 'A3DP9IH8W5OXJL': [4, 1673367667732, 1673965034927],\n",
       " 'AMAEYJH3DWA1V': [5, 1673367724382, 1673965103875],\n",
       " 'AYCD7UMZHW4WD': [999, 1673367821150],\n",
       " 'ATH176GTV3ABP': [999, 1673368064110, 1674099454320],\n",
       " 'A1M1W56A3UR5PE': [9, 1673368158334],\n",
       " 'A3S3WYVCVWW8IZ': [10, 1673368196632, 1673966299761],\n",
       " 'A21ZYNCWJLHMCY': [999, 999, 999],\n",
       " 'A1SJLXB0XFCJ97': [999, 999, 999],\n",
       " 'A2RSBH1E3TEESG': [11, 1673368592968, 1673967623892],\n",
       " 'A3QO3HIV92H659': [12, 1673368687949, 1673965849974],\n",
       " 'A1SJLXB0XFCJ92': [999, 1673368956444],\n",
       " 'A2T5CROJ0FWIJY': [14, 1673369034005],\n",
       " 'AV55CMG8KR1YH': [999, 999, 999],\n",
       " 'A2OT9ZJC4MQBS8': [16, 1673368812171, 1673965056975],\n",
       " 'A2KLIBLDVDV144': [17, 1673369107433, 1673965292568],\n",
       " 'A2PAWE1NW4MD8L': [15, 1673369242776, 1673965462601],\n",
       " 'A9500TJQDB94E': [18, 1673369248154, 1673965219705],\n",
       " 'AQQE1W9R9KRYW': [999, 999, 999],\n",
       " 'A1T2JRYTUVUD2O': [999, 1673369829871, 1674057987518],\n",
       " 'A66QAY9ZC7PS4': [19, 1673369856461, 1673966244178],\n",
       " 'A3EKR5FNVVN2CC': [21, 1673370404155],\n",
       " 'AW1EN7PL054OB': [999, 999, 999],\n",
       " 'A2YK6945O0SP8N': [999, 1673371195824],\n",
       " 'A2R5ZHND3OQJAV': [999, 1673372772271],\n",
       " 'A1I5KX8TP3K5L2': [24, 1673373282659, 1673973237603],\n",
       " 'A2OOYCMD4P4VFK': [999, 999, 999],\n",
       " 'A34LSCB90T5KYE': [25, 1673373897306, 1673984887533],\n",
       " 'A36BPBYVFDSNBB': [26, 1673374294506, 1673979563350, 1673979694814],\n",
       " 'A3D3FNUSK1A2P6': [27, 1673374977494, 1673980617990],\n",
       " 'A1OQFPHKZV0LM5': [28, 1673375095245],\n",
       " 'A2OK9P9QCBZKMB': [999, 1673375607244],\n",
       " 'A1P2XKONWAOXHP': [31, 1673377553473, 1673981181507, 1673982723492],\n",
       " 'A2RWLFIP23FZA7': [32, 1673382293069, 1673973513721],\n",
       " 'A30RAYNDOWQ61S': [34, 1673382442986, 1673967015721],\n",
       " 'AT5LT9B0GKOIK': [35, 1673384092055, 1673984929780, 1673985058595],\n",
       " 'AAZNLKG9ZCL1N': [999, 1673389930825, 1673390402332],\n",
       " 'A2L18Q7871EONK': [999, 1673390597725, 1674059640758],\n",
       " 'A3S4HVPIEK0QQ3': [999, 999, 999],\n",
       " 'A1XAL86XSJPFWK': [999, 999, 999],\n",
       " 'A1EH9BPKYXFBS5': [999, 1673403817843, 1674092907820],\n",
       " 'ATP0UFAVIANFL': [999, 1673404153506],\n",
       " 'AE681FG4LT6DV': [999, 999, 999],\n",
       " 'AQN32EZB7OQRG': [40, 1673406294162, 1674050329891],\n",
       " 'A1YC558J4E5KZ': [41, 1673407134330, 1674015893631],\n",
       " 'A3G55RJTW3BSGM': [42, 1673408338571, 1674013081449],\n",
       " 'A1122EUMFXHF38': [43, 1673410860118, 1674052508021],\n",
       " 'A208AK4JNI6PZ0': [999, 1673411131197],\n",
       " 'A3NQWRK8KWTILX': [45,\n",
       "  1673411463384,\n",
       "  1673966003740,\n",
       "  1673966057622,\n",
       "  1673966225446],\n",
       " 'AVSPYLB9KOHMX': [46, 1673445823727, 1674038943137],\n",
       " 'A1VBA5TN6G265Q': [47, 1673424204384],\n",
       " 'ATUS3Q9I9EJNZ': [999, None],\n",
       " 'A1T6TTD7XCUHOU': [49, 1673444061242, 1673966443562, 1674013819839],\n",
       " 'A290Z6QAL17PQE': [50, 1673444873189, 1674046484322],\n",
       " 'A1Y07DW8W2UXSD': [51, 1673445515902, 1674046980693],\n",
       " 'A249ZABI42JTSS': [52,\n",
       "  1673446169039,\n",
       "  1673976576314,\n",
       "  1673976878416,\n",
       "  1674007552305,\n",
       "  1674047784546],\n",
       " 'A28P7V6WDT9UN1': [53, 1673446293435, 1674047561527],\n",
       " 'A309WI6Y258387': [6, 1674068182063],\n",
       " 'AI6M2CNDFUW3J': [13, 1674082291428],\n",
       " 'A3GHCTI04OQA1Y': [999, 999, 999]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this section loads the shelf dict in the state it is after finishing the testing session for this batch. \n",
    "shelf_dict_after_test_name=PATH_TO_BATCH / 'shelf after test session closed.txt' #define the name of the relevant shelf for this stage\n",
    "with open(shelf_dict_after_test_name) as f:\n",
    "    data = f.read()\n",
    "shelf_dict = json.loads(data)\n",
    "shelf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section reads all the relevant files: \n",
    "if (PATH_TO_BATCH / 'Batch_encoding_batch_results.csv').exists():\n",
    "    encoding_df=pd.read_csv(PATH_TO_BATCH / 'Batch_encoding_batch_results.csv')\n",
    "else: \n",
    "    print(f'no \"Batch_encoding_batch_results.csv\" was found in data')\n",
    "\n",
    "if (PATH_TO_BATCH / 'Batch_testing_batch_results.csv').exists():\n",
    "    testing_df=pd.read_csv(PATH_TO_BATCH / 'Batch_testing_batch_results.csv')\n",
    "else: \n",
    "    print(f'no \"Batch_testing_batch_results.csv\" was found in data (probably because only the encoding session finished)')\n",
    "if (PATH_TO_BATCH / 'Batch_workers_after_test.csv').exists():\n",
    "    workers_df=pd.read_csv(PATH_TO_BATCH / 'Batch_workers_after_test.csv')\n",
    "else:\n",
    "    print('No AMAZON worker list was found: please make sure to upload one and name it correctly')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_consequtive_repetition(responses_array):\n",
    "#add a stop value so the loop will use the logic also if the end of the responses is all repeating: \n",
    "    responses_array=np.append(responses_array,[99])\n",
    "    longest_rep_dict=dict()\n",
    "    last_input=responses_array[0]\n",
    "    consequtive_rep_counter=0\n",
    "    for response in responses_array[1:]: \n",
    "        if response==last_input: #if consequtive rep: \n",
    "            consequtive_rep_counter=consequtive_rep_counter+1 #add to counter\n",
    "        else: #once a new entry is in the vector - store the counter rep information \n",
    "            if last_input in longest_rep_dict.keys(): #if it was allready stored in our dictionary\n",
    "                if longest_rep_dict[last_input]<consequtive_rep_counter: #replace the counter only if it is higher than what stored in dict\n",
    "                    longest_rep_dict[last_input]=consequtive_rep_counter\n",
    "            else: #this entry is not yet in the dictionary: add it \n",
    "                longest_rep_dict[last_input]=consequtive_rep_counter\n",
    "            \n",
    "            consequtive_rep_counter=0\n",
    "            last_input=response\n",
    "    return max(longest_rep_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_worker_results(PATH_TO_BATCH_DATA,subject_name,parse_type='encoding'):\n",
    "    cur_sub=pd.read_csv(PATH_TO_BATCH_DATA / subject_name)\n",
    "    sub_demographics=cur_sub[['workID','Age','Gender']].iloc[0]\n",
    "\n",
    "    #extract demo related information: \n",
    "\n",
    "    #if participant did not click on the arrow during the demo a 'demo_encoding_response.rt' colmumn wont exists: \n",
    "    #thus we will create one and fill it with nans (so everything will be consistent with other participants)\n",
    "    demo_columns=['demo_encoding_loop.thisTrialN','DemoImage','DemoCorrect','demo_encoding_response.rt','demo_encoding_response.keys']\n",
    "    demo_test_columns=['demo_test_response.keys','demo_test_response.corr','demo_test_response.rt','demo_test_loop.thisTrialN','DemoImage1','DemoImage2','DemoCorrectTest']\n",
    "    encoding_related_columns=['test_encoding_response.keys','test_encoding_response.corr','trials.thisTrialN','target_image','pair','layer','correct','test_encoding_response.rt','key_resp_end.keys']\n",
    "    test_related_columns=['layer','correct','test_test_response.keys','test_test_response.corr','test_test_response.rt','trials_2.thisRepN','trials_2.thisTrialN','trials_2.thisN','trials_2.thisIndex','trials_2.ran','image1','image2']\n",
    "\n",
    "    if not('demo_encoding_response.rt' in cur_sub.columns):\n",
    "        cur_sub['demo_encoding_response.rt']=np.nan  \n",
    "\n",
    "    if (parse_type=='encoding'):\n",
    "        sub_demo_information=cur_sub[demo_columns]\n",
    "        empty_inds=sub_demo_information.loc[sub_demo_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "        #drop irrelevant columns: \n",
    "        sub_demo_information=sub_demo_information.drop(index=empty_inds)\n",
    "\n",
    "\n",
    "        #extract the demo test columns: \n",
    "        sub_demo_test_information=cur_sub[demo_test_columns]\n",
    "        empty_inds=sub_demo_test_information.loc[sub_demo_test_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "        #drop irrelevant columns: \n",
    "        sub_demo_test_information=sub_demo_test_information.drop(index=empty_inds)\n",
    "\n",
    "        demo_df=pd.concat([sub_demo_information.reset_index(),sub_demo_test_information.reset_index()],axis=1)\n",
    "\n",
    "    #extract real experiment related information: \n",
    "\n",
    "    #if participant did not click on the arrow during the encoding a 'test_encoding_response.rt' column wont exists: \n",
    "    #thus we will create one and fill it with nans (so everything will be consistent with other participants)\n",
    "    if not('test_encoding_response.rt' in cur_sub.columns):\n",
    "        cur_sub['test_encoding_response.rt']=np.nan\n",
    "        \n",
    "\n",
    "    if (parse_type=='encoding') | (parse_type=='all'):\n",
    "        sub_encoding_information=cur_sub[encoding_related_columns]\n",
    "        #encoding section ends with a key press of the space key: so seperate this phase by finding this space key row\n",
    "        end_of_section_ind=np.where(sub_encoding_information['key_resp_end.keys']=='space')[0][0]\n",
    "        sub_encoding_information=sub_encoding_information.iloc[0:end_of_section_ind]\n",
    "        #remove all the rows that precede the real encoding phase: \n",
    "        empty_inds=sub_encoding_information.loc[sub_encoding_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "        sub_encoding_information=sub_encoding_information.drop(index=empty_inds).reset_index()\n",
    "\n",
    "    if (parse_type=='test') | (parse_type=='all'):\n",
    "    #extract real experiment TEST related information: \n",
    "        sub_test_information=cur_sub[test_related_columns].dropna()\n",
    "\n",
    "\n",
    "    subject_dictionary=dict()\n",
    "    subject_dictionary['demographics']=sub_demographics\n",
    "    if (parse_type=='encoding') | (parse_type=='all'):\n",
    "        subject_dictionary['demo_df']=demo_df\n",
    "    if (parse_type=='encoding') | (parse_type=='all'):\n",
    "        subject_dictionary['encoding_df']=sub_encoding_information\n",
    "    if (parse_type=='test') | (parse_type=='all'):\n",
    "        subject_dictionary['test_df']=sub_test_information\n",
    "\n",
    "    return subject_dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODING_A1122EUMFXHF38_2023-01-11_01h21.00.118.csv\n",
      "ENCODING_A1EH9BPKYXFBS5_2023-01-10_18h23.37.843.csv\n",
      "ENCODING_A1I5KX8TP3K5L2_2023-01-10_12h54.42.659.csv\n",
      "ENCODING_A1OQFPHKZV0LM5_2023-01-10_13h24.55.245.csv\n",
      "ENCODING_A1P2XKONWAOXHP_2023-01-10_14h05.53.473.csv\n",
      "ENCODING_A1T2JRYTUVUD2O_2023-01-10_08h57.09.871.csv\n",
      "ENCODING_A1T6TTD7XCUHOU_2023-01-11_08h34.21.242.csv\n",
      "ENCODING_A1TPGXT718D68E_2023-01-10_11h19.20.992.csv\n",
      "ENCODING_A1VBA5TN6G265Q_2023-01-11_03h03.24.384.csv\n",
      "ENCODING_A1Y07DW8W2UXSD_2023-01-11_07h58.35.902.csv\n",
      "ENCODING_A1YC558J4E5KZ_2023-01-10_22h18.54.330.csv\n",
      "ENCODING_A208AK4JNI6PZ0_2023-01-10_23h25.31.197.csv\n",
      "ENCODING_A249ZABI42JTSS_2023-01-11_09h09.29.039.csv\n",
      "ENCODING_A28P7V6WDT9UN1_2023-01-11_10h11.33.435.csv\n",
      "ENCODING_A290Z6QAL17PQE_2023-01-11_08h47.53.189.csv\n",
      "ENCODING_A2I6ZALE49CVSC_2023-01-10_10h16.07.444.csv\n",
      "ENCODING_A2KLIBLDVDV144_2023-01-10_11h45.07.433.csv\n",
      "ENCODING_A2L18Q7871EONK_2023-01-10_17h43.17.725.csv\n",
      "ENCODING_A2LA3NEWBU30QT_2023-01-10_11h20.50.470.csv\n",
      "ENCODING_A2MOU3YD664C0H_2023-01-10_11h20.19.383.csv\n",
      "ENCODING_A2OK9P9QCBZKMB_2023-01-10_13h33.27.244.csv\n",
      "ENCODING_A2OT9ZJC4MQBS8_2023-01-10_11h40.12.171.csv\n",
      "ENCODING_A2PAWE1NW4MD8L_2023-01-10_11h47.22.776.csv\n",
      "ENCODING_A2RSBH1E3TEESG_2023-01-10_11h36.32.968.csv\n",
      "ENCODING_A2RWLFIP23FZA7_2023-01-10_15h24.53.069.csv\n",
      "ENCODING_A2T5CROJ0FWIJY_2023-01-10_11h43.54.005.csv\n",
      "ENCODING_A2YK6945O0SP8N_2023-01-10_12h19.55.824.csv\n",
      "ENCODING_A30RAYNDOWQ61S_2023-01-10_14h27.22.986.csv\n",
      "ENCODING_A34LSCB90T5KYE_2023-01-10_13h04.57.306.csv\n",
      "ENCODING_A36BPBYVFDSNBB_2023-01-10_11h11.34.506.csv\n",
      "ENCODING_A3D3FNUSK1A2P6_2023-01-10_13h22.57.494.csv\n",
      "ENCODING_A3DP9IH8W5OXJL_2023-01-10_10h21.07.732.csv\n",
      "ENCODING_A3EKR5FNVVN2CC_2023-01-10_12h06.44.155.csv\n",
      "ENCODING_A3G55RJTW3BSGM_2023-01-10_22h38.58.571.csv\n",
      "ENCODING_A3NQWRK8KWTILX_2023-01-10_23h31.03.384.csv\n",
      "ENCODING_A3QO3HIV92H659_2023-01-10_11h38.07.949.csv\n",
      "ENCODING_A3S3WYVCVWW8IZ_2023-01-10_10h29.56.632.csv\n",
      "ENCODING_A66QAY9ZC7PS4_2023-01-10_11h57.36.461.csv\n",
      "ENCODING_A9500TJQDB94E_2023-01-10_11h47.28.154.csv\n",
      "ENCODING_AAZNLKG9ZCL1N_2023-01-10_17h32.10.825.csv\n",
      "ENCODING_AMAEYJH3DWA1V_2023-01-10_11h22.04.382.csv\n",
      "ENCODING_AQN32EZB7OQRG_2023-01-10_22h04.54.162.csv\n",
      "ENCODING_AT5LT9B0GKOIK_2023-01-10_15h54.52.055.csv\n",
      "ENCODING_ATH176GTV3ABP_2023-01-10_11h27.44.110.csv\n",
      "ENCODING_ATP0UFAVIANFL_2023-01-10_21h29.13.506.csv\n",
      "ENCODING_AVSPYLB9KOHMX_2023-01-11_10h03.43.727.csv\n",
      "ENCODING_AYCD7UMZHW4WD_2023-01-10_11h23.41.150.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get all results with Encoding information - extract the arrow attention check accuracy and RT (RT is currently not usd as a criterion)\n",
    "\n",
    "#this section extract the list of participants from the downloaded results files (and not via the workers or session list csvs) \n",
    "# - it will create the qualification_df (a table with information on the worker ids and encoding behavior of all participants that we have files for)\n",
    "all_filenames=[file for file in PATH_TO_BATCH_DATA.iterdir() if 'csv' in file.name and 'ENCODING' in file.name]\n",
    "#print(f'current csv files:\\n{all_filenames}')\n",
    "\n",
    "qualification_for_test_df=pd.DataFrame(columns=['workerID','arrow_acc','mean_arrow_RT'])\n",
    "for subject_csv in all_filenames:\n",
    "    print(subject_csv.name)\n",
    "    subject_dict=process_worker_results(PATH_TO_BATCH_DATA,path.Path(subject_csv))\n",
    "    cur_sub_encoding=subject_dict['encoding_df']\n",
    "\n",
    "    sname=subject_csv.name.split('_')[1] #change according to actuall format. \n",
    "\n",
    "    #get only attention check related info: \n",
    "    cur_sub_encoding=cur_sub_encoding[['test_encoding_response.keys','correct','test_encoding_response.rt']].copy().dropna(how = 'all')\n",
    "    if len(cur_sub_encoding)==0: #empty - the participant didnt respond on the arrow at all\n",
    "        arrow_acc=0\n",
    "        RT=nan\n",
    "    else: \n",
    "        RT=cur_sub_encoding['test_encoding_response.rt'].mean()\n",
    "        arrow_acc=(cur_sub_encoding['correct']==cur_sub_encoding['test_encoding_response.keys']).mean()\n",
    "    sub_df=pd.DataFrame({'workerID':sname,'arrow_acc':arrow_acc,'mean_arrow_RT':RT},index=[sname])\n",
    "    qualification_for_test_df=pd.concat([qualification_for_test_df,sub_df],axis=0)\n",
    "\n",
    "#the following part update the qualification_df with information on wether the participant id exists in the amazon workers list: \n",
    "\n",
    "#change participants qualifications if they exists in the workers list based on thier encoding arrow accuracy\n",
    "qualification_for_test_df['in_encoding_workers_list']=nan\n",
    "\n",
    "for curr_worker_ID in qualification_for_test_df.index:\n",
    "    if curr_worker_ID in encoding_df['WorkerId'].values:\n",
    "        qualification_for_test_df.loc[curr_worker_ID,'in_encoding_workers_list']=int(1)\n",
    "    else:\n",
    "        qualification_for_test_df.loc[curr_worker_ID,'in_encoding_workers_list']=int(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects_demo_df=pd.DataFrame()\n",
    "all_subjects_encoding_df=pd.DataFrame()\n",
    "all_subjects_test_df=pd.DataFrame()\n",
    "all_subjects_biographics_df=pd.DataFrame()\n",
    "all_filenames=[file.name for file in PATH_TO_BATCH_DATA.iterdir() if 'csv' in file.name and 'TEST' in file.name]\n",
    "\n",
    "for subject_test_filename in all_filenames:\n",
    "    subject_name=subject_test_filename.split('_')[1]\n",
    "    subject_encoding_filename=[file.name for file in PATH_TO_BATCH_DATA.iterdir() if 'csv' in file.name and 'ENCODING' in file.name and subject_name in file.name][0]\n",
    "    curr_subject_dictionary=process_worker_results(PATH_TO_BATCH_DATA,subject_encoding_filename,parse_type='encoding')\n",
    "    curr_demo_df=curr_subject_dictionary['demo_df']\n",
    "    curr_demo_df['subject']=subject_name\n",
    "    curr_encoding_df=curr_subject_dictionary['encoding_df']\n",
    "    curr_encoding_df['subject']=subject_name\n",
    "    curr_demographics_df=curr_subject_dictionary['demographics']\n",
    "    curr_demographics_df['subject']=subject_name\n",
    "\n",
    "    curr_subject_dictionary=process_worker_results(PATH_TO_BATCH_DATA,subject_test_filename,parse_type='test')\n",
    "    curr_test_df=curr_subject_dictionary['test_df']\n",
    "    curr_test_df['subject']=subject_name\n",
    "\n",
    "\n",
    "\n",
    "    all_subjects_demo_df=pd.concat([all_subjects_demo_df,curr_demo_df],axis=0,ignore_index=True)\n",
    "    all_subjects_encoding_df=pd.concat([all_subjects_encoding_df,curr_encoding_df],axis=0,ignore_index=True)\n",
    "    all_subjects_test_df=pd.concat([all_subjects_test_df,curr_test_df],axis=0,ignore_index=True)\n",
    "    all_subjects_biographics_df=pd.concat([all_subjects_biographics_df,pd.DataFrame(curr_demographics_df).T],axis=0,ignore_index=True)\n",
    "\n",
    "\n",
    "all_subjects_demo_df.to_csv(PATH_TO_BATCH / 'all_subjects_demo_df.csv')\n",
    "all_subjects_encoding_df.to_csv(PATH_TO_BATCH / 'all_subjects_encoding_df.csv')\n",
    "all_subjects_test_df.to_csv(PATH_TO_BATCH / 'all_subjects_test_df.csv')\n",
    "all_subjects_biographics_df.to_csv(PATH_TO_BATCH / 'all_subjects_biographics_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed the gender column to be consistent having two possible values: ['female' 'male']\n",
      "Mean age: 34.45, range: [25 - 60], 0.39% female\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import category\n",
    "\n",
    "# if there are any empty values - fill with mean of subjects age \n",
    "mean_value = all_subjects_biographics_df['Age'].mean()\n",
    "all_subjects_biographics_df['Age'].fillna(value=mean_value, inplace=True)\n",
    "all_subjects_biographics_df['Age'] = all_subjects_biographics_df['Age'].astype(np.int64)\n",
    "\n",
    "all_subjects_biographics_df['Age']=all_subjects_biographics_df['Age'].astype(int)\n",
    "all_subjects_biographics_df['Gender'].replace({'woman':'female','FEMLAE':'female','Male':'male','MALE':'male','FEMALE':'female','Female':'female','ale':'male'},inplace=True)\n",
    "if len(np.unique(all_subjects_biographics_df['Gender'].values))<=2:\n",
    "    print('transformed the gender column to be consistent having two possible values:',np.unique(all_subjects_biographics_df['Gender'].values))\n",
    "else: \n",
    "    print('gender is still inconsistent with more than 2 unique values:',np.unique(all_subjects_biographics_df['Gender'].values))\n",
    "all_subjects_biographics_df['Gender']=all_subjects_biographics_df['Gender'].astype(\"category\")\n",
    "\n",
    "mean_age,min_age,max_age=all_subjects_biographics_df['Age'].mean(),all_subjects_biographics_df['Age'].min(),all_subjects_biographics_df['Age'].max()\n",
    "female_prop=all_subjects_biographics_df.loc[all_subjects_biographics_df['Gender']=='female','Gender'].count()/all_subjects_biographics_df['Gender'].count()\n",
    "\n",
    "print(f'Mean age: {mean_age:.2f}, range: [{min_age} - {max_age}], {female_prop:.2f}% female')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this part plots the seperate dataframes: \n",
    "### demo phase (encoding and test in the same dataframe)\n",
    "### encoding experiment phase\n",
    "### test experiment phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>demo_encoding_loop.thisTrialN</th>\n",
       "      <th>DemoImage</th>\n",
       "      <th>DemoCorrect</th>\n",
       "      <th>demo_encoding_response.rt</th>\n",
       "      <th>demo_encoding_response.keys</th>\n",
       "      <th>index</th>\n",
       "      <th>demo_test_response.keys</th>\n",
       "      <th>demo_test_response.corr</th>\n",
       "      <th>demo_test_response.rt</th>\n",
       "      <th>demo_test_loop.thisTrialN</th>\n",
       "      <th>DemoImage1</th>\n",
       "      <th>DemoImage2</th>\n",
       "      <th>DemoCorrectTest</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>flower1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>flower1.jpg</td>\n",
       "      <td>flower1_pair.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>A1122EUMFXHF38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>flower2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>flower2_pair.jpg</td>\n",
       "      <td>flower2.jpg</td>\n",
       "      <td>right</td>\n",
       "      <td>A1122EUMFXHF38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>1.108</td>\n",
       "      <td>left</td>\n",
       "      <td>14.0</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.505</td>\n",
       "      <td>2.0</td>\n",
       "      <td>flower3.jpg</td>\n",
       "      <td>flower3_pair.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>A1122EUMFXHF38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>flower3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>right</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.031</td>\n",
       "      <td>3.0</td>\n",
       "      <td>flower4.jpg</td>\n",
       "      <td>flower4_pair.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>A1122EUMFXHF38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>flower4.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.132</td>\n",
       "      <td>4.0</td>\n",
       "      <td>flower5_pair.jpg</td>\n",
       "      <td>flower5.jpg</td>\n",
       "      <td>right</td>\n",
       "      <td>A1122EUMFXHF38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  demo_encoding_loop.thisTrialN    DemoImage DemoCorrect  \\\n",
       "0      4                            0.0  flower1.jpg         NaN   \n",
       "1      5                            1.0  flower2.jpg         NaN   \n",
       "2      6                            2.0     left.jpg        left   \n",
       "3      7                            3.0  flower3.jpg         NaN   \n",
       "4      8                            4.0  flower4.jpg         NaN   \n",
       "\n",
       "   demo_encoding_response.rt demo_encoding_response.keys  index  \\\n",
       "0                        NaN                         NaN   12.0   \n",
       "1                        NaN                         NaN   13.0   \n",
       "2                      1.108                        left   14.0   \n",
       "3                        NaN                         NaN   15.0   \n",
       "4                        NaN                         NaN   16.0   \n",
       "\n",
       "  demo_test_response.keys  demo_test_response.corr  demo_test_response.rt  \\\n",
       "0                    left                      1.0                  1.878   \n",
       "1                   right                      1.0                  2.233   \n",
       "2                    left                      1.0                  2.505   \n",
       "3                   right                      0.0                  2.031   \n",
       "4                   right                      1.0                  2.132   \n",
       "\n",
       "   demo_test_loop.thisTrialN        DemoImage1        DemoImage2  \\\n",
       "0                        0.0       flower1.jpg  flower1_pair.jpg   \n",
       "1                        1.0  flower2_pair.jpg       flower2.jpg   \n",
       "2                        2.0       flower3.jpg  flower3_pair.jpg   \n",
       "3                        3.0       flower4.jpg  flower4_pair.jpg   \n",
       "4                        4.0  flower5_pair.jpg       flower5.jpg   \n",
       "\n",
       "  DemoCorrectTest         subject  \n",
       "0            left  A1122EUMFXHF38  \n",
       "1           right  A1122EUMFXHF38  \n",
       "2            left  A1122EUMFXHF38  \n",
       "3            left  A1122EUMFXHF38  \n",
       "4           right  A1122EUMFXHF38  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_subjects_demo_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_encoding_response.keys</th>\n",
       "      <th>test_encoding_response.corr</th>\n",
       "      <th>trials.thisTrialN</th>\n",
       "      <th>target_image</th>\n",
       "      <th>pair</th>\n",
       "      <th>layer</th>\n",
       "      <th>correct</th>\n",
       "      <th>test_encoding_response.rt</th>\n",
       "      <th>key_resp_end.keys</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BREWERS_BLACKBIRD_3.jpg</td>\n",
       "      <td>CAPE_LONGCLAW_2.jpg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1122EUMFXHF38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PYGMY_KINGFISHER_5.jpg</td>\n",
       "      <td>MASKED_BOOBY_5.jpg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1122EUMFXHF38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>OCELLATED_TURKEY_1.jpg</td>\n",
       "      <td>AMERICAN_PIPIT_1.jpg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1122EUMFXHF38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>WHITE_CHEEKED_TURACO_5.jpg</td>\n",
       "      <td>NORTHERN_MOCKINGBIRD_4.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1122EUMFXHF38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>FLAME_BOWERBIRD_3.jpg</td>\n",
       "      <td>BROWN_THRASHER_4.jpg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1122EUMFXHF38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index test_encoding_response.keys  test_encoding_response.corr  \\\n",
       "0     20                         NaN                          1.0   \n",
       "1     21                         NaN                          1.0   \n",
       "2     22                         NaN                          1.0   \n",
       "3     23                         NaN                          1.0   \n",
       "4     24                         NaN                          1.0   \n",
       "\n",
       "   trials.thisTrialN                target_image                        pair  \\\n",
       "0                0.0     BREWERS_BLACKBIRD_3.jpg         CAPE_LONGCLAW_2.jpg   \n",
       "1                1.0      PYGMY_KINGFISHER_5.jpg          MASKED_BOOBY_5.jpg   \n",
       "2                2.0      OCELLATED_TURKEY_1.jpg        AMERICAN_PIPIT_1.jpg   \n",
       "3                3.0  WHITE_CHEEKED_TURACO_5.jpg  NORTHERN_MOCKINGBIRD_4.jpg   \n",
       "4                4.0       FLAME_BOWERBIRD_3.jpg        BROWN_THRASHER_4.jpg   \n",
       "\n",
       "   layer correct  test_encoding_response.rt key_resp_end.keys         subject  \n",
       "0    3.0     NaN                        NaN               NaN  A1122EUMFXHF38  \n",
       "1    2.0     NaN                        NaN               NaN  A1122EUMFXHF38  \n",
       "2    2.0     NaN                        NaN               NaN  A1122EUMFXHF38  \n",
       "3    1.0     NaN                        NaN               NaN  A1122EUMFXHF38  \n",
       "4    2.0     NaN                        NaN               NaN  A1122EUMFXHF38  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_subjects_encoding_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>correct</th>\n",
       "      <th>test_test_response.keys</th>\n",
       "      <th>test_test_response.corr</th>\n",
       "      <th>test_test_response.rt</th>\n",
       "      <th>trials_2.thisRepN</th>\n",
       "      <th>trials_2.thisTrialN</th>\n",
       "      <th>trials_2.thisN</th>\n",
       "      <th>trials_2.thisIndex</th>\n",
       "      <th>trials_2.ran</th>\n",
       "      <th>image1</th>\n",
       "      <th>image2</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AMERICAN_PIPIT_1.jpg</td>\n",
       "      <td>OCELLATED_TURKEY_1.jpg</td>\n",
       "      <td>A1122EUMFXHF38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AFRICAN_PIED_HORNBILL_5.jpg</td>\n",
       "      <td>CAPUCHINBIRD_2.jpg</td>\n",
       "      <td>A1122EUMFXHF38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WATTLED_LAPWING_3.jpg</td>\n",
       "      <td>HAWAIIAN_GOOSE_4.jpg</td>\n",
       "      <td>A1122EUMFXHF38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PEACOCK_2.jpg</td>\n",
       "      <td>BROWN_NOODY_3.jpg</td>\n",
       "      <td>A1122EUMFXHF38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BLACK_THROATED_BUSHTIT_1.jpg</td>\n",
       "      <td>CHUKAR_PARTRIDGE_5.jpg</td>\n",
       "      <td>A1122EUMFXHF38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer correct test_test_response.keys  test_test_response.corr  \\\n",
       "0    2.0   right                    left                      0.0   \n",
       "1    3.0    left                   right                      0.0   \n",
       "2    3.0   right                   right                      1.0   \n",
       "3    1.0   right                    left                      0.0   \n",
       "4    3.0   right                   right                      1.0   \n",
       "\n",
       "   test_test_response.rt  trials_2.thisRepN  trials_2.thisTrialN  \\\n",
       "0                  2.246                0.0                  0.0   \n",
       "1                  1.854                0.0                  1.0   \n",
       "2                  1.598                0.0                  2.0   \n",
       "3                  2.202                0.0                  3.0   \n",
       "4                  1.705                0.0                  4.0   \n",
       "\n",
       "   trials_2.thisN  trials_2.thisIndex  trials_2.ran  \\\n",
       "0             0.0                 0.0           1.0   \n",
       "1             1.0                 1.0           1.0   \n",
       "2             2.0                 2.0           1.0   \n",
       "3             3.0                 3.0           1.0   \n",
       "4             4.0                 4.0           1.0   \n",
       "\n",
       "                         image1                  image2         subject  \n",
       "0          AMERICAN_PIPIT_1.jpg  OCELLATED_TURKEY_1.jpg  A1122EUMFXHF38  \n",
       "1   AFRICAN_PIED_HORNBILL_5.jpg      CAPUCHINBIRD_2.jpg  A1122EUMFXHF38  \n",
       "2         WATTLED_LAPWING_3.jpg    HAWAIIAN_GOOSE_4.jpg  A1122EUMFXHF38  \n",
       "3                 PEACOCK_2.jpg       BROWN_NOODY_3.jpg  A1122EUMFXHF38  \n",
       "4  BLACK_THROATED_BUSHTIT_1.jpg  CHUKAR_PARTRIDGE_5.jpg  A1122EUMFXHF38  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_subjects_test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1122EUMFXHF38</th>\n",
       "      <td>1.1080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.101833</td>\n",
       "      <td>2.031000</td>\n",
       "      <td>2.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1I5KX8TP3K5L2</th>\n",
       "      <td>1.1943</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.893267</td>\n",
       "      <td>1.945200</td>\n",
       "      <td>1.841333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1P2XKONWAOXHP</th>\n",
       "      <td>2.2121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.596817</td>\n",
       "      <td>1.636500</td>\n",
       "      <td>1.576975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1T6TTD7XCUHOU</th>\n",
       "      <td>1.6770</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.315167</td>\n",
       "      <td>1.645000</td>\n",
       "      <td>2.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1TPGXT718D68E</th>\n",
       "      <td>0.6776</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.806317</td>\n",
       "      <td>2.352800</td>\n",
       "      <td>1.697020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1Y07DW8W2UXSD</th>\n",
       "      <td>1.1390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.474167</td>\n",
       "      <td>1.377000</td>\n",
       "      <td>1.522750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1YC558J4E5KZ</th>\n",
       "      <td>0.5073</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.193900</td>\n",
       "      <td>1.853400</td>\n",
       "      <td>2.262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A249ZABI42JTSS</th>\n",
       "      <td>1.0199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.042283</td>\n",
       "      <td>2.324500</td>\n",
       "      <td>1.901175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A28P7V6WDT9UN1</th>\n",
       "      <td>0.8590</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.210833</td>\n",
       "      <td>1.114000</td>\n",
       "      <td>1.259250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A290Z6QAL17PQE</th>\n",
       "      <td>1.1810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.439833</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>1.497800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2KLIBLDVDV144</th>\n",
       "      <td>0.9302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.997517</td>\n",
       "      <td>0.793300</td>\n",
       "      <td>1.038360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2LA3NEWBU30QT</th>\n",
       "      <td>1.6784</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.751650</td>\n",
       "      <td>0.513200</td>\n",
       "      <td>0.870875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2MOU3YD664C0H</th>\n",
       "      <td>1.0410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.341833</td>\n",
       "      <td>3.642000</td>\n",
       "      <td>3.191750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2OT9ZJC4MQBS8</th>\n",
       "      <td>0.7694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.009533</td>\n",
       "      <td>1.401533</td>\n",
       "      <td>2.617533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2PAWE1NW4MD8L</th>\n",
       "      <td>1.0550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.755667</td>\n",
       "      <td>1.805500</td>\n",
       "      <td>1.656000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2RSBH1E3TEESG</th>\n",
       "      <td>1.2280</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.921033</td>\n",
       "      <td>2.404675</td>\n",
       "      <td>0.953750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2RWLFIP23FZA7</th>\n",
       "      <td>0.6500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.149000</td>\n",
       "      <td>2.815000</td>\n",
       "      <td>1.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A30RAYNDOWQ61S</th>\n",
       "      <td>0.5881</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>3.214067</td>\n",
       "      <td>3.051600</td>\n",
       "      <td>3.246560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A34LSCB90T5KYE</th>\n",
       "      <td>0.7660</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.066717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.066717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A36BPBYVFDSNBB</th>\n",
       "      <td>1.0418</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.679400</td>\n",
       "      <td>1.707600</td>\n",
       "      <td>1.665300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3D3FNUSK1A2P6</th>\n",
       "      <td>1.2038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.498900</td>\n",
       "      <td>2.772667</td>\n",
       "      <td>2.225133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3DP9IH8W5OXJL</th>\n",
       "      <td>0.7076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.943550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.943550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3G55RJTW3BSGM</th>\n",
       "      <td>0.6656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.340900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.340900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3QO3HIV92H659</th>\n",
       "      <td>0.8448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.553000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.553000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3S3WYVCVWW8IZ</th>\n",
       "      <td>0.9519</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.003500</td>\n",
       "      <td>1.905000</td>\n",
       "      <td>2.052750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A66QAY9ZC7PS4</th>\n",
       "      <td>1.4650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.712500</td>\n",
       "      <td>4.418333</td>\n",
       "      <td>7.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A9500TJQDB94E</th>\n",
       "      <td>0.9920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.754167</td>\n",
       "      <td>2.132333</td>\n",
       "      <td>1.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMAEYJH3DWA1V</th>\n",
       "      <td>1.3290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.723000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.723000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AQN32EZB7OQRG</th>\n",
       "      <td>1.1640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.381967</td>\n",
       "      <td>1.970800</td>\n",
       "      <td>2.464200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT5LT9B0GKOIK</th>\n",
       "      <td>2.4144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.515867</td>\n",
       "      <td>0.716000</td>\n",
       "      <td>3.415800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVSPYLB9KOHMX</th>\n",
       "      <td>0.7970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.358833</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.350600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A1122EUMFXHF38         1.1080                 1.0            0.833333   \n",
       "A1I5KX8TP3K5L2         1.1943                 1.0            0.500000   \n",
       "A1P2XKONWAOXHP         2.2121                 1.0            0.666667   \n",
       "A1T6TTD7XCUHOU         1.6770                 1.0            0.833333   \n",
       "A1TPGXT718D68E         0.6776                 1.0            0.833333   \n",
       "A1Y07DW8W2UXSD         1.1390                 1.0            0.666667   \n",
       "A1YC558J4E5KZ          0.5073                 1.0            0.833333   \n",
       "A249ZABI42JTSS         1.0199                 1.0            0.666667   \n",
       "A28P7V6WDT9UN1         0.8590                 1.0            0.666667   \n",
       "A290Z6QAL17PQE         1.1810                 1.0            0.833333   \n",
       "A2KLIBLDVDV144         0.9302                 1.0            0.833333   \n",
       "A2LA3NEWBU30QT         1.6784                 1.0            0.666667   \n",
       "A2MOU3YD664C0H         1.0410                 1.0            0.666667   \n",
       "A2OT9ZJC4MQBS8         0.7694                 1.0            0.500000   \n",
       "A2PAWE1NW4MD8L         1.0550                 1.0            0.333333   \n",
       "A2RSBH1E3TEESG         1.2280                 1.0            0.333333   \n",
       "A2RWLFIP23FZA7         0.6500                 1.0            0.666667   \n",
       "A30RAYNDOWQ61S         0.5881                 1.0            0.833333   \n",
       "A34LSCB90T5KYE         0.7660                 1.0            1.000000   \n",
       "A36BPBYVFDSNBB         1.0418                 1.0            0.666667   \n",
       "A3D3FNUSK1A2P6         1.2038                 1.0            0.500000   \n",
       "A3DP9IH8W5OXJL         0.7076                 1.0            1.000000   \n",
       "A3G55RJTW3BSGM         0.6656                 1.0            1.000000   \n",
       "A3QO3HIV92H659         0.8448                 1.0            1.000000   \n",
       "A3S3WYVCVWW8IZ         0.9519                 1.0            0.666667   \n",
       "A66QAY9ZC7PS4          1.4650                 1.0            0.500000   \n",
       "A9500TJQDB94E          0.9920                 1.0            0.500000   \n",
       "AMAEYJH3DWA1V          1.3290                 1.0            1.000000   \n",
       "AQN32EZB7OQRG          1.1640                 1.0            0.833333   \n",
       "AT5LT9B0GKOIK          2.4144                 1.0            0.666667   \n",
       "AVSPYLB9KOHMX          0.7970                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A1122EUMFXHF38              2.101833                2.031000   \n",
       "A1I5KX8TP3K5L2              1.893267                1.945200   \n",
       "A1P2XKONWAOXHP              1.596817                1.636500   \n",
       "A1T6TTD7XCUHOU              2.315167                1.645000   \n",
       "A1TPGXT718D68E              1.806317                2.352800   \n",
       "A1Y07DW8W2UXSD              1.474167                1.377000   \n",
       "A1YC558J4E5KZ               2.193900                1.853400   \n",
       "A249ZABI42JTSS              2.042283                2.324500   \n",
       "A28P7V6WDT9UN1              1.210833                1.114000   \n",
       "A290Z6QAL17PQE              1.439833                1.150000   \n",
       "A2KLIBLDVDV144              0.997517                0.793300   \n",
       "A2LA3NEWBU30QT              0.751650                0.513200   \n",
       "A2MOU3YD664C0H              3.341833                3.642000   \n",
       "A2OT9ZJC4MQBS8              2.009533                1.401533   \n",
       "A2PAWE1NW4MD8L              1.755667                1.805500   \n",
       "A2RSBH1E3TEESG              1.921033                2.404675   \n",
       "A2RWLFIP23FZA7              2.149000                2.815000   \n",
       "A30RAYNDOWQ61S              3.214067                3.051600   \n",
       "A34LSCB90T5KYE              2.066717                     NaN   \n",
       "A36BPBYVFDSNBB              1.679400                1.707600   \n",
       "A3D3FNUSK1A2P6              2.498900                2.772667   \n",
       "A3DP9IH8W5OXJL              1.943550                     NaN   \n",
       "A3G55RJTW3BSGM              2.340900                     NaN   \n",
       "A3QO3HIV92H659              1.553000                     NaN   \n",
       "A3S3WYVCVWW8IZ              2.003500                1.905000   \n",
       "A66QAY9ZC7PS4               5.712500                4.418333   \n",
       "A9500TJQDB94E               1.754167                2.132333   \n",
       "AMAEYJH3DWA1V               2.723000                     NaN   \n",
       "AQN32EZB7OQRG               2.381967                1.970800   \n",
       "AT5LT9B0GKOIK               2.515867                0.716000   \n",
       "AVSPYLB9KOHMX               1.358833                1.400000   \n",
       "\n",
       "                demo_RT_correct_mean  \n",
       "A1122EUMFXHF38              2.116000  \n",
       "A1I5KX8TP3K5L2              1.841333  \n",
       "A1P2XKONWAOXHP              1.576975  \n",
       "A1T6TTD7XCUHOU              2.449200  \n",
       "A1TPGXT718D68E              1.697020  \n",
       "A1Y07DW8W2UXSD              1.522750  \n",
       "A1YC558J4E5KZ               2.262000  \n",
       "A249ZABI42JTSS              1.901175  \n",
       "A28P7V6WDT9UN1              1.259250  \n",
       "A290Z6QAL17PQE              1.497800  \n",
       "A2KLIBLDVDV144              1.038360  \n",
       "A2LA3NEWBU30QT              0.870875  \n",
       "A2MOU3YD664C0H              3.191750  \n",
       "A2OT9ZJC4MQBS8              2.617533  \n",
       "A2PAWE1NW4MD8L              1.656000  \n",
       "A2RSBH1E3TEESG              0.953750  \n",
       "A2RWLFIP23FZA7              1.816000  \n",
       "A30RAYNDOWQ61S              3.246560  \n",
       "A34LSCB90T5KYE              2.066717  \n",
       "A36BPBYVFDSNBB              1.665300  \n",
       "A3D3FNUSK1A2P6              2.225133  \n",
       "A3DP9IH8W5OXJL              1.943550  \n",
       "A3G55RJTW3BSGM              2.340900  \n",
       "A3QO3HIV92H659              1.553000  \n",
       "A3S3WYVCVWW8IZ              2.052750  \n",
       "A66QAY9ZC7PS4               7.006667  \n",
       "A9500TJQDB94E               1.376000  \n",
       "AMAEYJH3DWA1V               2.723000  \n",
       "AQN32EZB7OQRG               2.464200  \n",
       "AT5LT9B0GKOIK               3.415800  \n",
       "AVSPYLB9KOHMX               1.350600  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this section extract information from the demo phase: it creates a df (all_subjects_summary_demo_info) containingsingle row per participants with metrics from the demo phase (average accuracy, RTs and so on (this can be used to screen participatns for further analysis)):\n",
    "all_subjects_summary_demo_info=pd.DataFrame(index=list(all_subjects_demo_df['subject'].unique()))\n",
    "\n",
    "for cur_subject in all_subjects_demo_df['subject'].unique():\n",
    "    cur_sub_demo_encoding=all_subjects_demo_df.loc[all_subjects_demo_df['subject']==cur_subject]\n",
    "    \n",
    "    #get only attention check related info: \n",
    "    curr_subjects_summary_demo_info=cur_sub_demo_encoding[['demo_encoding_response.keys','DemoCorrect','demo_encoding_response.rt']].copy().dropna()\n",
    "    if len(curr_subjects_summary_demo_info)==0: #empty - the participant didnt respond on the arrow at all: \n",
    "       all_subjects_summary_demo_info.loc[cur_subject,'arrow_correct']=0 \n",
    "       all_subjects_summary_demo_info.loc[cur_subject,'arrow_rt']=np.nan\n",
    "    else: \n",
    "        all_subjects_summary_demo_info.loc[cur_subject,'arrow_rt']=curr_subjects_summary_demo_info['demo_encoding_response.rt'].values\n",
    "        if all(curr_subjects_summary_demo_info['DemoCorrect']==curr_subjects_summary_demo_info['demo_encoding_response.keys']):\n",
    "            all_subjects_summary_demo_info.loc[cur_subject,'arrow_correct']=1\n",
    "        else:\n",
    "            all_subjects_summary_demo_info.loc[cur_subject,'arrow_correct']=0\n",
    "\n",
    "\n",
    "    #get the correctness of the demo testing phase: \n",
    "    cur_sub_demo_test_performence=cur_sub_demo_encoding[['DemoCorrectTest','demo_test_response.keys','demo_test_response.rt']].copy().dropna()\n",
    "    test_match_df=pd.DataFrame(columns=['arrow_correct'],data=cur_sub_demo_test_performence['DemoCorrectTest']==cur_sub_demo_test_performence['demo_test_response.keys'])\n",
    "    test_match_df['demo_test_response.rt']=cur_sub_demo_test_performence['demo_test_response.rt']\n",
    "    accuracy=test_match_df['arrow_correct'].mean()\n",
    "    mean_rt=test_match_df['demo_test_response.rt'].mean()\n",
    "    correct_and_incorrect_rts=test_match_df.groupby('arrow_correct').aggregate({'demo_test_response.rt':'mean'})\n",
    "    #update the summary info row: \n",
    "    all_subjects_summary_demo_info.loc[cur_subject,'demo_accuracy']=accuracy\n",
    "    all_subjects_summary_demo_info.loc[cur_subject,'RT_overall_mean']=mean_rt\n",
    "    all_subjects_summary_demo_info.loc[cur_subject,['RT_incorrect_mean','RT_correct_mean']]=np.nan\n",
    "\n",
    "    if False in correct_and_incorrect_rts.index:\n",
    "        all_subjects_summary_demo_info.loc[cur_subject,'RT_incorrect_mean']=correct_and_incorrect_rts.loc[False].values[0]\n",
    "    if True in correct_and_incorrect_rts.index:\n",
    "        all_subjects_summary_demo_info.loc[cur_subject,'RT_correct_mean']=correct_and_incorrect_rts.loc[True].values[0]\n",
    "\n",
    "\n",
    "#add a prefix to column names: \n",
    "all_subjects_summary_demo_info.columns=['demo_'+col for col in all_subjects_summary_demo_info.columns]\n",
    "all_subjects_summary_demo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1122EUMFXHF38</th>\n",
       "      <td>1.009800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1I5KX8TP3K5L2</th>\n",
       "      <td>1.258740</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1P2XKONWAOXHP</th>\n",
       "      <td>0.970920</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1T6TTD7XCUHOU</th>\n",
       "      <td>1.912750</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1TPGXT718D68E</th>\n",
       "      <td>1.272320</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1Y07DW8W2UXSD</th>\n",
       "      <td>1.250600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1YC558J4E5KZ</th>\n",
       "      <td>0.581260</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A249ZABI42JTSS</th>\n",
       "      <td>0.909800</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A28P7V6WDT9UN1</th>\n",
       "      <td>0.988800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A290Z6QAL17PQE</th>\n",
       "      <td>1.270000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2KLIBLDVDV144</th>\n",
       "      <td>1.086750</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2LA3NEWBU30QT</th>\n",
       "      <td>1.388880</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2MOU3YD664C0H</th>\n",
       "      <td>1.046200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2OT9ZJC4MQBS8</th>\n",
       "      <td>1.761333</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2PAWE1NW4MD8L</th>\n",
       "      <td>1.597400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2RSBH1E3TEESG</th>\n",
       "      <td>1.225100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2RWLFIP23FZA7</th>\n",
       "      <td>0.563400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A30RAYNDOWQ61S</th>\n",
       "      <td>0.573020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A34LSCB90T5KYE</th>\n",
       "      <td>0.750080</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A36BPBYVFDSNBB</th>\n",
       "      <td>1.108360</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3D3FNUSK1A2P6</th>\n",
       "      <td>1.074440</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3DP9IH8W5OXJL</th>\n",
       "      <td>0.766260</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3G55RJTW3BSGM</th>\n",
       "      <td>0.590820</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3QO3HIV92H659</th>\n",
       "      <td>2.124220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3S3WYVCVWW8IZ</th>\n",
       "      <td>1.056220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A66QAY9ZC7PS4</th>\n",
       "      <td>1.681000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A9500TJQDB94E</th>\n",
       "      <td>1.628000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMAEYJH3DWA1V</th>\n",
       "      <td>1.277000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AQN32EZB7OQRG</th>\n",
       "      <td>1.085580</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT5LT9B0GKOIK</th>\n",
       "      <td>1.736600</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVSPYLB9KOHMX</th>\n",
       "      <td>0.994400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                encoding_arrow_mean_rt  encoding_arrow_accuracy\n",
       "A1122EUMFXHF38                1.009800                      1.0\n",
       "A1I5KX8TP3K5L2                1.258740                      1.0\n",
       "A1P2XKONWAOXHP                0.970920                      1.0\n",
       "A1T6TTD7XCUHOU                1.912750                      0.8\n",
       "A1TPGXT718D68E                1.272320                      1.0\n",
       "A1Y07DW8W2UXSD                1.250600                      1.0\n",
       "A1YC558J4E5KZ                 0.581260                      1.0\n",
       "A249ZABI42JTSS                0.909800                      0.6\n",
       "A28P7V6WDT9UN1                0.988800                      1.0\n",
       "A290Z6QAL17PQE                1.270000                      1.0\n",
       "A2KLIBLDVDV144                1.086750                      0.8\n",
       "A2LA3NEWBU30QT                1.388880                      1.0\n",
       "A2MOU3YD664C0H                1.046200                      1.0\n",
       "A2OT9ZJC4MQBS8                1.761333                      0.6\n",
       "A2PAWE1NW4MD8L                1.597400                      1.0\n",
       "A2RSBH1E3TEESG                1.225100                      1.0\n",
       "A2RWLFIP23FZA7                0.563400                      1.0\n",
       "A30RAYNDOWQ61S                0.573020                      1.0\n",
       "A34LSCB90T5KYE                0.750080                      1.0\n",
       "A36BPBYVFDSNBB                1.108360                      1.0\n",
       "A3D3FNUSK1A2P6                1.074440                      1.0\n",
       "A3DP9IH8W5OXJL                0.766260                      1.0\n",
       "A3G55RJTW3BSGM                0.590820                      1.0\n",
       "A3QO3HIV92H659                2.124220                      1.0\n",
       "A3S3WYVCVWW8IZ                1.056220                      1.0\n",
       "A66QAY9ZC7PS4                 1.681000                      1.0\n",
       "A9500TJQDB94E                 1.628000                      1.0\n",
       "AMAEYJH3DWA1V                 1.277000                      1.0\n",
       "AQN32EZB7OQRG                 1.085580                      1.0\n",
       "AT5LT9B0GKOIK                 1.736600                      0.8\n",
       "AVSPYLB9KOHMX                 0.994400                      1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this part extract summary information from the experiment encoding phase: attention check accuracy and timings: \n",
    "all_subjects_summary_encoding_info=pd.DataFrame(index=list(all_subjects_encoding_df['subject'].unique()))\n",
    "\n",
    "for cur_subject in all_subjects_encoding_df['subject'].unique():\n",
    "    cur_sub_encoding=all_subjects_encoding_df.loc[all_subjects_encoding_df['subject']==cur_subject]\n",
    "    \n",
    "    #get only attention check related info: \n",
    "    cur_sub_encoding=cur_sub_encoding[['test_encoding_response.keys','correct','test_encoding_response.rt']].copy().dropna(how = 'all')\n",
    "    if len(cur_sub_encoding)==0: #empty - the participant didnt respond on the arrow at all: \n",
    "       all_subjects_summary_encoding_info.loc[cur_subject,'arrow_accuracy']=0 \n",
    "       all_subjects_summary_encoding_info.loc[cur_subject,'arrow_mean_rt']=np.nan\n",
    "    else: \n",
    "        all_subjects_summary_encoding_info.loc[cur_subject,'arrow_mean_rt']=cur_sub_encoding['test_encoding_response.rt'].mean()\n",
    "        arrow_accuracy=(cur_sub_encoding['correct']==cur_sub_encoding['test_encoding_response.keys']).mean()\n",
    "        all_subjects_summary_encoding_info.loc[cur_subject,'arrow_accuracy']=arrow_accuracy\n",
    "\n",
    "\n",
    "\n",
    "#add a prefix to column names: \n",
    "all_subjects_summary_encoding_info.columns=['encoding_'+col for col in all_subjects_summary_encoding_info.columns]        \n",
    "all_subjects_summary_encoding_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>testing_RT_incorrect_mean</th>\n",
       "      <th>testing_RT_correct_mean</th>\n",
       "      <th>testing_layer_1_rt</th>\n",
       "      <th>testing_layer_1_accuracy</th>\n",
       "      <th>testing_layer_2_rt</th>\n",
       "      <th>testing_layer_2_accuracy</th>\n",
       "      <th>testing_layer_3_rt</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1122EUMFXHF38</th>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.633100</td>\n",
       "      <td>1.671588</td>\n",
       "      <td>1.582769</td>\n",
       "      <td>1.589650</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.546700</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.762950</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1I5KX8TP3K5L2</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>2.166457</td>\n",
       "      <td>3.385755</td>\n",
       "      <td>1.886852</td>\n",
       "      <td>2.223270</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.112747</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.160363</td>\n",
       "      <td>0.35</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1P2XKONWAOXHP</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>2.083470</td>\n",
       "      <td>2.026427</td>\n",
       "      <td>2.127091</td>\n",
       "      <td>1.970525</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.136015</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.143870</td>\n",
       "      <td>0.75</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1T6TTD7XCUHOU</th>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.417356</td>\n",
       "      <td>2.520421</td>\n",
       "      <td>2.572927</td>\n",
       "      <td>2.613316</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.153600</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.494950</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1TPGXT718D68E</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.652180</td>\n",
       "      <td>1.642933</td>\n",
       "      <td>1.656143</td>\n",
       "      <td>1.736375</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.573695</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.646470</td>\n",
       "      <td>0.70</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1Y07DW8W2UXSD</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.534133</td>\n",
       "      <td>1.369500</td>\n",
       "      <td>1.643889</td>\n",
       "      <td>1.451450</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.441950</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.709000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1YC558J4E5KZ</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>2.279730</td>\n",
       "      <td>2.320081</td>\n",
       "      <td>2.258003</td>\n",
       "      <td>2.013655</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.618470</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.207065</td>\n",
       "      <td>0.60</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A249ZABI42JTSS</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>2.262347</td>\n",
       "      <td>2.263293</td>\n",
       "      <td>2.261461</td>\n",
       "      <td>2.272580</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.308035</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.206425</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A28P7V6WDT9UN1</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>1.371383</td>\n",
       "      <td>1.323379</td>\n",
       "      <td>1.416290</td>\n",
       "      <td>1.355250</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.353000</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.405900</td>\n",
       "      <td>0.60</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A290Z6QAL17PQE</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.426800</td>\n",
       "      <td>1.361833</td>\n",
       "      <td>1.491767</td>\n",
       "      <td>1.422650</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.486450</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.371300</td>\n",
       "      <td>0.35</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2KLIBLDVDV144</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.154768</td>\n",
       "      <td>0.186058</td>\n",
       "      <td>0.458397</td>\n",
       "      <td>0.094311</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.266895</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.100075</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2LA3NEWBU30QT</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.229433</td>\n",
       "      <td>1.128273</td>\n",
       "      <td>1.330593</td>\n",
       "      <td>1.136160</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.100470</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.451670</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2MOU3YD664C0H</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.669217</td>\n",
       "      <td>2.836267</td>\n",
       "      <td>2.502167</td>\n",
       "      <td>2.662400</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.384500</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.960750</td>\n",
       "      <td>0.45</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2OT9ZJC4MQBS8</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.189668</td>\n",
       "      <td>1.178792</td>\n",
       "      <td>1.196919</td>\n",
       "      <td>1.193665</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.297670</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.077670</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2PAWE1NW4MD8L</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>1.892283</td>\n",
       "      <td>1.766931</td>\n",
       "      <td>2.009548</td>\n",
       "      <td>1.596400</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.279400</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.801050</td>\n",
       "      <td>0.65</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2RSBH1E3TEESG</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>2.075883</td>\n",
       "      <td>2.912700</td>\n",
       "      <td>1.999809</td>\n",
       "      <td>2.096030</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.245515</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.886105</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2RWLFIP23FZA7</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.503000</td>\n",
       "      <td>1.506444</td>\n",
       "      <td>1.501524</td>\n",
       "      <td>1.525250</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.455200</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.528550</td>\n",
       "      <td>0.45</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A30RAYNDOWQ61S</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>2.591173</td>\n",
       "      <td>4.219322</td>\n",
       "      <td>2.303853</td>\n",
       "      <td>2.516420</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.653435</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.603665</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A34LSCB90T5KYE</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.574452</td>\n",
       "      <td>1.510615</td>\n",
       "      <td>1.606370</td>\n",
       "      <td>1.440645</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.838730</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.443980</td>\n",
       "      <td>0.65</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A36BPBYVFDSNBB</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>2.031311</td>\n",
       "      <td>10.270646</td>\n",
       "      <td>8.478672</td>\n",
       "      <td>1.759238</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.406300</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.877381</td>\n",
       "      <td>0.45</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3D3FNUSK1A2P6</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.343348</td>\n",
       "      <td>3.259946</td>\n",
       "      <td>3.862036</td>\n",
       "      <td>2.420440</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.369681</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.234283</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3DP9IH8W5OXJL</th>\n",
       "      <td>0.816667</td>\n",
       "      <td>1.508575</td>\n",
       "      <td>1.517473</td>\n",
       "      <td>1.506578</td>\n",
       "      <td>1.530875</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.518590</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.476260</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3G55RJTW3BSGM</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>2.533977</td>\n",
       "      <td>2.630525</td>\n",
       "      <td>2.449497</td>\n",
       "      <td>2.696585</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.517665</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.387680</td>\n",
       "      <td>0.60</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3QO3HIV92H659</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>2.129614</td>\n",
       "      <td>2.496904</td>\n",
       "      <td>2.134909</td>\n",
       "      <td>2.031015</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.057845</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.308947</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3S3WYVCVWW8IZ</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.515252</td>\n",
       "      <td>1.761357</td>\n",
       "      <td>1.382733</td>\n",
       "      <td>1.455290</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.631820</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.458645</td>\n",
       "      <td>0.55</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A66QAY9ZC7PS4</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>2.422678</td>\n",
       "      <td>2.317227</td>\n",
       "      <td>2.693632</td>\n",
       "      <td>2.094850</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.755263</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3.384550</td>\n",
       "      <td>0.75</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A9500TJQDB94E</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.996305</td>\n",
       "      <td>2.442786</td>\n",
       "      <td>1.879063</td>\n",
       "      <td>1.805350</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.084650</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.104316</td>\n",
       "      <td>0.35</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMAEYJH3DWA1V</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>2.726200</td>\n",
       "      <td>2.582476</td>\n",
       "      <td>2.803590</td>\n",
       "      <td>3.332650</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.525000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.320950</td>\n",
       "      <td>0.70</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AQN32EZB7OQRG</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>2.532382</td>\n",
       "      <td>2.769067</td>\n",
       "      <td>2.338730</td>\n",
       "      <td>2.378005</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.802510</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.416630</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT5LT9B0GKOIK</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.266383</td>\n",
       "      <td>0.384224</td>\n",
       "      <td>0.156145</td>\n",
       "      <td>0.196915</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.059530</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.542705</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVSPYLB9KOHMX</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>1.278450</td>\n",
       "      <td>1.308862</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.234350</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.347450</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.253550</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                testing_Test_overall_accuracy  testing_RT_overall_mean  \\\n",
       "A1122EUMFXHF38                       0.433333                 1.633100   \n",
       "A1I5KX8TP3K5L2                       0.516667                 2.166457   \n",
       "A1P2XKONWAOXHP                       0.566667                 2.083470   \n",
       "A1T6TTD7XCUHOU                       0.683333                 2.417356   \n",
       "A1TPGXT718D68E                       0.700000                 1.652180   \n",
       "A1Y07DW8W2UXSD                       0.600000                 1.534133   \n",
       "A1YC558J4E5KZ                        0.650000                 2.279730   \n",
       "A249ZABI42JTSS                       0.516667                 2.262347   \n",
       "A28P7V6WDT9UN1                       0.516667                 1.371383   \n",
       "A290Z6QAL17PQE                       0.500000                 1.426800   \n",
       "A2KLIBLDVDV144                       0.600000                 0.154768   \n",
       "A2LA3NEWBU30QT                       0.500000                 1.229433   \n",
       "A2MOU3YD664C0H                       0.500000                 2.669217   \n",
       "A2OT9ZJC4MQBS8                       0.600000                 1.189668   \n",
       "A2PAWE1NW4MD8L                       0.516667                 1.892283   \n",
       "A2RSBH1E3TEESG                       0.916667                 2.075883   \n",
       "A2RWLFIP23FZA7                       0.700000                 1.503000   \n",
       "A30RAYNDOWQ61S                       0.850000                 2.591173   \n",
       "A34LSCB90T5KYE                       0.666667                 1.574452   \n",
       "A36BPBYVFDSNBB                       0.416667                 2.031311   \n",
       "A3D3FNUSK1A2P6                       0.600000                 2.343348   \n",
       "A3DP9IH8W5OXJL                       0.816667                 1.508575   \n",
       "A3G55RJTW3BSGM                       0.533333                 2.533977   \n",
       "A3QO3HIV92H659                       0.583333                 2.129614   \n",
       "A3S3WYVCVWW8IZ                       0.650000                 1.515252   \n",
       "A66QAY9ZC7PS4                        0.633333                 2.422678   \n",
       "A9500TJQDB94E                        0.533333                 1.996305   \n",
       "AMAEYJH3DWA1V                        0.650000                 2.726200   \n",
       "AQN32EZB7OQRG                        0.550000                 2.532382   \n",
       "AT5LT9B0GKOIK                        0.516667                 0.266383   \n",
       "AVSPYLB9KOHMX                        0.516667                 1.278450   \n",
       "\n",
       "                testing_RT_incorrect_mean  testing_RT_correct_mean  \\\n",
       "A1122EUMFXHF38                   1.671588                 1.582769   \n",
       "A1I5KX8TP3K5L2                   3.385755                 1.886852   \n",
       "A1P2XKONWAOXHP                   2.026427                 2.127091   \n",
       "A1T6TTD7XCUHOU                   2.520421                 2.572927   \n",
       "A1TPGXT718D68E                   1.642933                 1.656143   \n",
       "A1Y07DW8W2UXSD                   1.369500                 1.643889   \n",
       "A1YC558J4E5KZ                    2.320081                 2.258003   \n",
       "A249ZABI42JTSS                   2.263293                 2.261461   \n",
       "A28P7V6WDT9UN1                   1.323379                 1.416290   \n",
       "A290Z6QAL17PQE                   1.361833                 1.491767   \n",
       "A2KLIBLDVDV144                   0.186058                 0.458397   \n",
       "A2LA3NEWBU30QT                   1.128273                 1.330593   \n",
       "A2MOU3YD664C0H                   2.836267                 2.502167   \n",
       "A2OT9ZJC4MQBS8                   1.178792                 1.196919   \n",
       "A2PAWE1NW4MD8L                   1.766931                 2.009548   \n",
       "A2RSBH1E3TEESG                   2.912700                 1.999809   \n",
       "A2RWLFIP23FZA7                   1.506444                 1.501524   \n",
       "A30RAYNDOWQ61S                   4.219322                 2.303853   \n",
       "A34LSCB90T5KYE                   1.510615                 1.606370   \n",
       "A36BPBYVFDSNBB                  10.270646                 8.478672   \n",
       "A3D3FNUSK1A2P6                   3.259946                 3.862036   \n",
       "A3DP9IH8W5OXJL                   1.517473                 1.506578   \n",
       "A3G55RJTW3BSGM                   2.630525                 2.449497   \n",
       "A3QO3HIV92H659                   2.496904                 2.134909   \n",
       "A3S3WYVCVWW8IZ                   1.761357                 1.382733   \n",
       "A66QAY9ZC7PS4                    2.317227                 2.693632   \n",
       "A9500TJQDB94E                    2.442786                 1.879063   \n",
       "AMAEYJH3DWA1V                    2.582476                 2.803590   \n",
       "AQN32EZB7OQRG                    2.769067                 2.338730   \n",
       "AT5LT9B0GKOIK                    0.384224                 0.156145   \n",
       "AVSPYLB9KOHMX                    1.308862                 1.250000   \n",
       "\n",
       "                testing_layer_1_rt  testing_layer_1_accuracy  \\\n",
       "A1122EUMFXHF38            1.589650                      0.40   \n",
       "A1I5KX8TP3K5L2            2.223270                      0.70   \n",
       "A1P2XKONWAOXHP            1.970525                      0.60   \n",
       "A1T6TTD7XCUHOU            2.613316                      0.70   \n",
       "A1TPGXT718D68E            1.736375                      0.65   \n",
       "A1Y07DW8W2UXSD            1.451450                      0.60   \n",
       "A1YC558J4E5KZ             2.013655                      0.70   \n",
       "A249ZABI42JTSS            2.272580                      0.55   \n",
       "A28P7V6WDT9UN1            1.355250                      0.60   \n",
       "A290Z6QAL17PQE            1.422650                      0.65   \n",
       "A2KLIBLDVDV144            0.094311                      0.50   \n",
       "A2LA3NEWBU30QT            1.136160                      0.65   \n",
       "A2MOU3YD664C0H            2.662400                      0.65   \n",
       "A2OT9ZJC4MQBS8            1.193665                      0.55   \n",
       "A2PAWE1NW4MD8L            1.596400                      0.45   \n",
       "A2RSBH1E3TEESG            2.096030                      0.85   \n",
       "A2RWLFIP23FZA7            1.525250                      0.85   \n",
       "A30RAYNDOWQ61S            2.516420                      0.85   \n",
       "A34LSCB90T5KYE            1.440645                      0.65   \n",
       "A36BPBYVFDSNBB            1.759238                      0.50   \n",
       "A3D3FNUSK1A2P6            2.420440                      0.75   \n",
       "A3DP9IH8W5OXJL            1.530875                      0.75   \n",
       "A3G55RJTW3BSGM            2.696585                      0.55   \n",
       "A3QO3HIV92H659            2.031015                      0.45   \n",
       "A3S3WYVCVWW8IZ            1.455290                      0.75   \n",
       "A66QAY9ZC7PS4             2.094850                      0.60   \n",
       "A9500TJQDB94E             1.805350                      0.70   \n",
       "AMAEYJH3DWA1V             3.332650                      0.75   \n",
       "AQN32EZB7OQRG             2.378005                      0.65   \n",
       "AT5LT9B0GKOIK             0.196915                      0.50   \n",
       "AVSPYLB9KOHMX             1.234350                      0.65   \n",
       "\n",
       "                testing_layer_2_rt  testing_layer_2_accuracy  \\\n",
       "A1122EUMFXHF38            1.546700                      0.45   \n",
       "A1I5KX8TP3K5L2            2.112747                      0.50   \n",
       "A1P2XKONWAOXHP            2.136015                      0.35   \n",
       "A1T6TTD7XCUHOU            2.153600                      0.70   \n",
       "A1TPGXT718D68E            1.573695                      0.75   \n",
       "A1Y07DW8W2UXSD            1.441950                      0.65   \n",
       "A1YC558J4E5KZ             2.618470                      0.65   \n",
       "A249ZABI42JTSS            2.308035                      0.55   \n",
       "A28P7V6WDT9UN1            1.353000                      0.35   \n",
       "A290Z6QAL17PQE            1.486450                      0.50   \n",
       "A2KLIBLDVDV144            0.266895                      0.70   \n",
       "A2LA3NEWBU30QT            1.100470                      0.35   \n",
       "A2MOU3YD664C0H            2.384500                      0.40   \n",
       "A2OT9ZJC4MQBS8            1.297670                      0.70   \n",
       "A2PAWE1NW4MD8L            2.279400                      0.45   \n",
       "A2RSBH1E3TEESG            2.245515                      0.90   \n",
       "A2RWLFIP23FZA7            1.455200                      0.80   \n",
       "A30RAYNDOWQ61S            2.653435                      0.85   \n",
       "A34LSCB90T5KYE            1.838730                      0.70   \n",
       "A36BPBYVFDSNBB            2.406300                      0.30   \n",
       "A3D3FNUSK1A2P6            2.369681                      0.50   \n",
       "A3DP9IH8W5OXJL            1.518590                      0.85   \n",
       "A3G55RJTW3BSGM            2.517665                      0.45   \n",
       "A3QO3HIV92H659            2.057845                      0.70   \n",
       "A3S3WYVCVWW8IZ            1.631820                      0.65   \n",
       "A66QAY9ZC7PS4             1.755263                      0.55   \n",
       "A9500TJQDB94E             2.084650                      0.55   \n",
       "AMAEYJH3DWA1V             2.525000                      0.50   \n",
       "AQN32EZB7OQRG             2.802510                      0.60   \n",
       "AT5LT9B0GKOIK             0.059530                      0.35   \n",
       "AVSPYLB9KOHMX             1.347450                      0.55   \n",
       "\n",
       "                testing_layer_3_rt  testing_layer_3_accuracy  \\\n",
       "A1122EUMFXHF38            1.762950                      0.45   \n",
       "A1I5KX8TP3K5L2            2.160363                      0.35   \n",
       "A1P2XKONWAOXHP            2.143870                      0.75   \n",
       "A1T6TTD7XCUHOU            2.494950                      0.65   \n",
       "A1TPGXT718D68E            1.646470                      0.70   \n",
       "A1Y07DW8W2UXSD            1.709000                      0.55   \n",
       "A1YC558J4E5KZ             2.207065                      0.60   \n",
       "A249ZABI42JTSS            2.206425                      0.45   \n",
       "A28P7V6WDT9UN1            1.405900                      0.60   \n",
       "A290Z6QAL17PQE            1.371300                      0.35   \n",
       "A2KLIBLDVDV144            0.100075                      0.60   \n",
       "A2LA3NEWBU30QT            1.451670                      0.50   \n",
       "A2MOU3YD664C0H            2.960750                      0.45   \n",
       "A2OT9ZJC4MQBS8            1.077670                      0.55   \n",
       "A2PAWE1NW4MD8L            1.801050                      0.65   \n",
       "A2RSBH1E3TEESG            1.886105                      1.00   \n",
       "A2RWLFIP23FZA7            1.528550                      0.45   \n",
       "A30RAYNDOWQ61S            2.603665                      0.85   \n",
       "A34LSCB90T5KYE            1.443980                      0.65   \n",
       "A36BPBYVFDSNBB            1.877381                      0.45   \n",
       "A3D3FNUSK1A2P6            2.234283                      0.55   \n",
       "A3DP9IH8W5OXJL            1.476260                      0.85   \n",
       "A3G55RJTW3BSGM            2.387680                      0.60   \n",
       "A3QO3HIV92H659            2.308947                      0.60   \n",
       "A3S3WYVCVWW8IZ            1.458645                      0.55   \n",
       "A66QAY9ZC7PS4             3.384550                      0.75   \n",
       "A9500TJQDB94E             2.104316                      0.35   \n",
       "AMAEYJH3DWA1V             2.320950                      0.70   \n",
       "AQN32EZB7OQRG             2.416630                      0.40   \n",
       "AT5LT9B0GKOIK             0.542705                      0.70   \n",
       "AVSPYLB9KOHMX             1.253550                      0.35   \n",
       "\n",
       "                testing_longest_response_strike  \n",
       "A1122EUMFXHF38                             11.0  \n",
       "A1I5KX8TP3K5L2                              3.0  \n",
       "A1P2XKONWAOXHP                              6.0  \n",
       "A1T6TTD7XCUHOU                              4.0  \n",
       "A1TPGXT718D68E                              5.0  \n",
       "A1Y07DW8W2UXSD                              7.0  \n",
       "A1YC558J4E5KZ                               5.0  \n",
       "A249ZABI42JTSS                              4.0  \n",
       "A28P7V6WDT9UN1                              5.0  \n",
       "A290Z6QAL17PQE                              3.0  \n",
       "A2KLIBLDVDV144                              1.0  \n",
       "A2LA3NEWBU30QT                              6.0  \n",
       "A2MOU3YD664C0H                              5.0  \n",
       "A2OT9ZJC4MQBS8                              3.0  \n",
       "A2PAWE1NW4MD8L                              7.0  \n",
       "A2RSBH1E3TEESG                              7.0  \n",
       "A2RWLFIP23FZA7                              6.0  \n",
       "A30RAYNDOWQ61S                              4.0  \n",
       "A34LSCB90T5KYE                             10.0  \n",
       "A36BPBYVFDSNBB                              7.0  \n",
       "A3D3FNUSK1A2P6                              8.0  \n",
       "A3DP9IH8W5OXJL                              5.0  \n",
       "A3G55RJTW3BSGM                              5.0  \n",
       "A3QO3HIV92H659                              3.0  \n",
       "A3S3WYVCVWW8IZ                              6.0  \n",
       "A66QAY9ZC7PS4                              56.0  \n",
       "A9500TJQDB94E                               4.0  \n",
       "AMAEYJH3DWA1V                               5.0  \n",
       "AQN32EZB7OQRG                               4.0  \n",
       "AT5LT9B0GKOIK                               2.0  \n",
       "AVSPYLB9KOHMX                               2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this part extract summary information from the experiment testing phase: attention check accuracy and timings: \n",
    "all_subjects_summary_testing_info=pd.DataFrame(index=list(all_subjects_test_df['subject'].unique()))\n",
    "\n",
    "\n",
    "#this code calculates response time averages (RT) exlcusing the trials that are TOO long: \n",
    "trial_too_long_exclusion_criteria=10\n",
    "\n",
    "\n",
    "for cur_subject in all_subjects_test_df['subject'].unique():\n",
    "    cur_sub_testing=all_subjects_test_df.loc[all_subjects_test_df['subject']==cur_subject]\n",
    "\n",
    "    #get the correctness of the testing phase: \n",
    "    cur_sub_testing_performence=cur_sub_testing[['correct','test_test_response.keys','test_test_response.rt','layer','test_test_response.corr']].copy().dropna()\n",
    "\n",
    "\n",
    "    test_match_df=pd.DataFrame(columns=['correct'],data=cur_sub_testing_performence['correct']==cur_sub_testing_performence['test_test_response.keys'])\n",
    "    test_match_df['test_test_response.rt']=cur_sub_testing_performence['test_test_response.rt']\n",
    "    accuracy=test_match_df['correct'].mean()\n",
    "\n",
    "    # if there is one rt that is very long, lets not include it in the mean calculation \n",
    "    \n",
    "    mean_rt=(test_match_df.loc[test_match_df['test_test_response.rt']<=trial_too_long_exclusion_criteria,'test_test_response.rt']).mean()\n",
    "    correct_and_incorrect_rts_overall=test_match_df.groupby('correct').aggregate({'test_test_response.rt':'mean'})\n",
    "    \n",
    "    #update the summary info row: \n",
    "    all_subjects_summary_testing_info.loc[cur_subject,'Test_overall_accuracy']=accuracy\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,'RT_overall_mean']=mean_rt\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,['RT_incorrect_mean','RT_correct_mean']]=np.nan\n",
    "\n",
    "    if False in correct_and_incorrect_rts_overall.index:\n",
    "        all_subjects_summary_testing_info.loc[cur_subject,'RT_incorrect_mean']=correct_and_incorrect_rts_overall.loc[False].values[0]\n",
    "    if True in correct_and_incorrect_rts_overall.index:\n",
    "        all_subjects_summary_testing_info.loc[cur_subject,'RT_correct_mean']=correct_and_incorrect_rts_overall.loc[True].values[0]\n",
    "\n",
    "\n",
    "\n",
    "    #extract layer wise information (accuracy and rt):\n",
    "    cur_sub_testing_performence_copy=cur_sub_testing_performence.copy()\n",
    "    cur_sub_testing_performence_copy.loc[cur_sub_testing_performence_copy['test_test_response.rt']>trial_too_long_exclusion_criteria,'test_test_response.rt']=nan\n",
    "    correct_and_incorrect_rts=cur_sub_testing_performence_copy.groupby('layer').aggregate({'test_test_response.rt':'mean','test_test_response.corr':'mean'})\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,['layer_1_rt','layer_1_accuracy','layer_2_rt','layer_2_accuracy','layer_3_rt','layer_3_accuracy']]=correct_and_incorrect_rts.values.flatten()\n",
    "\n",
    "\n",
    "    #check the longest structured strike (to find bots or very unattentive participants):\n",
    "    responses=cur_sub_testing_performence['test_test_response.keys'].replace({'left':1,'right':2}).values\n",
    "    max_iter=find_largest_consequtive_repetition(responses)\n",
    "\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,'longest_response_strike']=max_iter\n",
    "\n",
    "#add a prefix to column names: \n",
    "all_subjects_summary_testing_info.columns=['testing_'+col for col in all_subjects_summary_testing_info.columns]        \n",
    "all_subjects_summary_testing_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>test_test_response.keys</th>\n",
       "      <th>test_test_response.rt</th>\n",
       "      <th>layer</th>\n",
       "      <th>test_test_response.corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2.192</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.412</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.193</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.161</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.548</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.535</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.289</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.301</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.177</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.509</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.797</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.558</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.147</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.145</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.126</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.282</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.228</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.264</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.404</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.151</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.140</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.914</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.447</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.319</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.881</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.021</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.155</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.472</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>0.783</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.511</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.106</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.161</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.183</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.273</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.924</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.411</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.399</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.441</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.391</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.410</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.275</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.048</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.226</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.334</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.198</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.161</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     correct test_test_response.keys  test_test_response.rt  layer  \\\n",
       "1800    left                   right                  2.192    3.0   \n",
       "1801    left                   right                  1.412    3.0   \n",
       "1802   right                    left                  1.193    3.0   \n",
       "1803   right                   right                  1.024    1.0   \n",
       "1804   right                   right                  1.301    1.0   \n",
       "1805   right                    left                  1.426    1.0   \n",
       "1806    left                    left                  1.165    1.0   \n",
       "1807   right                   right                  1.161    3.0   \n",
       "1808    left                   right                  1.548    2.0   \n",
       "1809    left                   right                  1.535    2.0   \n",
       "1810    left                    left                  1.289    1.0   \n",
       "1811   right                    left                  1.301    3.0   \n",
       "1812   right                   right                  1.104    1.0   \n",
       "1813    left                    left                  1.301    1.0   \n",
       "1814   right                   right                  1.177    1.0   \n",
       "1815    left                    left                  1.509    2.0   \n",
       "1816    left                    left                  1.797    2.0   \n",
       "1817   right                    left                  1.558    2.0   \n",
       "1818    left                   right                  1.147    2.0   \n",
       "1819    left                   right                  1.174    1.0   \n",
       "1820   right                   right                  1.145    2.0   \n",
       "1821   right                    left                  1.126    1.0   \n",
       "1822    left                    left                  1.409    1.0   \n",
       "1823    left                   right                  1.282    2.0   \n",
       "1824   right                   right                  1.116    1.0   \n",
       "1825    left                    left                  1.228    2.0   \n",
       "1826    left                    left                  1.300    2.0   \n",
       "1827    left                   right                  1.264    2.0   \n",
       "1828    left                   right                  1.404    2.0   \n",
       "1829    left                    left                  1.151    2.0   \n",
       "1830   right                    left                  1.140    3.0   \n",
       "1831   right                    left                  1.533    3.0   \n",
       "1832    left                   right                  0.914    3.0   \n",
       "1833    left                    left                  1.447    1.0   \n",
       "1834   right                    left                  1.319    2.0   \n",
       "1835    left                   right                  0.881    3.0   \n",
       "1836    left                   right                  1.021    3.0   \n",
       "1837   right                    left                  1.155    1.0   \n",
       "1838   right                    left                  1.472    3.0   \n",
       "1839   right                   right                  0.783    3.0   \n",
       "1840   right                   right                  1.511    3.0   \n",
       "1841    left                    left                  1.106    2.0   \n",
       "1842    left                    left                  1.161    2.0   \n",
       "1843    left                   right                  1.293    1.0   \n",
       "1844   right                    left                  1.283    1.0   \n",
       "1845    left                    left                  1.183    1.0   \n",
       "1846   right                   right                  1.273    3.0   \n",
       "1847   right                    left                  0.924    3.0   \n",
       "1848   right                   right                  1.411    2.0   \n",
       "1849   right                    left                  1.275    1.0   \n",
       "1850   right                   right                  1.399    2.0   \n",
       "1851   right                    left                  1.441    3.0   \n",
       "1852    left                    left                  1.391    1.0   \n",
       "1853    left                   right                  1.410    2.0   \n",
       "1854    left                    left                  1.275    2.0   \n",
       "1855   right                   right                  1.048    1.0   \n",
       "1856    left                    left                  1.226    3.0   \n",
       "1857   right                    left                  1.334    3.0   \n",
       "1858   right                   right                  1.198    3.0   \n",
       "1859   right                   right                  1.161    3.0   \n",
       "\n",
       "      test_test_response.corr  \n",
       "1800                      0.0  \n",
       "1801                      0.0  \n",
       "1802                      0.0  \n",
       "1803                      1.0  \n",
       "1804                      1.0  \n",
       "1805                      0.0  \n",
       "1806                      1.0  \n",
       "1807                      1.0  \n",
       "1808                      0.0  \n",
       "1809                      0.0  \n",
       "1810                      1.0  \n",
       "1811                      0.0  \n",
       "1812                      1.0  \n",
       "1813                      1.0  \n",
       "1814                      1.0  \n",
       "1815                      1.0  \n",
       "1816                      1.0  \n",
       "1817                      0.0  \n",
       "1818                      0.0  \n",
       "1819                      0.0  \n",
       "1820                      1.0  \n",
       "1821                      0.0  \n",
       "1822                      1.0  \n",
       "1823                      0.0  \n",
       "1824                      1.0  \n",
       "1825                      1.0  \n",
       "1826                      1.0  \n",
       "1827                      0.0  \n",
       "1828                      0.0  \n",
       "1829                      1.0  \n",
       "1830                      0.0  \n",
       "1831                      0.0  \n",
       "1832                      0.0  \n",
       "1833                      1.0  \n",
       "1834                      0.0  \n",
       "1835                      0.0  \n",
       "1836                      0.0  \n",
       "1837                      0.0  \n",
       "1838                      0.0  \n",
       "1839                      1.0  \n",
       "1840                      1.0  \n",
       "1841                      1.0  \n",
       "1842                      1.0  \n",
       "1843                      0.0  \n",
       "1844                      0.0  \n",
       "1845                      1.0  \n",
       "1846                      1.0  \n",
       "1847                      0.0  \n",
       "1848                      1.0  \n",
       "1849                      0.0  \n",
       "1850                      1.0  \n",
       "1851                      0.0  \n",
       "1852                      1.0  \n",
       "1853                      0.0  \n",
       "1854                      1.0  \n",
       "1855                      1.0  \n",
       "1856                      1.0  \n",
       "1857                      0.0  \n",
       "1858                      1.0  \n",
       "1859                      1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cur_sub_testing_performence.loc[cur_sub_testing_performence['test_test_response.rt']>trial_too_long_exclusion_criteria,'test_test_response.rt']=nan\n",
    "cur_sub_testing_performence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outlier_responses(sub_test_dataframe,fast_threshold=0.1,fast_allowed_count=2,slow_threshold=10,slow_allowed_count=2):\n",
    "    isfast_outlier=(sub_test_dataframe['test_test_response.rt']<fast_threshold).sum()>fast_allowed_count\n",
    "    isslow_outlier=(sub_test_dataframe['test_test_response.rt']>slow_threshold).sum()>slow_allowed_count\n",
    "    return isfast_outlier,isslow_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary for criterions:\n",
      "demo accuracy higher than 0.5 - qualified: 29\n",
      "demo attention check correctness equals 1.0 - qualified: 31\n",
      "experiment encoding attention check accuracy 0.6 - qualified: 29\n",
      "experiment longest consequtive strike of maximum of  15.0 responses - qualified: 30\n",
      "test too fast (thresold: 0.3, allowed count: 3.0 qualified: 29\n",
      "test too slow (thresold: 10.0, allowed count: 2.0 qualified: 29\n",
      "above chance accuracy in test, qualified: 13\n",
      "OVERALL: number of qualified participants (adhere to all criterions): 10\n"
     ]
    }
   ],
   "source": [
    "#combine all oneliners into a single matrix - 1 line per participant with all information we want:\n",
    "data_df_for_analysis=pd.concat([all_subjects_summary_demo_info,all_subjects_summary_encoding_info,all_subjects_summary_testing_info],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#as each participant saw 20 distractors per layer, we need atleast 0.75 (15/20) accuracy in one of the layers or above 0.616 (37/60) in the overall: \n",
    "\n",
    "#how many participants would fail the demo (did not correctly answered the arrow or had less than 60% performence)\n",
    "demo_criterions_accuracy=data_df_for_analysis['demo_demo_accuracy']>=criterions_df['demo_accuracy_treshold']\n",
    "demo_criterions_attention_check=data_df_for_analysis['demo_arrow_correct']>=criterions_df['demo_arrow_correctness']\n",
    "#find which participants performed pooly on the attention checks of the experiment encoding phase: \n",
    "encoding_ciriterions=data_df_for_analysis['encoding_arrow_accuracy']>criterions_df['encoding_arrow_accuracy']\n",
    "#remove participants that are too slow: \n",
    "test_criterions_strike=data_df_for_analysis['testing_longest_response_strike']<criterions_df['longest_allowed_consequtive_strike']\n",
    "\n",
    "too_fast_criterions=[]\n",
    "too_slow_criterions=[]\n",
    "for subject in data_df_for_analysis.index:\n",
    "    sub_test_dataframe=all_subjects_test_df[all_subjects_test_df['subject']==subject]\n",
    "    toofast_criterion,tooslow_criterion=find_outlier_responses(sub_test_dataframe,fast_threshold=criterions_df['fast_threshold'],fast_allowed_count=criterions_df['fast_allowed_count'],slow_threshold=criterions_df['slow_threshold'],slow_allowed_count=criterions_df['slow_allowed_count'])\n",
    "    too_slow_criterions.append(not tooslow_criterion)\n",
    "    too_fast_criterions.append(not toofast_criterion)\n",
    "\n",
    "\n",
    "\n",
    "print(f'summary for criterions:')\n",
    "print(f'demo accuracy higher than {criterions_df.demo_accuracy_treshold} - qualified: {demo_criterions_accuracy.sum()}')\n",
    "print(f'demo attention check correctness equals {criterions_df.demo_arrow_correctness} - qualified: {demo_criterions_attention_check.sum()}')\n",
    "print(f'experiment encoding attention check accuracy {criterions_df.encoding_arrow_accuracy} - qualified: {encoding_ciriterions.sum()}')\n",
    "print(f'experiment longest consequtive strike of maximum of  {criterions_df.longest_allowed_consequtive_strike} responses - qualified: {test_criterions_strike.sum()}')\n",
    "print(f'test too fast (thresold: {criterions_df.fast_threshold}, allowed count: {criterions_df.fast_allowed_count} qualified: {sum(too_fast_criterions)}')\n",
    "print(f'test too slow (thresold: {criterions_df.slow_threshold}, allowed count: {criterions_df.slow_allowed_count} qualified: {sum(too_slow_criterions)}')\n",
    "#accuracy criterion on the test: \n",
    "test_accuracy_critertions=(data_df_for_analysis['testing_Test_overall_accuracy']>=criterions_df['binom_averages']) | (data_df_for_analysis[['testing_layer_1_accuracy' ,'testing_layer_2_accuracy' ,'testing_layer_3_accuracy']]>=criterions_df['binom_single_layer']).T.any()\n",
    "#remove participants that were discarded based on behavior up to the test and now qualify or disqualify based on test accuracy (do they have atleast 1 significant (binomial test) accuracy in one layer, or above threshold in overall accuracy )\n",
    "only_qualified=demo_criterions_accuracy & demo_criterions_attention_check & encoding_ciriterions & test_criterions_strike & too_fast_criterions & too_slow_criterions & test_accuracy_critertions\n",
    "print(f'above chance accuracy in test, qualified: {sum(test_accuracy_critertions)}')\n",
    "print(f'OVERALL: number of qualified participants (adhere to all criterions): {sum(only_qualified)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A15B4KZ3S04HS8': [999, 1667149704730, 1667223830820, 1667239242566],\n",
       " 'A1LA6CIGBNDOH9': [999, 1667156876722, 1667237966478],\n",
       " 'A22HIX1M4QXZBB': [999, 1666804285762, 1666882028114],\n",
       " 'A248QG4DPULP46': [999, 1666796745860, 1666875548743],\n",
       " 'A2J1DNVMJ56JG1': [999, 1666806879557, 1666887012627],\n",
       " 'A2J57IBR2XIWLS': [999, 1667171400527, 1667244911656, 1667248541474],\n",
       " 'A3MIDLO5S7FU06': [999, 1667148924846, 1667227496622],\n",
       " 'A3U0GQGAPN2DAV': [999, 1667148683750, 1667239544108],\n",
       " 'A5P12YJP805RG': [999, 1667147891427, 1667216156787, 1667226130459],\n",
       " 'ASNNAP90D5R1Z': [999, 1667152406322, 1667216854306, 1667237576573],\n",
       " 'A1JJYY622DGE5L': [0, 1667410475964, 1667477742569],\n",
       " 'A2KDZLWD8RAHDM': [999, 1667410512595],\n",
       " 'AE33JO53WTHZQ': [4, 1667410525427, 1667460407566, 1667492580892],\n",
       " 'A4ANRSA55IW5Q': [5, 1667410579171, 1667460858095],\n",
       " 'A11EXIB1MVBZFJ': [6,\n",
       "  1667410584962,\n",
       "  1667481177705,\n",
       "  1667481243565,\n",
       "  1667486537259],\n",
       " 'AMEBLCWTZKLS2': [8, 1667410598167, 1667492835383],\n",
       " 'A3EBIC3PKUSKCL': [9, 1667410616477],\n",
       " 'A1PN0EFQD8OHSU': [999, 999, 999],\n",
       " 'ASVSPBUO4YRBT': [999,\n",
       "  1667410627238,\n",
       "  1667410745681,\n",
       "  1667410971272,\n",
       "  1667414162527],\n",
       " 'A10AKR84P1WXHL': [999, 999, 999],\n",
       " 'AVZRZOK0F26P6': [12,\n",
       "  1667410735707,\n",
       "  1667460650866,\n",
       "  1667464035856,\n",
       "  1667470051189],\n",
       " 'A3EWBTHYFI4I6Q': [999, 1667410796338, 1667411217538, 1667412334055],\n",
       " 'A1MT4FMXL4WRAF': [999, 999, 999],\n",
       " 'ABGKJYEITBKIL': [999, 999, 999],\n",
       " 'AK4WAT44YKU7J': [14, 1667410895492, 1667499225041],\n",
       " 'A23OK9EV00HCR4': [999, 1667410896026, 1667411400167, 1667411936244],\n",
       " 'A3VHDQR8A9JJ4F': [15, 1667410936684, 1667481841208, 1667489120043],\n",
       " 'AL113DDABUJQ0': [999, 999, 999],\n",
       " 'A1CB9NR3SN4VMY': [999, 999, 999],\n",
       " 'AB8XECKH1JO8P': [18, 1667411003183, 1667477788852],\n",
       " 'A2HY7GQ07YIZTT': [999, 1667411105519],\n",
       " 'A33PJ8605347GY': [999, 1667411126127, 1667411219518],\n",
       " 'A1W0K28IND6NR4': [999, 1667411170189],\n",
       " 'A2U50SMRZT60ZF': [999, 1667411316900],\n",
       " 'A1U0FDPQ953KXX': [23,\n",
       "  1667411372469,\n",
       "  1667460670237,\n",
       "  1667486731278,\n",
       "  1667487481938],\n",
       " 'AZNWNTQ47L88M': [999,\n",
       "  1667411391333,\n",
       "  1667412316025,\n",
       "  1667412683374,\n",
       "  1667412895440],\n",
       " 'A2M183CETUMR96': [26, 1667411416274, 1667508073675],\n",
       " 'A1LCUPRZ0I8S3I': [27, 1667411428866, 1667411954191, 1667491335070],\n",
       " 'A1L5A88C9PPK5L': [999, 1667411482584, 1667411924868],\n",
       " 'A3UZ5V4Y0K3YPV': [29, 1667411545745],\n",
       " 'A2FQLA1NF502GW': [999, 1667411467356, 1667411876434],\n",
       " 'AEHH65WR5E3L6': [999, 1667411673797],\n",
       " 'ATA61WNUAP91U': [33,\n",
       "  1667411683834,\n",
       "  1667460503131,\n",
       "  1667460556038,\n",
       "  1667474685059,\n",
       "  1667485798828,\n",
       "  1667485989768,\n",
       "  1667486779367,\n",
       "  1667487486096],\n",
       " 'A149YZJBFRDWBJ': [34, 1667411770370, 1667464142055],\n",
       " 'A1SL80AWG592HX': [999, 1667411857667],\n",
       " 'A1I1IMZ2ROJY3I': [999, 1667412158260],\n",
       " 'A1B2U0G48Y1U52': [999,\n",
       "  1667412168250,\n",
       "  1667412628125,\n",
       "  1667413623675,\n",
       "  1667413924624,\n",
       "  1667414164762],\n",
       " 'A3NME80IO3UFFO': [999, 1667412504694],\n",
       " 'A1TH9QF8FD0SF5': [999, 1667412423095, 1667412467798, 1667412725256],\n",
       " 'A3RDT5DH21PVAR': [40, 1667412557169, 1667463111081, 1667489384949],\n",
       " 'A1F9KLZGHE9DTA': [41, 1667412665463, 1667477099376, 1667490931872],\n",
       " 'A2PTABUVOUYAH5': [999, 1667413036111],\n",
       " 'ALAEBEEHK525U': [999, 1667413197979, 1667413278101],\n",
       " 'A201VG3B3F1Q40': [999, 1667413385261, 1667413892002],\n",
       " 'A3USIO03UXTDUT': [999, 1667413691795],\n",
       " 'AVP8OEUW3NB4D': [999, 1667413739582],\n",
       " 'A2ASRB2MTHDHPD': [48,\n",
       "  1667413818790,\n",
       "  1667460588952,\n",
       "  1667460634014,\n",
       "  1667463332414,\n",
       "  1667469223330,\n",
       "  1667477780124,\n",
       "  1667491030413],\n",
       " 'A3OU2PDA0ZTT4P': [999, 1667414057681, 1667414109456],\n",
       " 'ATRB1HXZI3J2P': [999, 1667414114770, 1667414870410],\n",
       " 'A1HUQ7QA5QWM5Q': [999, 999, 999],\n",
       " 'A2A66W3JTSP642': [52, 1667414300849, 1667463264844, 1667463345795],\n",
       " 'A98E8M4QLI9RS': [53, 1667414307130, 1667496258234],\n",
       " 'A2F5SKVBQQXFX0': [999, 999, 999],\n",
       " 'A3FJQY40AAYLDF': [51, 1667414420527],\n",
       " 'A12K1ADYMRSWMJ': [999, 1667428873368],\n",
       " 'A31FDAPJJ2EBGA': [55,\n",
       "  1667414651812,\n",
       "  1667474991019,\n",
       "  1667476033621,\n",
       "  1667476361011],\n",
       " 'A1W9HGZ8IKQMTW': [999, 1667414589575],\n",
       " 'A3JJXDML3XNSQP': [57, 1667414639083, 1667480092020, 1667495850160],\n",
       " 'A1OOCYEFLAJD98': [58, 1667414710731, 1667504143232],\n",
       " 'A5AE8MWFQVBX62': [999, 1667414713167],\n",
       " 'A129Y082RKJN6V': [999, 1667414976124, 1667415066714, 1667415232165],\n",
       " 'ASQJWS2HM0ZW9': [999, 1667415007137],\n",
       " 'A5JWBZ2885D1N': [999, 999, 999],\n",
       " 'A14CZ7WXO9TOSX': [999, 999, 999],\n",
       " 'AEOLA4FY5IDHE': [999, 999, 999],\n",
       " 'A2Y8LZS5C81O25': [999, 999, 999],\n",
       " 'AQC0KPAOX4ZPL': [999, 999, 999],\n",
       " 'A3NAONPCTVT6P1': [999, 999, 999],\n",
       " 'A2PF6UAA5SUVD0': [999, 999, 999],\n",
       " 'A319QISFZHTOGY': [1000],\n",
       " 'A100FVY6N5ROG6': [1000],\n",
       " 'A290Z6QAL17PQE': [999, 999, 999],\n",
       " 'A2MQPQ30Z0ETL4': [999, 999, 999],\n",
       " 'A2BUHMLNE3LUU0': [999,\n",
       "  1667425773436,\n",
       "  1667425900929,\n",
       "  1667426336350,\n",
       "  1667427580185],\n",
       " 'AG6UL22QLCKOG': [999, 999, 999],\n",
       " 'A29DB0P3TCTY3I': [999, 999, 999],\n",
       " 'A1Y0ZBE9UBJV2S': [999, 999, 999],\n",
       " 'A3Q228ENXTJ38F': [999, 999, 999],\n",
       " 'A1NQVG69U3TRDK': [999, 999, 999],\n",
       " 'A39IAY6VBVR8FD': [999, 999, 999],\n",
       " 'A3JRY3AL756S3P': [999, 999, 999],\n",
       " 'AP9YNGPNQSX7I': [999, 999, 999],\n",
       " 'A29O6FOYRB10S2': [999, 999, 999],\n",
       " 'A31YK51P992Q4L': [999, 999, 999, 1667452473135],\n",
       " 'AUGML2ZY46M47': [999, 999, 999],\n",
       " 'AQCZJ81IS07OK': [999, 999, 1667451864242],\n",
       " 'A2HFHW1AT6CYCV': [999, 999, 999],\n",
       " 'A2A66Wjgsvjmdcmc': [1, 1667464782624],\n",
       " 'A2BUHMLNE3LUU1': [2, 1667515288683]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this section loads the shelf dict in the state it is after finishing the testing session for this batch. \n",
    "shelf_dict_after_test_name=PATH_TO_BATCH / 'shelf after test session closed.txt' #define the name of the relevant shelf for this stage\n",
    "with open(shelf_dict_after_test_name) as f:\n",
    "    data = f.read()\n",
    "shelf_dict = json.loads(data)\n",
    "shelf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section reads all the relevant files: \n",
    "if (PATH_TO_BATCH / 'Batch_encoding_batch_results.csv').exists():\n",
    "    encoding_df=pd.read_csv(PATH_TO_BATCH / 'Batch_encoding_batch_results.csv')\n",
    "else: \n",
    "    print(f'no \"Batch_encoding_batch_results.csv\" was found in data')\n",
    "\n",
    "if (PATH_TO_BATCH / 'Batch_testing_batch_results.csv').exists():\n",
    "    testing_df=pd.read_csv(PATH_TO_BATCH / 'Batch_testing_batch_results.csv')\n",
    "else: \n",
    "    print(f'no \"Batch_testing_batch_results.csv\" was found in data (probably because only the encoding session finished)')\n",
    "if (PATH_TO_BATCH / 'Batch_workers_after_test.csv').exists():\n",
    "    workers_df=pd.read_csv(PATH_TO_BATCH / 'Batch_workers_after_test.csv')\n",
    "else:\n",
    "    print('No AMAZON worker list was found: please make sure to upload one and name it correctly')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_consequtive_repetition(responses_array):\n",
    "#add a stop value so the loop will use the logic also if the end of the responses is all repeating: \n",
    "    responses_array=np.append(responses_array,[99])\n",
    "    longest_rep_dict=dict()\n",
    "    last_input=responses_array[0]\n",
    "    consequtive_rep_counter=0\n",
    "    for response in responses_array[1:]: \n",
    "        if response==last_input: #if consequtive rep: \n",
    "            consequtive_rep_counter=consequtive_rep_counter+1 #add to counter\n",
    "        else: #once a new entry is in the vector - store the counter rep information \n",
    "            if last_input in longest_rep_dict.keys(): #if it was allready stored in our dictionary\n",
    "                if longest_rep_dict[last_input]<consequtive_rep_counter: #replace the counter only if it is higher than what stored in dict\n",
    "                    longest_rep_dict[last_input]=consequtive_rep_counter\n",
    "            else: #this entry is not yet in the dictionary: add it \n",
    "                longest_rep_dict[last_input]=consequtive_rep_counter\n",
    "            \n",
    "            consequtive_rep_counter=0\n",
    "            last_input=response\n",
    "    return max(longest_rep_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_worker_results(PATH_TO_BATCH_DATA,subject_name,parse_type='encoding'):\n",
    "    cur_sub=pd.read_csv(PATH_TO_BATCH_DATA / subject_name)\n",
    "    sub_demographics=cur_sub[['workID','Age','Gender']].iloc[0]\n",
    "\n",
    "    #extract demo related information: \n",
    "\n",
    "    #if participant did not click on the arrow during the demo a 'demo_encoding_response.rt' colmumn wont exists: \n",
    "    #thus we will create one and fill it with nans (so everything will be consistent with other participants)\n",
    "    if not('demo_encoding_response.rt' in cur_sub.columns):\n",
    "        cur_sub['demo_encoding_response.rt']=np.nan\n",
    "    demo_columns=['demo_encoding_loop.thisTrialN','DemoImage','DemoCorrect','demo_encoding_response.rt','demo_encoding_response.keys']\n",
    "\n",
    "    if (parse_type=='encoding'):\n",
    "        sub_demo_information=cur_sub[demo_columns]\n",
    "        empty_inds=sub_demo_information.loc[sub_demo_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "        #drop irrelevant columns: \n",
    "        sub_demo_information=sub_demo_information.drop(index=empty_inds)\n",
    "\n",
    "\n",
    "        #extract the demo test columns: \n",
    "        demo_test_columns=['demo_test_response.keys','demo_test_response.corr','demo_test_response.rt','demo_test_loop.thisTrialN','DemoImage1','DemoImage2','DemoCorrectTest']\n",
    "        sub_demo_test_information=cur_sub[demo_test_columns]\n",
    "        empty_inds=sub_demo_test_information.loc[sub_demo_test_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "        #drop irrelevant columns: \n",
    "        sub_demo_test_information=sub_demo_test_information.drop(index=empty_inds)\n",
    "\n",
    "        demo_df=pd.concat([sub_demo_information.reset_index(),sub_demo_test_information.reset_index()],axis=1)\n",
    "\n",
    "    #extract real experiment related information: \n",
    "\n",
    "    #if participant did not click on the arrow during the encoding a 'test_encoding_response.rt' column wont exists: \n",
    "    #thus we will create one and fill it with nans (so everything will be consistent with other participants)\n",
    "    if not('test_encoding_response.rt' in cur_sub.columns):\n",
    "        cur_sub['test_encoding_response.rt']=np.nan\n",
    "\n",
    "\n",
    "    if (parse_type=='encoding') | (parse_type=='all'):\n",
    "        encoding_related_columns=['test_encoding_response.keys','test_encoding_response.corr','trials.thisTrialN','target_image','pair','layer','correct','test_encoding_response.rt','key_resp_end.keys']\n",
    "        sub_encoding_information=cur_sub[encoding_related_columns]\n",
    "        #encoding section ends with a key press of the space key: so seperate this phase by finding this space key row\n",
    "        end_of_section_ind=np.where(sub_encoding_information['key_resp_end.keys']=='space')[0][0]\n",
    "        sub_encoding_information=sub_encoding_information.iloc[0:end_of_section_ind]\n",
    "        #remove all the rows that precede the real encoding phase: \n",
    "        empty_inds=sub_encoding_information.loc[sub_encoding_information.isnull().apply(lambda x: all(x), axis=1)].index\n",
    "        sub_encoding_information=sub_encoding_information.drop(index=empty_inds).reset_index()\n",
    "\n",
    "    if (parse_type=='test') | (parse_type=='all'):\n",
    "    #extract real experiment TEST related information: \n",
    "        test_related_columns=['layer','correct','test_test_response.keys','test_test_response.corr','test_test_response.rt','trials_2.thisRepN','trials_2.thisTrialN','trials_2.thisN','trials_2.thisIndex','trials_2.ran','image1','image2']\n",
    "        sub_test_information=cur_sub[test_related_columns].dropna()\n",
    "\n",
    "\n",
    "    subject_dictionary=dict()\n",
    "    subject_dictionary['demographics']=sub_demographics\n",
    "    if (parse_type=='encoding') | (parse_type=='all'):\n",
    "        subject_dictionary['demo_df']=demo_df\n",
    "    if (parse_type=='encoding') | (parse_type=='all'):\n",
    "        subject_dictionary['encoding_df']=sub_encoding_information\n",
    "    if (parse_type=='test') | (parse_type=='all'):\n",
    "        subject_dictionary['test_df']=sub_test_information\n",
    "\n",
    "    return subject_dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get all results with Encoding information - extract the arrow attention check accuracy and RT (RT is currently not usd as a criterion)\n",
    "\n",
    "#this section extract the list of participants from the downloaded results files (and not via the workers or session list csvs) \n",
    "# - it will create the qualification_df (a table with information on the worker ids and encoding behavior of all participants that we have files for)\n",
    "all_filenames=[file for file in PATH_TO_BATCH_DATA.iterdir() if 'csv' in file.name and 'ENCODING' in file.name]\n",
    "#print(f'current csv files:\\n{all_filenames}')\n",
    "\n",
    "qualification_for_test_df=pd.DataFrame(columns=['workerID','arrow_acc','mean_arrow_RT'])\n",
    "for subject_csv in all_filenames:\n",
    "    subject_dict=process_worker_results(PATH_TO_BATCH_DATA,path.Path(subject_csv))\n",
    "    cur_sub_encoding=subject_dict['encoding_df']\n",
    "\n",
    "    sname=subject_csv.name.split('_')[1] #change according to actuall format. \n",
    "\n",
    "    #get only attention check related info: \n",
    "    cur_sub_encoding=cur_sub_encoding[['test_encoding_response.keys','correct','test_encoding_response.rt']].copy().dropna(how = 'all')\n",
    "    if len(cur_sub_encoding)==0: #empty - the participant didnt respond on the arrow at all\n",
    "        arrow_acc=0\n",
    "        RT=nan\n",
    "    else: \n",
    "        RT=cur_sub_encoding['test_encoding_response.rt'].mean()\n",
    "        arrow_acc=(cur_sub_encoding['correct']==cur_sub_encoding['test_encoding_response.keys']).mean()\n",
    "    sub_df=pd.DataFrame({'workerID':sname,'arrow_acc':arrow_acc,'mean_arrow_RT':RT},index=[sname])\n",
    "    qualification_for_test_df=pd.concat([qualification_for_test_df,sub_df],axis=0)\n",
    "\n",
    "#the following part update the qualification_df with information on wether the participant id exists in the amazon workers list: \n",
    "\n",
    "#change participants qualifications if they exists in the workers list based on thier encoding arrow accuracy\n",
    "qualification_for_test_df['in_encoding_workers_list']=nan\n",
    "\n",
    "for curr_worker_ID in qualification_for_test_df.index:\n",
    "    if curr_worker_ID in encoding_df['WorkerId'].values:\n",
    "        qualification_for_test_df.loc[curr_worker_ID,'in_encoding_workers_list']=int(1)\n",
    "    else:\n",
    "        qualification_for_test_df.loc[curr_worker_ID,'in_encoding_workers_list']=int(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects_demo_df=pd.DataFrame()\n",
    "all_subjects_encoding_df=pd.DataFrame()\n",
    "all_subjects_test_df=pd.DataFrame()\n",
    "all_subjects_biographics_df=pd.DataFrame()\n",
    "all_filenames=[file.name for file in PATH_TO_BATCH_DATA.iterdir() if 'csv' in file.name and 'TEST' in file.name]\n",
    "\n",
    "for subject_test_filename in all_filenames:\n",
    "    subject_name=subject_test_filename.split('_')[1]\n",
    "    subject_encoding_filename=[file.name for file in PATH_TO_BATCH_DATA.iterdir() if 'csv' in file.name and 'ENCODING' in file.name and subject_name in file.name][0]\n",
    "    curr_subject_dictionary=process_worker_results(PATH_TO_BATCH_DATA,subject_encoding_filename,parse_type='encoding')\n",
    "    curr_demo_df=curr_subject_dictionary['demo_df']\n",
    "    curr_demo_df['subject']=subject_name\n",
    "    curr_encoding_df=curr_subject_dictionary['encoding_df']\n",
    "    curr_encoding_df['subject']=subject_name\n",
    "    curr_demographics_df=curr_subject_dictionary['demographics']\n",
    "    curr_demographics_df['subject']=subject_name\n",
    "\n",
    "    #get the name of this participant encoding: \n",
    "\n",
    "    curr_subject_dictionary=process_worker_results(PATH_TO_BATCH_DATA,subject_test_filename,parse_type='test')\n",
    "    curr_test_df=curr_subject_dictionary['test_df']\n",
    "    curr_test_df['subject']=subject_name\n",
    "\n",
    "\n",
    "\n",
    "    all_subjects_demo_df=pd.concat([all_subjects_demo_df,curr_demo_df],axis=0,ignore_index=True)\n",
    "    all_subjects_encoding_df=pd.concat([all_subjects_encoding_df,curr_encoding_df],axis=0,ignore_index=True)\n",
    "    all_subjects_test_df=pd.concat([all_subjects_test_df,curr_test_df],axis=0,ignore_index=True)\n",
    "    all_subjects_biographics_df=pd.concat([all_subjects_biographics_df,pd.DataFrame(curr_demographics_df).T],axis=0,ignore_index=True)\n",
    "\n",
    "\n",
    "all_subjects_demo_df.to_csv(PATH_TO_BATCH / 'all_subjects_demo_df.csv')\n",
    "all_subjects_encoding_df.to_csv(PATH_TO_BATCH / 'all_subjects_encoding_df.csv')\n",
    "all_subjects_test_df.to_csv(PATH_TO_BATCH / 'all_subjects_test_df.csv')\n",
    "all_subjects_biographics_df.to_csv(PATH_TO_BATCH / 'all_subjects_biographics_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender is still inconsistent with more than 2 unique values: ['Men' 'female' 'male']\n",
      "Mean age: 40.13, range: [23 - 67], 0.33% female\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import category\n",
    "\n",
    "# if there are any empty values - fill with mean of subjects age \n",
    "mean_value = all_subjects_biographics_df['Age'].mean()\n",
    "all_subjects_biographics_df['Age'].fillna(value=mean_value, inplace=True)\n",
    "all_subjects_biographics_df['Age'] = all_subjects_biographics_df['Age'].astype(np.int64)\n",
    "\n",
    "all_subjects_biographics_df['Age']=all_subjects_biographics_df['Age'].astype(int)\n",
    "all_subjects_biographics_df['Gender'].replace({'ma':'male','Femae': 'female','woman':'female','FEMLAE':'female','Male':'male','MALE':'male','FEMALE':'female','Female':'female','ale':'male'},inplace=True)\n",
    "if len(np.unique(all_subjects_biographics_df['Gender'].values))<=2:\n",
    "    print('transformed the gender column to be consistent having two possible values:',np.unique(all_subjects_biographics_df['Gender'].values))\n",
    "else: \n",
    "    print('gender is still inconsistent with more than 2 unique values:',np.unique(all_subjects_biographics_df['Gender'].values))\n",
    "all_subjects_biographics_df['Gender']=all_subjects_biographics_df['Gender'].astype(\"category\")\n",
    "\n",
    "mean_age,min_age,max_age=all_subjects_biographics_df['Age'].mean(),all_subjects_biographics_df['Age'].min(),all_subjects_biographics_df['Age'].max()\n",
    "female_prop=all_subjects_biographics_df.loc[all_subjects_biographics_df['Gender']=='female','Gender'].count()/all_subjects_biographics_df['Gender'].count()\n",
    "\n",
    "print(f'Mean age: {mean_age:.2f}, range: [{min_age} - {max_age}], {female_prop:.2f}% female')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this part plots the seperate dataframes: \n",
    "### demo phase (encoding and test in the same dataframe)\n",
    "### encoding experiment phase\n",
    "### test experiment phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>demo_encoding_loop.thisTrialN</th>\n",
       "      <th>DemoImage</th>\n",
       "      <th>DemoCorrect</th>\n",
       "      <th>demo_encoding_response.rt</th>\n",
       "      <th>demo_encoding_response.keys</th>\n",
       "      <th>index</th>\n",
       "      <th>demo_test_response.keys</th>\n",
       "      <th>demo_test_response.corr</th>\n",
       "      <th>demo_test_response.rt</th>\n",
       "      <th>demo_test_loop.thisTrialN</th>\n",
       "      <th>DemoImage1</th>\n",
       "      <th>DemoImage2</th>\n",
       "      <th>DemoCorrectTest</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>flower1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>flower1.jpg</td>\n",
       "      <td>flower1_pair.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>flower2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>flower2_pair.jpg</td>\n",
       "      <td>flower2.jpg</td>\n",
       "      <td>right</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>1.156</td>\n",
       "      <td>left</td>\n",
       "      <td>14.0</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.285</td>\n",
       "      <td>2.0</td>\n",
       "      <td>flower3.jpg</td>\n",
       "      <td>flower3_pair.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>flower3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>left</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.122</td>\n",
       "      <td>3.0</td>\n",
       "      <td>flower4.jpg</td>\n",
       "      <td>flower4_pair.jpg</td>\n",
       "      <td>left</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>flower4.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.966</td>\n",
       "      <td>4.0</td>\n",
       "      <td>flower5_pair.jpg</td>\n",
       "      <td>flower5.jpg</td>\n",
       "      <td>right</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  demo_encoding_loop.thisTrialN    DemoImage DemoCorrect  \\\n",
       "0      4                            0.0  flower1.jpg         NaN   \n",
       "1      5                            1.0  flower2.jpg         NaN   \n",
       "2      6                            2.0     left.jpg        left   \n",
       "3      7                            3.0  flower3.jpg         NaN   \n",
       "4      8                            4.0  flower4.jpg         NaN   \n",
       "\n",
       "   demo_encoding_response.rt demo_encoding_response.keys  index  \\\n",
       "0                        NaN                         NaN   12.0   \n",
       "1                        NaN                         NaN   13.0   \n",
       "2                      1.156                        left   14.0   \n",
       "3                        NaN                         NaN   15.0   \n",
       "4                        NaN                         NaN   16.0   \n",
       "\n",
       "  demo_test_response.keys  demo_test_response.corr  demo_test_response.rt  \\\n",
       "0                    left                      1.0                 28.483   \n",
       "1                   right                      1.0                 15.897   \n",
       "2                    left                      1.0                  2.285   \n",
       "3                    left                      1.0                  2.122   \n",
       "4                   right                      1.0                  9.966   \n",
       "\n",
       "   demo_test_loop.thisTrialN        DemoImage1        DemoImage2  \\\n",
       "0                        0.0       flower1.jpg  flower1_pair.jpg   \n",
       "1                        1.0  flower2_pair.jpg       flower2.jpg   \n",
       "2                        2.0       flower3.jpg  flower3_pair.jpg   \n",
       "3                        3.0       flower4.jpg  flower4_pair.jpg   \n",
       "4                        4.0  flower5_pair.jpg       flower5.jpg   \n",
       "\n",
       "  DemoCorrectTest         subject  \n",
       "0            left  A11EXIB1MVBZFJ  \n",
       "1           right  A11EXIB1MVBZFJ  \n",
       "2            left  A11EXIB1MVBZFJ  \n",
       "3            left  A11EXIB1MVBZFJ  \n",
       "4           right  A11EXIB1MVBZFJ  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects_demo_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_encoding_response.keys</th>\n",
       "      <th>test_encoding_response.corr</th>\n",
       "      <th>trials.thisTrialN</th>\n",
       "      <th>target_image</th>\n",
       "      <th>pair</th>\n",
       "      <th>layer</th>\n",
       "      <th>correct</th>\n",
       "      <th>test_encoding_response.rt</th>\n",
       "      <th>key_resp_end.keys</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2592379964-131054.jpg</td>\n",
       "      <td>2592380272-354673.jpg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2898635427-367120.jpg</td>\n",
       "      <td>2898621427-366486.jpg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2458347385-199723.jpg</td>\n",
       "      <td>2458347252-348911.jpg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2512875899-126682.jpg</td>\n",
       "      <td>2592380177-354628.jpg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2238481928-19949.jpg</td>\n",
       "      <td>2883264367-365620.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index test_encoding_response.keys  test_encoding_response.corr  \\\n",
       "0     20                         NaN                          1.0   \n",
       "1     21                         NaN                          1.0   \n",
       "2     22                         NaN                          1.0   \n",
       "3     23                         NaN                          1.0   \n",
       "4     24                         NaN                          1.0   \n",
       "\n",
       "   trials.thisTrialN           target_image                   pair  layer  \\\n",
       "0                0.0  2592379964-131054.jpg  2592380272-354673.jpg    3.0   \n",
       "1                1.0  2898635427-367120.jpg  2898621427-366486.jpg    3.0   \n",
       "2                2.0  2458347385-199723.jpg  2458347252-348911.jpg    3.0   \n",
       "3                3.0  2512875899-126682.jpg  2592380177-354628.jpg    2.0   \n",
       "4                4.0   2238481928-19949.jpg  2883264367-365620.jpg    1.0   \n",
       "\n",
       "  correct  test_encoding_response.rt key_resp_end.keys         subject  \n",
       "0     NaN                        NaN               NaN  A11EXIB1MVBZFJ  \n",
       "1     NaN                        NaN               NaN  A11EXIB1MVBZFJ  \n",
       "2     NaN                        NaN               NaN  A11EXIB1MVBZFJ  \n",
       "3     NaN                        NaN               NaN  A11EXIB1MVBZFJ  \n",
       "4     NaN                        NaN               NaN  A11EXIB1MVBZFJ  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects_encoding_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>correct</th>\n",
       "      <th>test_test_response.keys</th>\n",
       "      <th>test_test_response.corr</th>\n",
       "      <th>test_test_response.rt</th>\n",
       "      <th>trials_2.thisRepN</th>\n",
       "      <th>trials_2.thisTrialN</th>\n",
       "      <th>trials_2.thisN</th>\n",
       "      <th>trials_2.thisIndex</th>\n",
       "      <th>trials_2.ran</th>\n",
       "      <th>image1</th>\n",
       "      <th>image2</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>316.708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2238499057-320266.jpg</td>\n",
       "      <td>2238428357-313623.jpg</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2901941438-69835.jpg</td>\n",
       "      <td>2460547508-51571.jpg</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2238560245-182099.jpg</td>\n",
       "      <td>2238480980-168129.jpg</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2864901420-212147.jpg</td>\n",
       "      <td>2864907432-362042.jpg</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2446759803-49250.jpg</td>\n",
       "      <td>2898635428-69104.jpg</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer correct test_test_response.keys  test_test_response.corr  \\\n",
       "0    1.0   right                   right                      1.0   \n",
       "1    3.0   right                    left                      0.0   \n",
       "2    3.0    left                   right                      0.0   \n",
       "3    1.0   right                   right                      1.0   \n",
       "4    1.0   right                   right                      1.0   \n",
       "\n",
       "   test_test_response.rt  trials_2.thisRepN  trials_2.thisTrialN  \\\n",
       "0                316.708                0.0                  0.0   \n",
       "1                  5.956                0.0                  1.0   \n",
       "2                  3.076                0.0                  2.0   \n",
       "3                  1.610                0.0                  3.0   \n",
       "4                  1.676                0.0                  4.0   \n",
       "\n",
       "   trials_2.thisN  trials_2.thisIndex  trials_2.ran                 image1  \\\n",
       "0             0.0                 0.0           1.0  2238499057-320266.jpg   \n",
       "1             1.0                 1.0           1.0   2901941438-69835.jpg   \n",
       "2             2.0                 2.0           1.0  2238560245-182099.jpg   \n",
       "3             3.0                 3.0           1.0  2864901420-212147.jpg   \n",
       "4             4.0                 4.0           1.0   2446759803-49250.jpg   \n",
       "\n",
       "                  image2         subject  \n",
       "0  2238428357-313623.jpg  A11EXIB1MVBZFJ  \n",
       "1   2460547508-51571.jpg  A11EXIB1MVBZFJ  \n",
       "2  2238480980-168129.jpg  A11EXIB1MVBZFJ  \n",
       "3  2864907432-362042.jpg  A11EXIB1MVBZFJ  \n",
       "4   2898635428-69104.jpg  A11EXIB1MVBZFJ  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects_test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11EXIB1MVBZFJ</th>\n",
       "      <td>1.1560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.790667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.790667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1F9KLZGHE9DTA</th>\n",
       "      <td>0.5979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.385950</td>\n",
       "      <td>1.740400</td>\n",
       "      <td>1.315060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1LCUPRZ0I8S3I</th>\n",
       "      <td>0.9871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.185933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OOCYEFLAJD98</th>\n",
       "      <td>0.5116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.427583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1U0FDPQ953KXX</th>\n",
       "      <td>1.1286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.252667</td>\n",
       "      <td>3.311800</td>\n",
       "      <td>5.640840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2ASRB2MTHDHPD</th>\n",
       "      <td>1.2799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.293650</td>\n",
       "      <td>4.709733</td>\n",
       "      <td>5.877567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>0.5185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5.864933</td>\n",
       "      <td>3.148550</td>\n",
       "      <td>11.297700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3JJXDML3XNSQP</th>\n",
       "      <td>1.8620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.357000</td>\n",
       "      <td>15.925000</td>\n",
       "      <td>3.243400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3RDT5DH21PVAR</th>\n",
       "      <td>2.1221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.208033</td>\n",
       "      <td>1.722100</td>\n",
       "      <td>2.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3VHDQR8A9JJ4F</th>\n",
       "      <td>0.6487</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.888650</td>\n",
       "      <td>1.807700</td>\n",
       "      <td>1.904840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A98E8M4QLI9RS</th>\n",
       "      <td>0.4490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.305167</td>\n",
       "      <td>1.206000</td>\n",
       "      <td>1.354750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE33JO53WTHZQ</th>\n",
       "      <td>1.3502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.566183</td>\n",
       "      <td>4.398000</td>\n",
       "      <td>4.650275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK4WAT44YKU7J</th>\n",
       "      <td>0.6394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.239683</td>\n",
       "      <td>2.574500</td>\n",
       "      <td>2.072275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMEBLCWTZKLS2</th>\n",
       "      <td>0.9730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.663333</td>\n",
       "      <td>1.395000</td>\n",
       "      <td>1.717000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATA61WNUAP91U</th>\n",
       "      <td>1.3853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.389683</td>\n",
       "      <td>2.182800</td>\n",
       "      <td>2.431060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A11EXIB1MVBZFJ         1.1560                 1.0            1.000000   \n",
       "A1F9KLZGHE9DTA         0.5979                 1.0            0.833333   \n",
       "A1LCUPRZ0I8S3I         0.9871                 1.0            1.000000   \n",
       "A1OOCYEFLAJD98         0.5116                 1.0            1.000000   \n",
       "A1U0FDPQ953KXX         1.1286                 1.0            0.833333   \n",
       "A2ASRB2MTHDHPD         1.2799                 1.0            0.500000   \n",
       "A2M183CETUMR96         0.5185                 1.0            0.333333   \n",
       "A3JJXDML3XNSQP         1.8620                 1.0            0.833333   \n",
       "A3RDT5DH21PVAR         2.1221                 1.0            0.666667   \n",
       "A3VHDQR8A9JJ4F         0.6487                 1.0            0.833333   \n",
       "A98E8M4QLI9RS          0.4490                 1.0            0.666667   \n",
       "AE33JO53WTHZQ          1.3502                 1.0            0.666667   \n",
       "AK4WAT44YKU7J          0.6394                 1.0            0.666667   \n",
       "AMEBLCWTZKLS2          0.9730                 1.0            0.833333   \n",
       "ATA61WNUAP91U          1.3853                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A11EXIB1MVBZFJ             15.790667                     NaN   \n",
       "A1F9KLZGHE9DTA              1.385950                1.740400   \n",
       "A1LCUPRZ0I8S3I              2.185933                     NaN   \n",
       "A1OOCYEFLAJD98              2.427583                     NaN   \n",
       "A1U0FDPQ953KXX              5.252667                3.311800   \n",
       "A2ASRB2MTHDHPD              5.293650                4.709733   \n",
       "A2M183CETUMR96              5.864933                3.148550   \n",
       "A3JJXDML3XNSQP              5.357000               15.925000   \n",
       "A3RDT5DH21PVAR              2.208033                1.722100   \n",
       "A3VHDQR8A9JJ4F              1.888650                1.807700   \n",
       "A98E8M4QLI9RS               1.305167                1.206000   \n",
       "AE33JO53WTHZQ               4.566183                4.398000   \n",
       "AK4WAT44YKU7J               2.239683                2.574500   \n",
       "AMEBLCWTZKLS2               1.663333                1.395000   \n",
       "ATA61WNUAP91U               2.389683                2.182800   \n",
       "\n",
       "                demo_RT_correct_mean  \n",
       "A11EXIB1MVBZFJ             15.790667  \n",
       "A1F9KLZGHE9DTA              1.315060  \n",
       "A1LCUPRZ0I8S3I              2.185933  \n",
       "A1OOCYEFLAJD98              2.427583  \n",
       "A1U0FDPQ953KXX              5.640840  \n",
       "A2ASRB2MTHDHPD              5.877567  \n",
       "A2M183CETUMR96             11.297700  \n",
       "A3JJXDML3XNSQP              3.243400  \n",
       "A3RDT5DH21PVAR              2.451000  \n",
       "A3VHDQR8A9JJ4F              1.904840  \n",
       "A98E8M4QLI9RS               1.354750  \n",
       "AE33JO53WTHZQ               4.650275  \n",
       "AK4WAT44YKU7J               2.072275  \n",
       "AMEBLCWTZKLS2               1.717000  \n",
       "ATA61WNUAP91U               2.431060  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this section extract information from the demo phase: it creates a df (all_subjects_summary_demo_info) containingsingle row per participants with metrics from the demo phase (average accuracy, RTs and so on (this can be used to screen participatns for further analysis)):\n",
    "all_subjects_summary_demo_info=pd.DataFrame(index=list(all_subjects_demo_df['subject'].unique()))\n",
    "\n",
    "for cur_subject in all_subjects_demo_df['subject'].unique():\n",
    "    cur_sub_demo_encoding=all_subjects_demo_df.loc[all_subjects_demo_df['subject']==cur_subject]\n",
    "    \n",
    "    #get only attention check related info: \n",
    "    curr_subjects_summary_demo_info=cur_sub_demo_encoding[['demo_encoding_response.keys','DemoCorrect','demo_encoding_response.rt']].copy().dropna()\n",
    "    if len(curr_subjects_summary_demo_info)==0: #empty - the participant didnt respond on the arrow at all: \n",
    "       all_subjects_summary_demo_info.loc[cur_subject,'arrow_correct']=0 \n",
    "       all_subjects_summary_demo_info.loc[cur_subject,'arrow_rt']=np.nan\n",
    "    else: \n",
    "        all_subjects_summary_demo_info.loc[cur_subject,'arrow_rt']=curr_subjects_summary_demo_info['demo_encoding_response.rt'].values\n",
    "        if all(curr_subjects_summary_demo_info['DemoCorrect']==curr_subjects_summary_demo_info['demo_encoding_response.keys']):\n",
    "            all_subjects_summary_demo_info.loc[cur_subject,'arrow_correct']=1\n",
    "        else:\n",
    "            all_subjects_summary_demo_info.loc[cur_subject,'arrow_correct']=0\n",
    "\n",
    "\n",
    "    #get the correctness of the demo testing phase: \n",
    "    cur_sub_demo_test_performence=cur_sub_demo_encoding[['DemoCorrectTest','demo_test_response.keys','demo_test_response.rt']].copy().dropna()\n",
    "    test_match_df=pd.DataFrame(columns=['arrow_correct'],data=cur_sub_demo_test_performence['DemoCorrectTest']==cur_sub_demo_test_performence['demo_test_response.keys'])\n",
    "    test_match_df['demo_test_response.rt']=cur_sub_demo_test_performence['demo_test_response.rt']\n",
    "    accuracy=test_match_df['arrow_correct'].mean()\n",
    "    mean_rt=test_match_df['demo_test_response.rt'].mean()\n",
    "    correct_and_incorrect_rts=test_match_df.groupby('arrow_correct').aggregate({'demo_test_response.rt':'mean'})\n",
    "    #update the summary info row: \n",
    "    all_subjects_summary_demo_info.loc[cur_subject,'demo_accuracy']=accuracy\n",
    "    all_subjects_summary_demo_info.loc[cur_subject,'RT_overall_mean']=mean_rt\n",
    "    all_subjects_summary_demo_info.loc[cur_subject,['RT_incorrect_mean','RT_correct_mean']]=np.nan\n",
    "\n",
    "    if False in correct_and_incorrect_rts.index:\n",
    "        all_subjects_summary_demo_info.loc[cur_subject,'RT_incorrect_mean']=correct_and_incorrect_rts.loc[False].values[0]\n",
    "    if True in correct_and_incorrect_rts.index:\n",
    "        all_subjects_summary_demo_info.loc[cur_subject,'RT_correct_mean']=correct_and_incorrect_rts.loc[True].values[0]\n",
    "\n",
    "\n",
    "#add a prefix to column names: \n",
    "all_subjects_summary_demo_info.columns=['demo_'+col for col in all_subjects_summary_demo_info.columns]\n",
    "all_subjects_summary_demo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11EXIB1MVBZFJ</th>\n",
       "      <td>1.13860</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1F9KLZGHE9DTA</th>\n",
       "      <td>0.59792</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1LCUPRZ0I8S3I</th>\n",
       "      <td>1.37952</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OOCYEFLAJD98</th>\n",
       "      <td>0.67562</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1U0FDPQ953KXX</th>\n",
       "      <td>1.30840</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2ASRB2MTHDHPD</th>\n",
       "      <td>1.63130</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>0.48240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3JJXDML3XNSQP</th>\n",
       "      <td>1.37120</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3RDT5DH21PVAR</th>\n",
       "      <td>1.14476</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3VHDQR8A9JJ4F</th>\n",
       "      <td>0.62064</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A98E8M4QLI9RS</th>\n",
       "      <td>0.59220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE33JO53WTHZQ</th>\n",
       "      <td>1.10420</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK4WAT44YKU7J</th>\n",
       "      <td>0.52266</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMEBLCWTZKLS2</th>\n",
       "      <td>1.03720</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATA61WNUAP91U</th>\n",
       "      <td>1.27288</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                encoding_arrow_mean_rt  encoding_arrow_accuracy\n",
       "A11EXIB1MVBZFJ                 1.13860                      1.0\n",
       "A1F9KLZGHE9DTA                 0.59792                      1.0\n",
       "A1LCUPRZ0I8S3I                 1.37952                      1.0\n",
       "A1OOCYEFLAJD98                 0.67562                      1.0\n",
       "A1U0FDPQ953KXX                 1.30840                      1.0\n",
       "A2ASRB2MTHDHPD                 1.63130                      1.0\n",
       "A2M183CETUMR96                 0.48240                      1.0\n",
       "A3JJXDML3XNSQP                 1.37120                      1.0\n",
       "A3RDT5DH21PVAR                 1.14476                      0.8\n",
       "A3VHDQR8A9JJ4F                 0.62064                      1.0\n",
       "A98E8M4QLI9RS                  0.59220                      1.0\n",
       "AE33JO53WTHZQ                  1.10420                      0.6\n",
       "AK4WAT44YKU7J                  0.52266                      1.0\n",
       "AMEBLCWTZKLS2                  1.03720                      1.0\n",
       "ATA61WNUAP91U                  1.27288                      1.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this part extract summary information from the experiment encoding phase: attention check accuracy and timings: \n",
    "all_subjects_summary_encoding_info=pd.DataFrame(index=list(all_subjects_encoding_df['subject'].unique()))\n",
    "\n",
    "for cur_subject in all_subjects_encoding_df['subject'].unique():\n",
    "    cur_sub_encoding=all_subjects_encoding_df.loc[all_subjects_encoding_df['subject']==cur_subject]\n",
    "    \n",
    "    #get only attention check related info: \n",
    "    cur_sub_encoding=cur_sub_encoding[['test_encoding_response.keys','correct','test_encoding_response.rt']].copy().dropna(how = 'all')\n",
    "    if len(cur_sub_encoding)==0: #empty - the participant didnt respond on the arrow at all: \n",
    "       all_subjects_summary_encoding_info.loc[cur_subject,'arrow_accuracy']=0 \n",
    "       all_subjects_summary_encoding_info.loc[cur_subject,'arrow_mean_rt']=np.nan\n",
    "    else: \n",
    "        all_subjects_summary_encoding_info.loc[cur_subject,'arrow_mean_rt']=cur_sub_encoding['test_encoding_response.rt'].mean()\n",
    "        arrow_accuracy=(cur_sub_encoding['correct']==cur_sub_encoding['test_encoding_response.keys']).mean()\n",
    "        all_subjects_summary_encoding_info.loc[cur_subject,'arrow_accuracy']=arrow_accuracy\n",
    "\n",
    "\n",
    "\n",
    "#add a prefix to column names: \n",
    "all_subjects_summary_encoding_info.columns=['encoding_'+col for col in all_subjects_summary_encoding_info.columns]        \n",
    "all_subjects_summary_encoding_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>testing_RT_incorrect_mean</th>\n",
       "      <th>testing_RT_correct_mean</th>\n",
       "      <th>testing_layer_1_rt</th>\n",
       "      <th>testing_layer_1_accuracy</th>\n",
       "      <th>testing_layer_2_rt</th>\n",
       "      <th>testing_layer_2_accuracy</th>\n",
       "      <th>testing_layer_3_rt</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11EXIB1MVBZFJ</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>2.094241</td>\n",
       "      <td>3.899862</td>\n",
       "      <td>12.155968</td>\n",
       "      <td>2.203368</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.671950</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.429632</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1F9KLZGHE9DTA</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.418513</td>\n",
       "      <td>1.469431</td>\n",
       "      <td>1.379576</td>\n",
       "      <td>1.499780</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.293545</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.462215</td>\n",
       "      <td>0.45</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1LCUPRZ0I8S3I</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>2.649913</td>\n",
       "      <td>2.984377</td>\n",
       "      <td>2.456276</td>\n",
       "      <td>2.447855</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.726375</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.775510</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OOCYEFLAJD98</th>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.343953</td>\n",
       "      <td>2.364995</td>\n",
       "      <td>4.215473</td>\n",
       "      <td>2.133665</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.373321</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.526340</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1U0FDPQ953KXX</th>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.785461</td>\n",
       "      <td>2.953126</td>\n",
       "      <td>3.233671</td>\n",
       "      <td>2.932160</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.165090</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.231432</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2ASRB2MTHDHPD</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.991117</td>\n",
       "      <td>3.284967</td>\n",
       "      <td>1.759483</td>\n",
       "      <td>2.114545</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.728868</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.116825</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>3.089463</td>\n",
       "      <td>3.843117</td>\n",
       "      <td>3.468331</td>\n",
       "      <td>2.946050</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.996610</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3.323068</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3JJXDML3XNSQP</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>3.407035</td>\n",
       "      <td>3.755030</td>\n",
       "      <td>6.430444</td>\n",
       "      <td>3.214316</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.324833</td>\n",
       "      <td>0.45</td>\n",
       "      <td>3.664100</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3RDT5DH21PVAR</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.398958</td>\n",
       "      <td>1.180700</td>\n",
       "      <td>1.704520</td>\n",
       "      <td>1.312745</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.234080</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.650050</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3VHDQR8A9JJ4F</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.261107</td>\n",
       "      <td>1.207860</td>\n",
       "      <td>1.299140</td>\n",
       "      <td>1.261695</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.359075</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.162550</td>\n",
       "      <td>0.45</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A98E8M4QLI9RS</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.622333</td>\n",
       "      <td>1.542000</td>\n",
       "      <td>1.675889</td>\n",
       "      <td>1.706150</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.675100</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.485750</td>\n",
       "      <td>0.65</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE33JO53WTHZQ</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.571715</td>\n",
       "      <td>2.570700</td>\n",
       "      <td>2.572150</td>\n",
       "      <td>2.428975</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.844180</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.441990</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK4WAT44YKU7J</th>\n",
       "      <td>0.783333</td>\n",
       "      <td>2.428318</td>\n",
       "      <td>2.267331</td>\n",
       "      <td>2.472847</td>\n",
       "      <td>2.452395</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.254125</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.578435</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMEBLCWTZKLS2</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>2.287683</td>\n",
       "      <td>2.439800</td>\n",
       "      <td>2.179029</td>\n",
       "      <td>2.148400</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.409650</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.305000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATA61WNUAP91U</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>2.547673</td>\n",
       "      <td>2.430700</td>\n",
       "      <td>2.610659</td>\n",
       "      <td>2.755065</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.373785</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.514170</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                testing_Test_overall_accuracy  testing_RT_overall_mean  \\\n",
       "A11EXIB1MVBZFJ                       0.516667                 2.094241   \n",
       "A1F9KLZGHE9DTA                       0.566667                 1.418513   \n",
       "A1LCUPRZ0I8S3I                       0.633333                 2.649913   \n",
       "A1OOCYEFLAJD98                       0.683333                 2.343953   \n",
       "A1U0FDPQ953KXX                       0.683333                 2.785461   \n",
       "A2ASRB2MTHDHPD                       0.500000                 1.991117   \n",
       "A2M183CETUMR96                       0.900000                 3.089463   \n",
       "A3JJXDML3XNSQP                       0.450000                 3.407035   \n",
       "A3RDT5DH21PVAR                       0.416667                 1.398958   \n",
       "A3VHDQR8A9JJ4F                       0.583333                 1.261107   \n",
       "A98E8M4QLI9RS                        0.600000                 1.622333   \n",
       "AE33JO53WTHZQ                        0.700000                 2.571715   \n",
       "AK4WAT44YKU7J                        0.783333                 2.428318   \n",
       "AMEBLCWTZKLS2                        0.583333                 2.287683   \n",
       "ATA61WNUAP91U                        0.650000                 2.547673   \n",
       "\n",
       "                testing_RT_incorrect_mean  testing_RT_correct_mean  \\\n",
       "A11EXIB1MVBZFJ                   3.899862                12.155968   \n",
       "A1F9KLZGHE9DTA                   1.469431                 1.379576   \n",
       "A1LCUPRZ0I8S3I                   2.984377                 2.456276   \n",
       "A1OOCYEFLAJD98                   2.364995                 4.215473   \n",
       "A1U0FDPQ953KXX                   2.953126                 3.233671   \n",
       "A2ASRB2MTHDHPD                   3.284967                 1.759483   \n",
       "A2M183CETUMR96                   3.843117                 3.468331   \n",
       "A3JJXDML3XNSQP                   3.755030                 6.430444   \n",
       "A3RDT5DH21PVAR                   1.180700                 1.704520   \n",
       "A3VHDQR8A9JJ4F                   1.207860                 1.299140   \n",
       "A98E8M4QLI9RS                    1.542000                 1.675889   \n",
       "AE33JO53WTHZQ                    2.570700                 2.572150   \n",
       "AK4WAT44YKU7J                    2.267331                 2.472847   \n",
       "AMEBLCWTZKLS2                    2.439800                 2.179029   \n",
       "ATA61WNUAP91U                    2.430700                 2.610659   \n",
       "\n",
       "                testing_layer_1_rt  testing_layer_1_accuracy  \\\n",
       "A11EXIB1MVBZFJ            2.203368                      0.60   \n",
       "A1F9KLZGHE9DTA            1.499780                      0.65   \n",
       "A1LCUPRZ0I8S3I            2.447855                      0.75   \n",
       "A1OOCYEFLAJD98            2.133665                      0.75   \n",
       "A1U0FDPQ953KXX            2.932160                      0.75   \n",
       "A2ASRB2MTHDHPD            2.114545                      0.70   \n",
       "A2M183CETUMR96            2.946050                      0.90   \n",
       "A3JJXDML3XNSQP            3.214316                      0.30   \n",
       "A3RDT5DH21PVAR            1.312745                      0.50   \n",
       "A3VHDQR8A9JJ4F            1.261695                      0.60   \n",
       "A98E8M4QLI9RS             1.706150                      0.60   \n",
       "AE33JO53WTHZQ             2.428975                      0.75   \n",
       "AK4WAT44YKU7J             2.452395                      0.70   \n",
       "AMEBLCWTZKLS2             2.148400                      0.75   \n",
       "ATA61WNUAP91U             2.755065                      0.80   \n",
       "\n",
       "                testing_layer_2_rt  testing_layer_2_accuracy  \\\n",
       "A11EXIB1MVBZFJ            1.671950                      0.50   \n",
       "A1F9KLZGHE9DTA            1.293545                      0.60   \n",
       "A1LCUPRZ0I8S3I            2.726375                      0.50   \n",
       "A1OOCYEFLAJD98            2.373321                      0.70   \n",
       "A1U0FDPQ953KXX            3.165090                      0.60   \n",
       "A2ASRB2MTHDHPD            1.728868                      0.25   \n",
       "A2M183CETUMR96            2.996610                      0.90   \n",
       "A3JJXDML3XNSQP            3.324833                      0.45   \n",
       "A3RDT5DH21PVAR            1.234080                      0.35   \n",
       "A3VHDQR8A9JJ4F            1.359075                      0.70   \n",
       "A98E8M4QLI9RS             1.675100                      0.55   \n",
       "AE33JO53WTHZQ             2.844180                      0.75   \n",
       "AK4WAT44YKU7J             2.254125                      0.85   \n",
       "AMEBLCWTZKLS2             2.409650                      0.55   \n",
       "ATA61WNUAP91U             2.373785                      0.65   \n",
       "\n",
       "                testing_layer_3_rt  testing_layer_3_accuracy  \\\n",
       "A11EXIB1MVBZFJ            2.429632                      0.45   \n",
       "A1F9KLZGHE9DTA            1.462215                      0.45   \n",
       "A1LCUPRZ0I8S3I            2.775510                      0.65   \n",
       "A1OOCYEFLAJD98            2.526340                      0.60   \n",
       "A1U0FDPQ953KXX            2.231432                      0.70   \n",
       "A2ASRB2MTHDHPD            2.116825                      0.55   \n",
       "A2M183CETUMR96            3.323068                      0.90   \n",
       "A3JJXDML3XNSQP            3.664100                      0.60   \n",
       "A3RDT5DH21PVAR            1.650050                      0.40   \n",
       "A3VHDQR8A9JJ4F            1.162550                      0.45   \n",
       "A98E8M4QLI9RS             1.485750                      0.65   \n",
       "AE33JO53WTHZQ             2.441990                      0.60   \n",
       "AK4WAT44YKU7J             2.578435                      0.80   \n",
       "AMEBLCWTZKLS2             2.305000                      0.45   \n",
       "ATA61WNUAP91U             2.514170                      0.50   \n",
       "\n",
       "                testing_longest_response_strike  \n",
       "A11EXIB1MVBZFJ                              4.0  \n",
       "A1F9KLZGHE9DTA                              6.0  \n",
       "A1LCUPRZ0I8S3I                              4.0  \n",
       "A1OOCYEFLAJD98                              4.0  \n",
       "A1U0FDPQ953KXX                              3.0  \n",
       "A2ASRB2MTHDHPD                              9.0  \n",
       "A2M183CETUMR96                              5.0  \n",
       "A3JJXDML3XNSQP                              3.0  \n",
       "A3RDT5DH21PVAR                              4.0  \n",
       "A3VHDQR8A9JJ4F                              7.0  \n",
       "A98E8M4QLI9RS                               6.0  \n",
       "AE33JO53WTHZQ                               4.0  \n",
       "AK4WAT44YKU7J                               7.0  \n",
       "AMEBLCWTZKLS2                               3.0  \n",
       "ATA61WNUAP91U                               5.0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this part extract summary information from the experiment testing phase: attention check accuracy and timings: \n",
    "all_subjects_summary_testing_info=pd.DataFrame(index=list(all_subjects_test_df['subject'].unique()))\n",
    "\n",
    "\n",
    "#this code calculates response time averages (RT) exlcusing the trials that are TOO long: \n",
    "trial_too_long_exclusion_criteria=10\n",
    "\n",
    "\n",
    "for cur_subject in all_subjects_test_df['subject'].unique():\n",
    "    cur_sub_testing=all_subjects_test_df.loc[all_subjects_test_df['subject']==cur_subject]\n",
    "\n",
    "    #get the correctness of the testing phase: \n",
    "    cur_sub_testing_performence=cur_sub_testing[['correct','test_test_response.keys','test_test_response.rt','layer','test_test_response.corr']].copy().dropna()\n",
    "\n",
    "\n",
    "    test_match_df=pd.DataFrame(columns=['correct'],data=cur_sub_testing_performence['correct']==cur_sub_testing_performence['test_test_response.keys'])\n",
    "    test_match_df['test_test_response.rt']=cur_sub_testing_performence['test_test_response.rt']\n",
    "    accuracy=test_match_df['correct'].mean()\n",
    "\n",
    "    # if there is one rt that is very long, lets not include it in the mean calculation \n",
    "    \n",
    "    mean_rt=(test_match_df.loc[test_match_df['test_test_response.rt']<=trial_too_long_exclusion_criteria,'test_test_response.rt']).mean()\n",
    "    correct_and_incorrect_rts_overall=test_match_df.groupby('correct').aggregate({'test_test_response.rt':'mean'})\n",
    "    \n",
    "    #update the summary info row: \n",
    "    all_subjects_summary_testing_info.loc[cur_subject,'Test_overall_accuracy']=accuracy\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,'RT_overall_mean']=mean_rt\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,['RT_incorrect_mean','RT_correct_mean']]=np.nan\n",
    "\n",
    "    if False in correct_and_incorrect_rts_overall.index:\n",
    "        all_subjects_summary_testing_info.loc[cur_subject,'RT_incorrect_mean']=correct_and_incorrect_rts_overall.loc[False].values[0]\n",
    "    if True in correct_and_incorrect_rts_overall.index:\n",
    "        all_subjects_summary_testing_info.loc[cur_subject,'RT_correct_mean']=correct_and_incorrect_rts_overall.loc[True].values[0]\n",
    "\n",
    "\n",
    "\n",
    "    #extract layer wise information (accuracy and rt):\n",
    "    cur_sub_testing_performence_copy=cur_sub_testing_performence.copy()\n",
    "    cur_sub_testing_performence_copy.loc[cur_sub_testing_performence_copy['test_test_response.rt']>trial_too_long_exclusion_criteria,'test_test_response.rt']=nan\n",
    "    correct_and_incorrect_rts=cur_sub_testing_performence_copy.groupby('layer').aggregate({'test_test_response.rt':'mean','test_test_response.corr':'mean'})\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,['layer_1_rt','layer_1_accuracy','layer_2_rt','layer_2_accuracy','layer_3_rt','layer_3_accuracy']]=correct_and_incorrect_rts.values.flatten()\n",
    "\n",
    "\n",
    "    #check the longest structured strike (to find bots or very unattentive participants):\n",
    "    responses=cur_sub_testing_performence['test_test_response.keys'].replace({'left':1,'right':2}).values\n",
    "    max_iter=find_largest_consequtive_repetition(responses)\n",
    "\n",
    "    all_subjects_summary_testing_info.loc[cur_subject,'longest_response_strike']=max_iter\n",
    "\n",
    "#add a prefix to column names: \n",
    "all_subjects_summary_testing_info.columns=['testing_'+col for col in all_subjects_summary_testing_info.columns]        \n",
    "all_subjects_summary_testing_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>test_test_response.keys</th>\n",
       "      <th>test_test_response.rt</th>\n",
       "      <th>layer</th>\n",
       "      <th>test_test_response.corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2.8954</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.8464</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.8510</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.6270</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.9200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.4969</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.4957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2.8855</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>3.1462</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.3710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2.0046</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.8653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>3.5147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.3726</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.7509</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2.1360</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>3.2505</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.9870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2.8643</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.6243</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.2411</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2.6363</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2.3570</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.9731</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2.2587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>5.1742</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2.1055</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2.9254</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>2.4407</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>9.2838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.7248</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2.0479</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>3.8502</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2.0291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>8.5149</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.7867</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2.7540</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2.2552</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.6194</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.2638</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2.5345</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.5056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>6.6864</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.9968</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>5.0033</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.6450</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>1.4939</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>right</td>\n",
       "      <td>left</td>\n",
       "      <td>2.1803</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>4.8913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.7712</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2.0227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.6791</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>1.7477</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.8178</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.9012</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>1.6761</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2.1733</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>1.7636</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>3.1826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "      <td>2.0409</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    correct test_test_response.keys  test_test_response.rt  layer  \\\n",
       "840    left                   right                 2.8954    1.0   \n",
       "841    left                    left                 1.8464    3.0   \n",
       "842   right                   right                 1.8510    3.0   \n",
       "843   right                   right                 1.6270    3.0   \n",
       "844    left                    left                 1.9200    2.0   \n",
       "845    left                    left                 1.4969    2.0   \n",
       "846    left                    left                 1.4957    1.0   \n",
       "847   right                    left                 2.8855    3.0   \n",
       "848   right                    left                 3.1462    3.0   \n",
       "849    left                    left                 1.3710    1.0   \n",
       "850    left                   right                 2.0046    3.0   \n",
       "851    left                    left                 1.8653    1.0   \n",
       "852    left                   right                 3.5147    1.0   \n",
       "853    left                    left                 1.3726    1.0   \n",
       "854    left                    left                 1.7509    3.0   \n",
       "855   right                    left                 2.1360    2.0   \n",
       "856    left                    left                 3.2505    1.0   \n",
       "857   right                   right                 1.9870    1.0   \n",
       "858    left                   right                 2.8643    2.0   \n",
       "859    left                   right                 1.6243    2.0   \n",
       "860    left                    left                 1.2411    2.0   \n",
       "861   right                    left                 2.6363    3.0   \n",
       "862    left                    left                 2.3570    2.0   \n",
       "863    left                   right                 1.9731    3.0   \n",
       "864   right                    left                 2.2587    1.0   \n",
       "865   right                   right                 5.1742    1.0   \n",
       "866    left                   right                 2.1055    3.0   \n",
       "867    left                    left                 2.9254    2.0   \n",
       "868    left                   right                 2.4407    2.0   \n",
       "869    left                    left                 9.2838    1.0   \n",
       "870    left                    left                 1.7248    2.0   \n",
       "871    left                    left                 2.0479    1.0   \n",
       "872    left                    left                 3.8502    2.0   \n",
       "873    left                    left                 2.0291    1.0   \n",
       "874    left                    left                 8.5149    2.0   \n",
       "875   right                   right                 1.7867    3.0   \n",
       "876   right                    left                 2.7540    3.0   \n",
       "877   right                    left                 2.2552    2.0   \n",
       "878   right                    left                 1.6194    3.0   \n",
       "879    left                    left                 1.2638    1.0   \n",
       "880    left                    left                 2.5345    3.0   \n",
       "881    left                   right                 1.5056    2.0   \n",
       "882   right                   right                 6.6864    3.0   \n",
       "883    left                    left                 1.9968    2.0   \n",
       "884   right                    left                 5.0033    3.0   \n",
       "885   right                   right                 1.6450    2.0   \n",
       "886   right                    left                 1.4939    2.0   \n",
       "887   right                    left                 2.1803    3.0   \n",
       "888   right                   right                 4.8913    1.0   \n",
       "889    left                    left                 1.7712    1.0   \n",
       "890    left                    left                 2.0227    1.0   \n",
       "891   right                   right                 1.6791    2.0   \n",
       "892    left                   right                 1.7477    1.0   \n",
       "893   right                   right                 1.8178    3.0   \n",
       "894   right                   right                 1.9012    3.0   \n",
       "895    left                    left                 1.6761    1.0   \n",
       "896    left                    left                 2.1733    3.0   \n",
       "897   right                   right                 1.7636    2.0   \n",
       "898    left                    left                 3.1826    1.0   \n",
       "899    left                    left                 2.0409    2.0   \n",
       "\n",
       "     test_test_response.corr  \n",
       "840                      0.0  \n",
       "841                      1.0  \n",
       "842                      1.0  \n",
       "843                      1.0  \n",
       "844                      1.0  \n",
       "845                      1.0  \n",
       "846                      1.0  \n",
       "847                      0.0  \n",
       "848                      0.0  \n",
       "849                      1.0  \n",
       "850                      0.0  \n",
       "851                      1.0  \n",
       "852                      0.0  \n",
       "853                      1.0  \n",
       "854                      1.0  \n",
       "855                      0.0  \n",
       "856                      1.0  \n",
       "857                      1.0  \n",
       "858                      0.0  \n",
       "859                      0.0  \n",
       "860                      1.0  \n",
       "861                      0.0  \n",
       "862                      1.0  \n",
       "863                      0.0  \n",
       "864                      0.0  \n",
       "865                      1.0  \n",
       "866                      0.0  \n",
       "867                      1.0  \n",
       "868                      0.0  \n",
       "869                      1.0  \n",
       "870                      1.0  \n",
       "871                      1.0  \n",
       "872                      1.0  \n",
       "873                      1.0  \n",
       "874                      1.0  \n",
       "875                      1.0  \n",
       "876                      0.0  \n",
       "877                      0.0  \n",
       "878                      0.0  \n",
       "879                      1.0  \n",
       "880                      1.0  \n",
       "881                      0.0  \n",
       "882                      1.0  \n",
       "883                      1.0  \n",
       "884                      0.0  \n",
       "885                      1.0  \n",
       "886                      0.0  \n",
       "887                      0.0  \n",
       "888                      1.0  \n",
       "889                      1.0  \n",
       "890                      1.0  \n",
       "891                      1.0  \n",
       "892                      0.0  \n",
       "893                      1.0  \n",
       "894                      1.0  \n",
       "895                      1.0  \n",
       "896                      1.0  \n",
       "897                      1.0  \n",
       "898                      1.0  \n",
       "899                      1.0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_sub_testing_performence.loc[cur_sub_testing_performence['test_test_response.rt']>trial_too_long_exclusion_criteria,'test_test_response.rt']=nan\n",
    "cur_sub_testing_performence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outlier_responses(sub_test_dataframe,fast_threshold=0.1,fast_allowed_count=2,slow_threshold=10,slow_allowed_count=2):\n",
    "    isfast_outlier=(sub_test_dataframe['test_test_response.rt']<fast_threshold).sum()>fast_allowed_count\n",
    "    isslow_outlier=(sub_test_dataframe['test_test_response.rt']>slow_threshold).sum()>slow_allowed_count\n",
    "    return isfast_outlier,isslow_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary for criterions:\n",
      "demo accuracy higher than 0.5 - qualified: 14\n",
      "demo attention check correctness equals 1 - qualified: 15\n",
      "experiment encoding attention check accuracy 0.6 - qualified: 14\n",
      "experiment longest consequtive strike of maximum of  15 responses - qualified: 15\n",
      "test too fast (thresold: 0.3, allowed count: 3 qualified: 15\n",
      "test too slow (thresold: 10, allowed count: 2 qualified: 13\n",
      "above chance accuracy in test, qualified: 8\n",
      "OVERALL: number of qualified participants (adhere to all criterions): 6\n"
     ]
    }
   ],
   "source": [
    "#combine all oneliners into a single matrix - 1 line per participant with all information we want:\n",
    "data_df_for_analysis=pd.concat([all_subjects_summary_demo_info,all_subjects_summary_encoding_info,all_subjects_summary_testing_info],axis=1)\n",
    "data_df_for_analysis\n",
    "\n",
    "\n",
    "\n",
    "#as each participant saw 20 distractors per layer, we need atleast 0.75 (15/20) accuracy in one of the layers or above 0.616 (37/60) in the overall: \n",
    "\n",
    "#how many participants would fail the demo (did not correctly answered the arrow or had less than 60% performence)\n",
    "demo_criterions_accuracy=data_df_for_analysis['demo_demo_accuracy']>=criterions_df['demo_accuracy_treshold']\n",
    "demo_criterions_attention_check=data_df_for_analysis['demo_arrow_correct']>=criterions_df['demo_arrow_correctness']\n",
    "#find which participants performed pooly on the attention checks of the experiment encoding phase: \n",
    "encoding_ciriterions=data_df_for_analysis['encoding_arrow_accuracy']>criterions_df['encoding_arrow_accuracy']\n",
    "#remove participants that are too slow: \n",
    "test_criterions_strike=data_df_for_analysis['testing_longest_response_strike']<criterions_df['longest_allowed_consequtive_strike']\n",
    "\n",
    "too_fast_criterions=[]\n",
    "too_slow_criterions=[]\n",
    "for subject in data_df_for_analysis.index:\n",
    "    sub_test_dataframe=all_subjects_test_df[all_subjects_test_df['subject']==subject]\n",
    "    toofast_criterion,tooslow_criterion=find_outlier_responses(sub_test_dataframe,fast_threshold=criterions_df['fast_threshold'],fast_allowed_count=criterions_df['fast_allowed_count'],slow_threshold=criterions_df['slow_threshold'],slow_allowed_count=criterions_df['slow_allowed_count'])\n",
    "    too_slow_criterions.append(not tooslow_criterion)\n",
    "    too_fast_criterions.append(not toofast_criterion)\n",
    "\n",
    "\n",
    "\n",
    "print(f'summary for criterions:')\n",
    "print(f'demo accuracy higher than {criterions_df.demo_accuracy_treshold} - qualified: {demo_criterions_accuracy.sum()}')\n",
    "print(f'demo attention check correctness equals {criterions_df.demo_arrow_correctness} - qualified: {demo_criterions_attention_check.sum()}')\n",
    "print(f'experiment encoding attention check accuracy {criterions_df.encoding_arrow_accuracy} - qualified: {encoding_ciriterions.sum()}')\n",
    "print(f'experiment longest consequtive strike of maximum of  {criterions_df.longest_allowed_consequtive_strike} responses - qualified: {test_criterions_strike.sum()}')\n",
    "print(f'test too fast (thresold: {criterions_df.fast_threshold}, allowed count: {criterions_df.fast_allowed_count} qualified: {sum(too_fast_criterions)}')\n",
    "print(f'test too slow (thresold: {criterions_df.slow_threshold}, allowed count: {criterions_df.slow_allowed_count} qualified: {sum(too_slow_criterions)}')\n",
    "#accuracy criterion on the test: \n",
    "test_accuracy_critertions=(data_df_for_analysis['testing_Test_overall_accuracy']>=criterions_df['binom_averages']) | (data_df_for_analysis[['testing_layer_1_accuracy' ,'testing_layer_2_accuracy' ,'testing_layer_3_accuracy']]>=criterions_df['binom_single_layer']).T.any()\n",
    "#remove participants that were discarded based on behavior up to the test and now qualify or disqualify based on test accuracy (do they have atleast 1 significant (binomial test) accuracy in one layer, or above threshold in overall accuracy )\n",
    "only_qualified=demo_criterions_accuracy & demo_criterions_attention_check & encoding_ciriterions & test_criterions_strike & too_fast_criterions & too_slow_criterions & test_accuracy_critertions\n",
    "print(f'above chance accuracy in test, qualified: {sum(test_accuracy_critertions)}')\n",
    "print(f'OVERALL: number of qualified participants (adhere to all criterions): {sum(only_qualified)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>testing_RT_incorrect_mean</th>\n",
       "      <th>testing_RT_correct_mean</th>\n",
       "      <th>testing_layer_1_rt</th>\n",
       "      <th>testing_layer_1_accuracy</th>\n",
       "      <th>testing_layer_2_rt</th>\n",
       "      <th>testing_layer_2_accuracy</th>\n",
       "      <th>testing_layer_3_rt</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11EXIB1MVBZFJ</th>\n",
       "      <td>1.1560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.790667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.790667</td>\n",
       "      <td>1.13860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>2.094241</td>\n",
       "      <td>3.899862</td>\n",
       "      <td>12.155968</td>\n",
       "      <td>2.203368</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.671950</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.429632</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1F9KLZGHE9DTA</th>\n",
       "      <td>0.5979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.385950</td>\n",
       "      <td>1.7404</td>\n",
       "      <td>1.315060</td>\n",
       "      <td>0.59792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.418513</td>\n",
       "      <td>1.469431</td>\n",
       "      <td>1.379576</td>\n",
       "      <td>1.499780</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.293545</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.462215</td>\n",
       "      <td>0.45</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1LCUPRZ0I8S3I</th>\n",
       "      <td>0.9871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>1.37952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>2.649913</td>\n",
       "      <td>2.984377</td>\n",
       "      <td>2.456276</td>\n",
       "      <td>2.447855</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.726375</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.775510</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OOCYEFLAJD98</th>\n",
       "      <td>0.5116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>0.67562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.343953</td>\n",
       "      <td>2.364995</td>\n",
       "      <td>4.215473</td>\n",
       "      <td>2.133665</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.373321</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.526340</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1U0FDPQ953KXX</th>\n",
       "      <td>1.1286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.252667</td>\n",
       "      <td>3.3118</td>\n",
       "      <td>5.640840</td>\n",
       "      <td>1.30840</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.785461</td>\n",
       "      <td>2.953126</td>\n",
       "      <td>3.233671</td>\n",
       "      <td>2.932160</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.165090</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.231432</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A11EXIB1MVBZFJ         1.1560                 1.0            1.000000   \n",
       "A1F9KLZGHE9DTA         0.5979                 1.0            0.833333   \n",
       "A1LCUPRZ0I8S3I         0.9871                 1.0            1.000000   \n",
       "A1OOCYEFLAJD98         0.5116                 1.0            1.000000   \n",
       "A1U0FDPQ953KXX         1.1286                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A11EXIB1MVBZFJ             15.790667                     NaN   \n",
       "A1F9KLZGHE9DTA              1.385950                  1.7404   \n",
       "A1LCUPRZ0I8S3I              2.185933                     NaN   \n",
       "A1OOCYEFLAJD98              2.427583                     NaN   \n",
       "A1U0FDPQ953KXX              5.252667                  3.3118   \n",
       "\n",
       "                demo_RT_correct_mean  encoding_arrow_mean_rt  \\\n",
       "A11EXIB1MVBZFJ             15.790667                 1.13860   \n",
       "A1F9KLZGHE9DTA              1.315060                 0.59792   \n",
       "A1LCUPRZ0I8S3I              2.185933                 1.37952   \n",
       "A1OOCYEFLAJD98              2.427583                 0.67562   \n",
       "A1U0FDPQ953KXX              5.640840                 1.30840   \n",
       "\n",
       "                encoding_arrow_accuracy  testing_Test_overall_accuracy  \\\n",
       "A11EXIB1MVBZFJ                      1.0                       0.516667   \n",
       "A1F9KLZGHE9DTA                      1.0                       0.566667   \n",
       "A1LCUPRZ0I8S3I                      1.0                       0.633333   \n",
       "A1OOCYEFLAJD98                      1.0                       0.683333   \n",
       "A1U0FDPQ953KXX                      1.0                       0.683333   \n",
       "\n",
       "                testing_RT_overall_mean  testing_RT_incorrect_mean  \\\n",
       "A11EXIB1MVBZFJ                 2.094241                   3.899862   \n",
       "A1F9KLZGHE9DTA                 1.418513                   1.469431   \n",
       "A1LCUPRZ0I8S3I                 2.649913                   2.984377   \n",
       "A1OOCYEFLAJD98                 2.343953                   2.364995   \n",
       "A1U0FDPQ953KXX                 2.785461                   2.953126   \n",
       "\n",
       "                testing_RT_correct_mean  testing_layer_1_rt  \\\n",
       "A11EXIB1MVBZFJ                12.155968            2.203368   \n",
       "A1F9KLZGHE9DTA                 1.379576            1.499780   \n",
       "A1LCUPRZ0I8S3I                 2.456276            2.447855   \n",
       "A1OOCYEFLAJD98                 4.215473            2.133665   \n",
       "A1U0FDPQ953KXX                 3.233671            2.932160   \n",
       "\n",
       "                testing_layer_1_accuracy  testing_layer_2_rt  \\\n",
       "A11EXIB1MVBZFJ                      0.60            1.671950   \n",
       "A1F9KLZGHE9DTA                      0.65            1.293545   \n",
       "A1LCUPRZ0I8S3I                      0.75            2.726375   \n",
       "A1OOCYEFLAJD98                      0.75            2.373321   \n",
       "A1U0FDPQ953KXX                      0.75            3.165090   \n",
       "\n",
       "                testing_layer_2_accuracy  testing_layer_3_rt  \\\n",
       "A11EXIB1MVBZFJ                       0.5            2.429632   \n",
       "A1F9KLZGHE9DTA                       0.6            1.462215   \n",
       "A1LCUPRZ0I8S3I                       0.5            2.775510   \n",
       "A1OOCYEFLAJD98                       0.7            2.526340   \n",
       "A1U0FDPQ953KXX                       0.6            2.231432   \n",
       "\n",
       "                testing_layer_3_accuracy  testing_longest_response_strike  \n",
       "A11EXIB1MVBZFJ                      0.45                              4.0  \n",
       "A1F9KLZGHE9DTA                      0.45                              6.0  \n",
       "A1LCUPRZ0I8S3I                      0.65                              4.0  \n",
       "A1OOCYEFLAJD98                      0.60                              4.0  \n",
       "A1U0FDPQ953KXX                      0.70                              3.0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_for_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "      <th>not_too_slow</th>\n",
       "      <th>not_too_Fast</th>\n",
       "      <th>sufficient_test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11EXIB1MVBZFJ</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1F9KLZGHE9DTA</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1LCUPRZ0I8S3I</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OOCYEFLAJD98</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1U0FDPQ953KXX</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2ASRB2MTHDHPD</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M183CETUMR96</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3JJXDML3XNSQP</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3RDT5DH21PVAR</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3VHDQR8A9JJ4F</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A98E8M4QLI9RS</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE33JO53WTHZQ</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK4WAT44YKU7J</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMEBLCWTZKLS2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATA61WNUAP91U</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_demo_accuracy  demo_arrow_correct  \\\n",
       "A11EXIB1MVBZFJ                True                True   \n",
       "A1F9KLZGHE9DTA                True                True   \n",
       "A1LCUPRZ0I8S3I                True                True   \n",
       "A1OOCYEFLAJD98                True                True   \n",
       "A1U0FDPQ953KXX                True                True   \n",
       "A2ASRB2MTHDHPD                True                True   \n",
       "A2M183CETUMR96               False                True   \n",
       "A3JJXDML3XNSQP                True                True   \n",
       "A3RDT5DH21PVAR                True                True   \n",
       "A3VHDQR8A9JJ4F                True                True   \n",
       "A98E8M4QLI9RS                 True                True   \n",
       "AE33JO53WTHZQ                 True                True   \n",
       "AK4WAT44YKU7J                 True                True   \n",
       "AMEBLCWTZKLS2                 True                True   \n",
       "ATA61WNUAP91U                 True                True   \n",
       "\n",
       "                encoding_arrow_accuracy  testing_longest_response_strike  \\\n",
       "A11EXIB1MVBZFJ                     True                             True   \n",
       "A1F9KLZGHE9DTA                     True                             True   \n",
       "A1LCUPRZ0I8S3I                     True                             True   \n",
       "A1OOCYEFLAJD98                     True                             True   \n",
       "A1U0FDPQ953KXX                     True                             True   \n",
       "A2ASRB2MTHDHPD                     True                             True   \n",
       "A2M183CETUMR96                     True                             True   \n",
       "A3JJXDML3XNSQP                     True                             True   \n",
       "A3RDT5DH21PVAR                     True                             True   \n",
       "A3VHDQR8A9JJ4F                     True                             True   \n",
       "A98E8M4QLI9RS                      True                             True   \n",
       "AE33JO53WTHZQ                     False                             True   \n",
       "AK4WAT44YKU7J                      True                             True   \n",
       "AMEBLCWTZKLS2                      True                             True   \n",
       "ATA61WNUAP91U                      True                             True   \n",
       "\n",
       "                not_too_slow  not_too_Fast  sufficient_test_acc  \n",
       "A11EXIB1MVBZFJ          True          True                False  \n",
       "A1F9KLZGHE9DTA          True          True                False  \n",
       "A1LCUPRZ0I8S3I          True          True                 True  \n",
       "A1OOCYEFLAJD98          True          True                 True  \n",
       "A1U0FDPQ953KXX          True          True                 True  \n",
       "A2ASRB2MTHDHPD          True          True                False  \n",
       "A2M183CETUMR96         False          True                 True  \n",
       "A3JJXDML3XNSQP         False          True                False  \n",
       "A3RDT5DH21PVAR          True          True                False  \n",
       "A3VHDQR8A9JJ4F          True          True                False  \n",
       "A98E8M4QLI9RS           True          True                False  \n",
       "AE33JO53WTHZQ           True          True                 True  \n",
       "AK4WAT44YKU7J           True          True                 True  \n",
       "AMEBLCWTZKLS2           True          True                 True  \n",
       "ATA61WNUAP91U           True          True                 True  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#update the batch_workers_df  with columns representing disqualification reasons: \n",
    "tooslow_df=pd.DataFrame(data=too_slow_criterions,index=data_df_for_analysis.index,columns=['not_too_slow'])\n",
    "toofast_df=pd.DataFrame(data=too_fast_criterions,index=data_df_for_analysis.index,columns=['not_too_Fast'])\n",
    "test_accuracy_critertions=pd.DataFrame(data=test_accuracy_critertions,index=data_df_for_analysis.index, columns=['sufficient_test_acc'])\n",
    "disqualification_df=pd.concat([demo_criterions_accuracy,demo_criterions_attention_check,encoding_ciriterions,test_criterions_strike,tooslow_df,toofast_df,test_accuracy_critertions],axis=1)\n",
    "disqualification_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge workers_df with disqualification and save: \n",
    "index_list=[ind.split('_')[0] for ind in disqualification_df.index]\n",
    "disqualification_df['WorkerId']=index_list\n",
    "\n",
    "batch_workers_df_extended = workers_df.merge(disqualification_df, left_on='Worker ID', right_on='WorkerId', how = 'inner')\n",
    "batch_workers_df_extended = workers_df.merge(disqualification_df, left_on='Worker ID', right_on='WorkerId', how = 'outer')\n",
    "\n",
    "#add qualification column: (currently any participant will get this qualification (even if he just openneded the experiment and quit, because we dont want him back)\n",
    "batch_workers_df_extended[qualification_name_for_entire_experiment]=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>testing_RT_incorrect_mean</th>\n",
       "      <th>testing_RT_correct_mean</th>\n",
       "      <th>testing_layer_1_rt</th>\n",
       "      <th>testing_layer_1_accuracy</th>\n",
       "      <th>testing_layer_2_rt</th>\n",
       "      <th>testing_layer_2_accuracy</th>\n",
       "      <th>testing_layer_3_rt</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1LCUPRZ0I8S3I</th>\n",
       "      <td>0.9871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>1.37952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>2.649913</td>\n",
       "      <td>2.984377</td>\n",
       "      <td>2.456276</td>\n",
       "      <td>2.447855</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.726375</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.775510</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OOCYEFLAJD98</th>\n",
       "      <td>0.5116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>0.67562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.343953</td>\n",
       "      <td>2.364995</td>\n",
       "      <td>4.215473</td>\n",
       "      <td>2.133665</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.373321</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.526340</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1U0FDPQ953KXX</th>\n",
       "      <td>1.1286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.252667</td>\n",
       "      <td>3.3118</td>\n",
       "      <td>5.640840</td>\n",
       "      <td>1.30840</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.785461</td>\n",
       "      <td>2.953126</td>\n",
       "      <td>3.233671</td>\n",
       "      <td>2.932160</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.165090</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.231432</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK4WAT44YKU7J</th>\n",
       "      <td>0.6394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.239683</td>\n",
       "      <td>2.5745</td>\n",
       "      <td>2.072275</td>\n",
       "      <td>0.52266</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>2.428318</td>\n",
       "      <td>2.267331</td>\n",
       "      <td>2.472847</td>\n",
       "      <td>2.452395</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.254125</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.578435</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMEBLCWTZKLS2</th>\n",
       "      <td>0.9730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.663333</td>\n",
       "      <td>1.3950</td>\n",
       "      <td>1.717000</td>\n",
       "      <td>1.03720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>2.287683</td>\n",
       "      <td>2.439800</td>\n",
       "      <td>2.179029</td>\n",
       "      <td>2.148400</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.409650</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.305000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATA61WNUAP91U</th>\n",
       "      <td>1.3853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.389683</td>\n",
       "      <td>2.1828</td>\n",
       "      <td>2.431060</td>\n",
       "      <td>1.27288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>2.547673</td>\n",
       "      <td>2.430700</td>\n",
       "      <td>2.610659</td>\n",
       "      <td>2.755065</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.373785</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.514170</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A1LCUPRZ0I8S3I         0.9871                 1.0            1.000000   \n",
       "A1OOCYEFLAJD98         0.5116                 1.0            1.000000   \n",
       "A1U0FDPQ953KXX         1.1286                 1.0            0.833333   \n",
       "AK4WAT44YKU7J          0.6394                 1.0            0.666667   \n",
       "AMEBLCWTZKLS2          0.9730                 1.0            0.833333   \n",
       "ATA61WNUAP91U          1.3853                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A1LCUPRZ0I8S3I              2.185933                     NaN   \n",
       "A1OOCYEFLAJD98              2.427583                     NaN   \n",
       "A1U0FDPQ953KXX              5.252667                  3.3118   \n",
       "AK4WAT44YKU7J               2.239683                  2.5745   \n",
       "AMEBLCWTZKLS2               1.663333                  1.3950   \n",
       "ATA61WNUAP91U               2.389683                  2.1828   \n",
       "\n",
       "                demo_RT_correct_mean  encoding_arrow_mean_rt  \\\n",
       "A1LCUPRZ0I8S3I              2.185933                 1.37952   \n",
       "A1OOCYEFLAJD98              2.427583                 0.67562   \n",
       "A1U0FDPQ953KXX              5.640840                 1.30840   \n",
       "AK4WAT44YKU7J               2.072275                 0.52266   \n",
       "AMEBLCWTZKLS2               1.717000                 1.03720   \n",
       "ATA61WNUAP91U               2.431060                 1.27288   \n",
       "\n",
       "                encoding_arrow_accuracy  testing_Test_overall_accuracy  \\\n",
       "A1LCUPRZ0I8S3I                      1.0                       0.633333   \n",
       "A1OOCYEFLAJD98                      1.0                       0.683333   \n",
       "A1U0FDPQ953KXX                      1.0                       0.683333   \n",
       "AK4WAT44YKU7J                       1.0                       0.783333   \n",
       "AMEBLCWTZKLS2                       1.0                       0.583333   \n",
       "ATA61WNUAP91U                       1.0                       0.650000   \n",
       "\n",
       "                testing_RT_overall_mean  testing_RT_incorrect_mean  \\\n",
       "A1LCUPRZ0I8S3I                 2.649913                   2.984377   \n",
       "A1OOCYEFLAJD98                 2.343953                   2.364995   \n",
       "A1U0FDPQ953KXX                 2.785461                   2.953126   \n",
       "AK4WAT44YKU7J                  2.428318                   2.267331   \n",
       "AMEBLCWTZKLS2                  2.287683                   2.439800   \n",
       "ATA61WNUAP91U                  2.547673                   2.430700   \n",
       "\n",
       "                testing_RT_correct_mean  testing_layer_1_rt  \\\n",
       "A1LCUPRZ0I8S3I                 2.456276            2.447855   \n",
       "A1OOCYEFLAJD98                 4.215473            2.133665   \n",
       "A1U0FDPQ953KXX                 3.233671            2.932160   \n",
       "AK4WAT44YKU7J                  2.472847            2.452395   \n",
       "AMEBLCWTZKLS2                  2.179029            2.148400   \n",
       "ATA61WNUAP91U                  2.610659            2.755065   \n",
       "\n",
       "                testing_layer_1_accuracy  testing_layer_2_rt  \\\n",
       "A1LCUPRZ0I8S3I                      0.75            2.726375   \n",
       "A1OOCYEFLAJD98                      0.75            2.373321   \n",
       "A1U0FDPQ953KXX                      0.75            3.165090   \n",
       "AK4WAT44YKU7J                       0.70            2.254125   \n",
       "AMEBLCWTZKLS2                       0.75            2.409650   \n",
       "ATA61WNUAP91U                       0.80            2.373785   \n",
       "\n",
       "                testing_layer_2_accuracy  testing_layer_3_rt  \\\n",
       "A1LCUPRZ0I8S3I                      0.50            2.775510   \n",
       "A1OOCYEFLAJD98                      0.70            2.526340   \n",
       "A1U0FDPQ953KXX                      0.60            2.231432   \n",
       "AK4WAT44YKU7J                       0.85            2.578435   \n",
       "AMEBLCWTZKLS2                       0.55            2.305000   \n",
       "ATA61WNUAP91U                       0.65            2.514170   \n",
       "\n",
       "                testing_layer_3_accuracy  testing_longest_response_strike  \n",
       "A1LCUPRZ0I8S3I                      0.65                              4.0  \n",
       "A1OOCYEFLAJD98                      0.60                              4.0  \n",
       "A1U0FDPQ953KXX                      0.70                              3.0  \n",
       "AK4WAT44YKU7J                       0.80                              7.0  \n",
       "AMEBLCWTZKLS2                       0.45                              3.0  \n",
       "ATA61WNUAP91U                       0.50                              5.0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract data that passes all criterions: \n",
    "final_participants_df=data_df_for_analysis[only_qualified]\n",
    "final_participants_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "      <th>not_too_slow</th>\n",
       "      <th>not_too_Fast</th>\n",
       "      <th>sufficient_test_acc</th>\n",
       "      <th>WorkerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A11EXIB1MVBZFJ</th>\n",
       "      <td>1.1560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.790667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.790667</td>\n",
       "      <td>1.13860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>2.094241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>A11EXIB1MVBZFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1F9KLZGHE9DTA</th>\n",
       "      <td>0.5979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.385950</td>\n",
       "      <td>1.7404</td>\n",
       "      <td>1.315060</td>\n",
       "      <td>0.59792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.418513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>A1F9KLZGHE9DTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1LCUPRZ0I8S3I</th>\n",
       "      <td>0.9871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>1.37952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>2.649913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A1LCUPRZ0I8S3I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OOCYEFLAJD98</th>\n",
       "      <td>0.5116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>0.67562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.343953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A1OOCYEFLAJD98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1U0FDPQ953KXX</th>\n",
       "      <td>1.1286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.252667</td>\n",
       "      <td>3.3118</td>\n",
       "      <td>5.640840</td>\n",
       "      <td>1.30840</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.785461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A1U0FDPQ953KXX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A11EXIB1MVBZFJ         1.1560                 1.0            1.000000   \n",
       "A1F9KLZGHE9DTA         0.5979                 1.0            0.833333   \n",
       "A1LCUPRZ0I8S3I         0.9871                 1.0            1.000000   \n",
       "A1OOCYEFLAJD98         0.5116                 1.0            1.000000   \n",
       "A1U0FDPQ953KXX         1.1286                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A11EXIB1MVBZFJ             15.790667                     NaN   \n",
       "A1F9KLZGHE9DTA              1.385950                  1.7404   \n",
       "A1LCUPRZ0I8S3I              2.185933                     NaN   \n",
       "A1OOCYEFLAJD98              2.427583                     NaN   \n",
       "A1U0FDPQ953KXX              5.252667                  3.3118   \n",
       "\n",
       "                demo_RT_correct_mean  encoding_arrow_mean_rt  \\\n",
       "A11EXIB1MVBZFJ             15.790667                 1.13860   \n",
       "A1F9KLZGHE9DTA              1.315060                 0.59792   \n",
       "A1LCUPRZ0I8S3I              2.185933                 1.37952   \n",
       "A1OOCYEFLAJD98              2.427583                 0.67562   \n",
       "A1U0FDPQ953KXX              5.640840                 1.30840   \n",
       "\n",
       "                encoding_arrow_accuracy  testing_Test_overall_accuracy  \\\n",
       "A11EXIB1MVBZFJ                      1.0                       0.516667   \n",
       "A1F9KLZGHE9DTA                      1.0                       0.566667   \n",
       "A1LCUPRZ0I8S3I                      1.0                       0.633333   \n",
       "A1OOCYEFLAJD98                      1.0                       0.683333   \n",
       "A1U0FDPQ953KXX                      1.0                       0.683333   \n",
       "\n",
       "                testing_RT_overall_mean  ...  testing_layer_3_accuracy  \\\n",
       "A11EXIB1MVBZFJ                 2.094241  ...                      0.45   \n",
       "A1F9KLZGHE9DTA                 1.418513  ...                      0.45   \n",
       "A1LCUPRZ0I8S3I                 2.649913  ...                      0.65   \n",
       "A1OOCYEFLAJD98                 2.343953  ...                      0.60   \n",
       "A1U0FDPQ953KXX                 2.785461  ...                      0.70   \n",
       "\n",
       "                testing_longest_response_strike  demo_demo_accuracy  \\\n",
       "A11EXIB1MVBZFJ                              4.0                True   \n",
       "A1F9KLZGHE9DTA                              6.0                True   \n",
       "A1LCUPRZ0I8S3I                              4.0                True   \n",
       "A1OOCYEFLAJD98                              4.0                True   \n",
       "A1U0FDPQ953KXX                              3.0                True   \n",
       "\n",
       "                demo_arrow_correct  encoding_arrow_accuracy  \\\n",
       "A11EXIB1MVBZFJ                True                     True   \n",
       "A1F9KLZGHE9DTA                True                     True   \n",
       "A1LCUPRZ0I8S3I                True                     True   \n",
       "A1OOCYEFLAJD98                True                     True   \n",
       "A1U0FDPQ953KXX                True                     True   \n",
       "\n",
       "                testing_longest_response_strike  not_too_slow  not_too_Fast  \\\n",
       "A11EXIB1MVBZFJ                             True          True          True   \n",
       "A1F9KLZGHE9DTA                             True          True          True   \n",
       "A1LCUPRZ0I8S3I                             True          True          True   \n",
       "A1OOCYEFLAJD98                             True          True          True   \n",
       "A1U0FDPQ953KXX                             True          True          True   \n",
       "\n",
       "                sufficient_test_acc        WorkerId  \n",
       "A11EXIB1MVBZFJ                False  A11EXIB1MVBZFJ  \n",
       "A1F9KLZGHE9DTA                False  A1F9KLZGHE9DTA  \n",
       "A1LCUPRZ0I8S3I                 True  A1LCUPRZ0I8S3I  \n",
       "A1OOCYEFLAJD98                 True  A1OOCYEFLAJD98  \n",
       "A1U0FDPQ953KXX                 True  A1U0FDPQ953KXX  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = pd.concat([data_df_for_analysis,disqualification_df], axis = 1)\n",
    "total_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_participants_df.to_csv(PATH_TO_BATCH / ('one_line_per_participant_all_info_valid_subjects_only_' + qualification_method + '.csv'))\n",
    "total_data.to_csv(PATH_TO_BATCH / ('one_line_per_participant_all_info_all_subject_' + qualification_method + '.csv'))\n",
    "criterions_df.to_csv(PATH_TO_BATCH /('criterions_info_' + qualification_method + '.csv'),index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RT')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(10,5))\n",
    "sns.barplot(data=final_participants_df[['testing_layer_1_accuracy','testing_layer_2_accuracy','testing_layer_3_accuracy']],ax=axes[0])\n",
    "sns.swarmplot(data=final_participants_df[['testing_layer_1_accuracy','testing_layer_2_accuracy','testing_layer_3_accuracy']],ax=axes[0],color='k')\n",
    "\n",
    "axes[0].set_xticklabels(labels=['layer1','layer2','layer3'],rotation=30)\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "\n",
    "sns.barplot(data=final_participants_df[['testing_layer_1_rt','testing_layer_2_rt','testing_layer_3_rt']],ax=axes[1])\n",
    "sns.swarmplot(data=final_participants_df[['testing_layer_1_rt','testing_layer_2_rt','testing_layer_3_rt']],ax=axes[1],color='k')\n",
    "\n",
    "axes[1].set_xticklabels(labels=['layer1','layer2','layer3'],rotation=30)\n",
    "axes[1].set_ylabel('RT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RT')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(10,5))\n",
    "sns.pointplot(data=final_participants_df[['testing_layer_1_accuracy','testing_layer_2_accuracy','testing_layer_3_accuracy']],ax=axes[0])\n",
    "#sns.swarmplot(data=final_participants_df[['testing_layer_1_accuracy','testing_layer_2_accuracy','testing_layer_3_accuracy']],ax=axes[0],color='k')\n",
    "\n",
    "axes[0].set_xticklabels(labels=['layer1','layer2','layer3'],rotation=30)\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "\n",
    "sns.pointplot(data=final_participants_df[['testing_layer_1_rt','testing_layer_2_rt','testing_layer_3_rt']],ax=axes[1])\n",
    "#sns.swarmplot(data=final_participants_df[['testing_layer_1_rt','testing_layer_2_rt','testing_layer_3_rt']],ax=axes[1],color='k')\n",
    "\n",
    "axes[1].set_xticklabels(labels=['layer1','layer2','layer3'],rotation=30)\n",
    "axes[1].set_ylabel('RT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changed entrees for: ['A2KDZLWD8RAHDM', 'A3EBIC3PKUSKCL', 'A1PN0EFQD8OHSU', 'A10AKR84P1WXHL', 'A1MT4FMXL4WRAF', 'ABGKJYEITBKIL', 'AL113DDABUJQ0', 'A1CB9NR3SN4VMY', 'A2HY7GQ07YIZTT', 'A1W0K28IND6NR4', 'A2U50SMRZT60ZF', 'A3UZ5V4Y0K3YPV', 'AEHH65WR5E3L6', 'A1SL80AWG592HX', 'A1I1IMZ2ROJY3I', 'A3NME80IO3UFFO', 'A2PTABUVOUYAH5', 'A3USIO03UXTDUT', 'AVP8OEUW3NB4D', 'A1HUQ7QA5QWM5Q', 'A2F5SKVBQQXFX0', 'A3FJQY40AAYLDF', 'A12K1ADYMRSWMJ', 'A1W9HGZ8IKQMTW', 'A5AE8MWFQVBX62', 'ASQJWS2HM0ZW9', 'A5JWBZ2885D1N', 'A14CZ7WXO9TOSX', 'AEOLA4FY5IDHE', 'A2Y8LZS5C81O25', 'AQC0KPAOX4ZPL', 'A3NAONPCTVT6P1', 'A2PF6UAA5SUVD0', 'A290Z6QAL17PQE', 'A2MQPQ30Z0ETL4', 'AG6UL22QLCKOG', 'A29DB0P3TCTY3I', 'A1Y0ZBE9UBJV2S', 'A3Q228ENXTJ38F', 'A1NQVG69U3TRDK', 'A39IAY6VBVR8FD', 'A3JRY3AL756S3P', 'AP9YNGPNQSX7I', 'A29O6FOYRB10S2', 'AUGML2ZY46M47', 'A2HFHW1AT6CYCV', 'A2A66Wjgsvjmdcmc', 'A2BUHMLNE3LUU1']\n"
     ]
    }
   ],
   "source": [
    "#this is the updated shelf: copy from here and place in the shelf location in pavlovia.org\n",
    "new_shelf_dict=shelf_dict.copy()\n",
    "\n",
    "\n",
    "clean_shelf_after_test=True #change to true if you run this code after completing both encoding and test sessions and want to also resert participants that didnt come back at all... \n",
    "if clean_shelf_after_test: \n",
    "\n",
    "\n",
    "    allowed_interval_in_hours=24\n",
    "    allowed_jitter=3\n",
    "    allowed_interval_in_ms=[allowed_interval_in_hours-allowed_jitter,allowed_interval_in_hours+allowed_jitter]*3600*1000\n",
    "\n",
    "\n",
    "    new_shelf_dict=shelf_dict.copy()\n",
    "    changed_keys_list=[]\n",
    "    for key in new_shelf_dict.keys():\n",
    "        cur_entries=new_shelf_dict[key]\n",
    "        if len(cur_entries)==2: \n",
    "            cur_entries[0]=999\n",
    "            changed_keys_list.append(key)\n",
    "\n",
    "        if len(cur_entries)>2:\n",
    "            encoding_time=cur_entries[1]\n",
    "            last_entree=cur_entries[-1]\n",
    "            if (last_entree - encoding_time) < allowed_interval_in_ms[0]:\n",
    "                cur_entries[0]=999\n",
    "                changed_keys_list.append(key)\n",
    "\n",
    "\n",
    "        new_shelf_dict[key]=cur_entries\n",
    "\n",
    "    print('changed entrees for:',changed_keys_list)\n",
    "\n",
    "    ##### print the updated shelf dictionary so you can copy it from the cell output and paste in the shelf:  (change the shelf only if you run this code after both encoding and TEST has ended) ####\n",
    "    new_shelf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_arrow_rt</th>\n",
       "      <th>demo_arrow_correct</th>\n",
       "      <th>demo_demo_accuracy</th>\n",
       "      <th>demo_RT_overall_mean</th>\n",
       "      <th>demo_RT_incorrect_mean</th>\n",
       "      <th>demo_RT_correct_mean</th>\n",
       "      <th>encoding_arrow_mean_rt</th>\n",
       "      <th>encoding_arrow_accuracy</th>\n",
       "      <th>testing_Test_overall_accuracy</th>\n",
       "      <th>testing_RT_overall_mean</th>\n",
       "      <th>testing_RT_incorrect_mean</th>\n",
       "      <th>testing_RT_correct_mean</th>\n",
       "      <th>testing_layer_1_rt</th>\n",
       "      <th>testing_layer_1_accuracy</th>\n",
       "      <th>testing_layer_2_rt</th>\n",
       "      <th>testing_layer_2_accuracy</th>\n",
       "      <th>testing_layer_3_rt</th>\n",
       "      <th>testing_layer_3_accuracy</th>\n",
       "      <th>testing_longest_response_strike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1LCUPRZ0I8S3I</th>\n",
       "      <td>0.9871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.185933</td>\n",
       "      <td>1.37952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>2.649913</td>\n",
       "      <td>2.984377</td>\n",
       "      <td>2.456276</td>\n",
       "      <td>2.447855</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.726375</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.775510</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1OOCYEFLAJD98</th>\n",
       "      <td>0.5116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.427583</td>\n",
       "      <td>0.67562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.343953</td>\n",
       "      <td>2.364995</td>\n",
       "      <td>4.215473</td>\n",
       "      <td>2.133665</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.373321</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.526340</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1U0FDPQ953KXX</th>\n",
       "      <td>1.1286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.252667</td>\n",
       "      <td>3.3118</td>\n",
       "      <td>5.640840</td>\n",
       "      <td>1.30840</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.785461</td>\n",
       "      <td>2.953126</td>\n",
       "      <td>3.233671</td>\n",
       "      <td>2.932160</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.165090</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.231432</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK4WAT44YKU7J</th>\n",
       "      <td>0.6394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.239683</td>\n",
       "      <td>2.5745</td>\n",
       "      <td>2.072275</td>\n",
       "      <td>0.52266</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>2.428318</td>\n",
       "      <td>2.267331</td>\n",
       "      <td>2.472847</td>\n",
       "      <td>2.452395</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.254125</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.578435</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMEBLCWTZKLS2</th>\n",
       "      <td>0.9730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.663333</td>\n",
       "      <td>1.3950</td>\n",
       "      <td>1.717000</td>\n",
       "      <td>1.03720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>2.287683</td>\n",
       "      <td>2.439800</td>\n",
       "      <td>2.179029</td>\n",
       "      <td>2.148400</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.409650</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.305000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                demo_arrow_rt  demo_arrow_correct  demo_demo_accuracy  \\\n",
       "A1LCUPRZ0I8S3I         0.9871                 1.0            1.000000   \n",
       "A1OOCYEFLAJD98         0.5116                 1.0            1.000000   \n",
       "A1U0FDPQ953KXX         1.1286                 1.0            0.833333   \n",
       "AK4WAT44YKU7J          0.6394                 1.0            0.666667   \n",
       "AMEBLCWTZKLS2          0.9730                 1.0            0.833333   \n",
       "\n",
       "                demo_RT_overall_mean  demo_RT_incorrect_mean  \\\n",
       "A1LCUPRZ0I8S3I              2.185933                     NaN   \n",
       "A1OOCYEFLAJD98              2.427583                     NaN   \n",
       "A1U0FDPQ953KXX              5.252667                  3.3118   \n",
       "AK4WAT44YKU7J               2.239683                  2.5745   \n",
       "AMEBLCWTZKLS2               1.663333                  1.3950   \n",
       "\n",
       "                demo_RT_correct_mean  encoding_arrow_mean_rt  \\\n",
       "A1LCUPRZ0I8S3I              2.185933                 1.37952   \n",
       "A1OOCYEFLAJD98              2.427583                 0.67562   \n",
       "A1U0FDPQ953KXX              5.640840                 1.30840   \n",
       "AK4WAT44YKU7J               2.072275                 0.52266   \n",
       "AMEBLCWTZKLS2               1.717000                 1.03720   \n",
       "\n",
       "                encoding_arrow_accuracy  testing_Test_overall_accuracy  \\\n",
       "A1LCUPRZ0I8S3I                      1.0                       0.633333   \n",
       "A1OOCYEFLAJD98                      1.0                       0.683333   \n",
       "A1U0FDPQ953KXX                      1.0                       0.683333   \n",
       "AK4WAT44YKU7J                       1.0                       0.783333   \n",
       "AMEBLCWTZKLS2                       1.0                       0.583333   \n",
       "\n",
       "                testing_RT_overall_mean  testing_RT_incorrect_mean  \\\n",
       "A1LCUPRZ0I8S3I                 2.649913                   2.984377   \n",
       "A1OOCYEFLAJD98                 2.343953                   2.364995   \n",
       "A1U0FDPQ953KXX                 2.785461                   2.953126   \n",
       "AK4WAT44YKU7J                  2.428318                   2.267331   \n",
       "AMEBLCWTZKLS2                  2.287683                   2.439800   \n",
       "\n",
       "                testing_RT_correct_mean  testing_layer_1_rt  \\\n",
       "A1LCUPRZ0I8S3I                 2.456276            2.447855   \n",
       "A1OOCYEFLAJD98                 4.215473            2.133665   \n",
       "A1U0FDPQ953KXX                 3.233671            2.932160   \n",
       "AK4WAT44YKU7J                  2.472847            2.452395   \n",
       "AMEBLCWTZKLS2                  2.179029            2.148400   \n",
       "\n",
       "                testing_layer_1_accuracy  testing_layer_2_rt  \\\n",
       "A1LCUPRZ0I8S3I                      0.75            2.726375   \n",
       "A1OOCYEFLAJD98                      0.75            2.373321   \n",
       "A1U0FDPQ953KXX                      0.75            3.165090   \n",
       "AK4WAT44YKU7J                       0.70            2.254125   \n",
       "AMEBLCWTZKLS2                       0.75            2.409650   \n",
       "\n",
       "                testing_layer_2_accuracy  testing_layer_3_rt  \\\n",
       "A1LCUPRZ0I8S3I                      0.50            2.775510   \n",
       "A1OOCYEFLAJD98                      0.70            2.526340   \n",
       "A1U0FDPQ953KXX                      0.60            2.231432   \n",
       "AK4WAT44YKU7J                       0.85            2.578435   \n",
       "AMEBLCWTZKLS2                       0.55            2.305000   \n",
       "\n",
       "                testing_layer_3_accuracy  testing_longest_response_strike  \n",
       "A1LCUPRZ0I8S3I                      0.65                              4.0  \n",
       "A1OOCYEFLAJD98                      0.60                              4.0  \n",
       "A1U0FDPQ953KXX                      0.70                              3.0  \n",
       "AK4WAT44YKU7J                       0.80                              7.0  \n",
       "AMEBLCWTZKLS2                       0.45                              3.0  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_participants_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 were given a UPDATE-completed birds memory rep, names: ['A15B4KZ3S04HS8', 'A1LA6CIGBNDOH9', 'A22HIX1M4QXZBB', 'A248QG4DPULP46', 'A2J1DNVMJ56JG1', 'A2J57IBR2XIWLS', 'A3MIDLO5S7FU06', 'A3U0GQGAPN2DAV', 'A5P12YJP805RG', 'ASNNAP90D5R1Z', 'A1JJYY622DGE5L', 'AE33JO53WTHZQ', 'A4ANRSA55IW5Q', 'A11EXIB1MVBZFJ', 'AMEBLCWTZKLS2', 'A3EBIC3PKUSKCL', 'AVZRZOK0F26P6', 'A1MT4FMXL4WRAF', 'AK4WAT44YKU7J', 'A3VHDQR8A9JJ4F', 'AL113DDABUJQ0', 'AB8XECKH1JO8P', 'A2HY7GQ07YIZTT', 'A1U0FDPQ953KXX', 'A2M183CETUMR96', 'A1LCUPRZ0I8S3I', 'A3UZ5V4Y0K3YPV', 'ATA61WNUAP91U', 'A149YZJBFRDWBJ', 'A1SL80AWG592HX', 'A1I1IMZ2ROJY3I', 'A3RDT5DH21PVAR', 'A1F9KLZGHE9DTA', 'AVP8OEUW3NB4D', 'A2ASRB2MTHDHPD', 'A1HUQ7QA5QWM5Q', 'A2A66W3JTSP642', 'A98E8M4QLI9RS', 'A3FJQY40AAYLDF', 'A12K1ADYMRSWMJ', 'A31FDAPJJ2EBGA', 'A1W9HGZ8IKQMTW', 'A3JJXDML3XNSQP', 'A1OOCYEFLAJD98', 'A129Y082RKJN6V', 'A2BUHMLNE3LUU0', 'A1NQVG69U3TRDK', 'AUGML2ZY46M47']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'dict' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\visual_memory_project\\visual-memory-project\\functions\\visual memory representations\\experiment analysis\\parse_results_24_h_encoding_and_testing.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/visual_memory_project/visual-memory-project/functions/visual%20memory%20representations/experiment%20analysis/parse_results_24_h_encoding_and_testing.ipynb#X42sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         data \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/visual_memory_project/visual-memory-project/functions/visual%20memory%20representations/experiment%20analysis/parse_results_24_h_encoding_and_testing.ipynb#X42sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         shelf_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(data)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/visual_memory_project/visual-memory-project/functions/visual%20memory%20representations/experiment%20analysis/parse_results_24_h_encoding_and_testing.ipynb#X42sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     new_shelf_dict \u001b[39m=\u001b[39m new_shelf_dict \u001b[39m|\u001b[39;49m shelf_dict\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/visual_memory_project/visual-memory-project/functions/visual%20memory%20representations/experiment%20analysis/parse_results_24_h_encoding_and_testing.ipynb#X42sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mcopy the following dictionary content to the pavlovia dictionary, and to the \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshelf final state.txt\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/visual_memory_project/visual-memory-project/functions/visual%20memory%20representations/experiment%20analysis/parse_results_24_h_encoding_and_testing.ipynb#X42sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m json\u001b[39m.\u001b[39mdumps(new_shelf_dict)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'dict' and 'dict'"
     ]
    }
   ],
   "source": [
    "#find all participants that exists in the shelf, and make sure they have a participantion code (so they wont be able to come back to this experiemnt)\n",
    "all_shelf_workers_that_are_assigned_participantion=[]\n",
    "for curr_key in shelf_dict.keys():\n",
    "    if curr_key in workers_df['Worker ID'].values:\n",
    "        workers_df.loc[workers_df['Worker ID']==curr_key,qualification_name_for_entire_experiment]=1\n",
    "        all_shelf_workers_that_are_assigned_participantion.append(curr_key)\n",
    "\n",
    "print(f'{len(all_shelf_workers_that_are_assigned_participantion)} were given a {qualification_name_for_entire_experiment}, names: {all_shelf_workers_that_are_assigned_participantion}')\n",
    "\n",
    "#create a new shelf, that only contains the ids and numbers of valid participants (this is so we wont re-use thier custom trials order (csvs))\n",
    "new_shelf_dict=dict()\n",
    "for sub_id in final_participants_df.index: \n",
    "    new_shelf_dict[sub_id]=shelf_dict[sub_id]\n",
    "new_shelf_dict  \n",
    "\n",
    "# add the final state of the previous batch \n",
    "previous_batch = 'batch ' + str(int(batch_name[-1]) - 1)\n",
    "root_dirs = list(PATH_TO_BATCH.parent.iterdir())\n",
    "target_dir = PATH_TO_BATCH.parent/ previous_batch\n",
    "if target_dir in root_dirs:\n",
    "    path_final_state_shelf = target_dir / 'shelf final state.txt'\n",
    "    with open(path_final_state_shelf) as f:\n",
    "        data = f.read()\n",
    "        shelf_dict = json.loads(data)\n",
    "    \n",
    "    new_shelf_dict = new_shelf_dict | shelf_dict\n",
    "\n",
    "\n",
    "print('\\n\\ncopy the following dictionary content to the pavlovia dictionary, and to the \"shelf final state.txt\"\\n')\n",
    "json.dumps(new_shelf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_workers_df_extended.to_csv(PATH_TO_BATCH / path.Path(batch_name+'_workers_results_extended_with_disqualification.csv'))\n",
    "workers_df.to_csv(PATH_TO_BATCH / path.Path(batch_name+'_workers_results_for_upload_after_encoding_and_test.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6 | packaged by conda-forge | (default, Oct  7 2020, 18:22:52) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daaad0aab37e3cfda126cdace0cf33ee7e0dcddc208629485a16e56be0130fd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
